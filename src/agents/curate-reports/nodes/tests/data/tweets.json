[
  {
    "edit_history_tweet_ids": ["1880334437671633389"],
    "created_at": "2025-01-17T19:20:39.000Z",
    "text": "RT @isaacbmiller1: i wrote up a dspy example notebook showing off this type of functionality as a first example of multimodal dspy. (comple‚Ä¶",
    "author_id": "1605274291569799168",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880329244200579363" }],
    "id": "1880334437671633389"
  },
  {
    "edit_history_tweet_ids": ["1880334332616929325"],
    "created_at": "2025-01-17T19:20:14.000Z",
    "text": "what startups are working on the ai agent RBAC space?",
    "author_id": "260411518",
    "id": "1880334332616929325"
  },
  {
    "edit_history_tweet_ids": ["1880334203214291231"],
    "created_at": "2025-01-17T19:19:43.000Z",
    "text": "@polynoamial Thanks for not doing vagueposting",
    "author_id": "800854096219471872",
    "in_reply_to_user_id": "825088493764407298",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880333390525919722" }
    ],
    "id": "1880334203214291231"
  },
  {
    "edit_history_tweet_ids": ["1880333766536884533"],
    "created_at": "2025-01-17T19:17:59.000Z",
    "text": "RT @DKThomp: I spent a long, long time trying to answer a question that I really care about.\n\nIs moderate drinking‚Äîsay, 1 glass of wine a n‚Ä¶",
    "author_id": "10834752",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879900932520968577" }],
    "id": "1880333766536884533"
  },
  {
    "edit_history_tweet_ids": ["1880333390525919722"],
    "created_at": "2025-01-17T19:16:29.000Z",
    "text": "Lots of vague AI hype on social media these days. There are good reasons to be optimistic about further progress, but plenty of unsolved research problems remain.",
    "author_id": "825088493764407298",
    "id": "1880333390525919722"
  },
  {
    "edit_history_tweet_ids": ["1880333319201841458"],
    "created_at": "2025-01-17T19:16:12.000Z",
    "text": "RT @TheXeophon: The more I interact with AI, the more I am attracted to human writing, human art and human interaction",
    "author_id": "175282603",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880168270663385412" }],
    "id": "1880333319201841458"
  },
  {
    "edit_history_tweet_ids": ["1880332720070705450"],
    "created_at": "2025-01-17T19:13:50.000Z",
    "text": "RT @XRobservatory: On the eve of the AI Action Summit in Paris, we proudly announce our AI Safety Debate with Prof. Yoshua Bengio!üì¢\n\nNext t‚Ä¶",
    "author_id": "1831398480700428289",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880298416259182644" }],
    "id": "1880332720070705450"
  },
  {
    "edit_history_tweet_ids": ["1880332618807615658"],
    "created_at": "2025-01-17T19:13:25.000Z",
    "text": "can't believe claude just said \"bfloat16 is pog\" i love the future",
    "author_id": "1499415401763115019",
    "id": "1880332618807615658"
  },
  {
    "edit_history_tweet_ids": ["1880331528129167708"],
    "attachments": { "media_keys": ["3_1880329921823723521"] },
    "created_at": "2025-01-17T19:09:05.000Z",
    "text": "https://t.co/YyF0mEL2CR (made by @swishfever) https://t.co/prRnVX4V5Y",
    "author_id": "441465751",
    "id": "1880331528129167708"
  },
  {
    "edit_history_tweet_ids": ["1880331306204373400"],
    "created_at": "2025-01-17T19:08:12.000Z",
    "text": "spent the last month building my own framework to train a diffusion model from scratch.  it was hard\n\nalmost like i just learned to cast an ancient spell that requires lots of mysterious steps and ingredients.  for a long time i was trying, and nothing happened.  but when it‚Ä¶ https://t.co/emrh8x2QOf",
    "author_id": "783098774130401280",
    "note_tweet": {
      "text": "spent the last month building my own framework to train a diffusion model from scratch.  it was hard\n\nalmost like i just learned to cast an ancient spell that requires lots of mysterious steps and ingredients.  for a long time i was trying, and nothing happened.  but when it worked it felt like magic\n\ni've learned a lot so wanted to share a bit üßµ\n\n- i'm doing *conditional* diffusion, trying to produce outputs x that depend on some inputs y.  my biggest blocker was that the architectural biases matter here ‚Äì  you can NOT put the conditioning directly into the input, or the model will just learn to map y to x instead of using y to denoise the noisy input x. (the loss will go down but sampling will not work)\n- thus the diffusion world has a zoo of \"conditional\" architectures that can be a little challenging to adapt for your problem. but you have to use one or else things just won't work\n- apparently, architecture still matters in vision (sad).   initialization, residuals, and extra normalization can make all the difference\n- learning a small \"probe\" alongside your diffusion model is hugely valuable.  you can just cut the gradients to the probe so that it doesn't affect training.  this way you will know when you beat the baseline.  (i'm not sure if this is common practice but it was invaluable for me)\n- you need to incorporate sampling into training every-so-often. otherwise you will never figure out why your model doesn't work\n- the normalization is super important.  your input data needs to have ~mean 0 or std 1.  otherwise learning might not work,  or will be super slow\n- in diffusion a lot of things can have the same shape but be different \"types\" in the sense that they're incompatible in some way.  easy to make these bugs and the code will still run.  and you often can find them by checking that the norms, stds, and means are approximately correct\n- complex systems that you write from scratch will inevitably have tons of bugs.  you can start with trying to learn the identity function (in diffusion just set the noise to zeros).  if you can't do this something is broken.  in my case this helped me realize one of my losses had a sign flipped\n- in my opinion the loss after 1000 steps or so is usually a reliable signal for debugging architectural changes\n- diffusion people look down on DDPM as old and outdated but turns out it's still \"good enough for government work\" and worked fine for me eventually\n- wouldn't recommend the diffusers library.  not sure it's really being developed anymore.  heard the openai impl is much better\n- in general building systems from scratch is a slow and frustrating way to do research and i would recommend most people just start with a good codebase and tweaking it to fit your problem.  but if you build everything yourself you will learn a lot and feel a deep sense of satisfaction when it all starts working :)"
    },
    "id": "1880331306204373400"
  },
  {
    "edit_history_tweet_ids": ["1880331180660388330"],
    "created_at": "2025-01-17T19:07:42.000Z",
    "text": "Please @OpenAI fix the desktop app. When I copy and paste text from it into Slack/Linear/Etc the bullets &amp; formatting gets messed up. Have to switch back to browser for that",
    "author_id": "288382985",
    "id": "1880331180660388330"
  },
  {
    "edit_history_tweet_ids": ["1880331069964317059"],
    "created_at": "2025-01-17T19:07:16.000Z",
    "text": "RT @not_so_lain: @CohereForAI are launching a new cohort for people who are newly starting their journey in the research field.\n\nfeel free‚Ä¶",
    "author_id": "731538535795163136",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880290990369698274" }],
    "id": "1880331069964317059"
  },
  {
    "edit_history_tweet_ids": ["1880330571211239678"],
    "attachments": { "media_keys": ["3_1880330437358211072"] },
    "created_at": "2025-01-17T19:05:17.000Z",
    "text": "what if https://t.co/APmZR9o1ru",
    "author_id": "73105934",
    "id": "1880330571211239678"
  },
  {
    "edit_history_tweet_ids": ["1880330335650738469"],
    "attachments": { "media_keys": ["3_1880330220332359680"] },
    "created_at": "2025-01-17T19:04:21.000Z",
    "text": "got the email from OpenAI\n\nmust be real https://t.co/3slS8UO4pR",
    "author_id": "800854096219471872",
    "in_reply_to_user_id": "800854096219471872",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880111092430696851" }
    ],
    "id": "1880330335650738469"
  },
  {
    "edit_history_tweet_ids": ["1880328329666109446", "1880329810737786926"],
    "attachments": { "media_keys": ["3_1880328326608207873"] },
    "created_at": "2025-01-17T19:02:16.000Z",
    "text": "On LiveCodeBench, DeepSeek-R1 scores somewhere between o1 low reasoning and o1 medium reasoning \n\nNote that this looks to be full R1 and not the lite version from before https://t.co/2N663zHG9E https://t.co/ZUdSnGdsQR",
    "author_id": "1718879852827484160",
    "referenced_tweets": [{ "type": "quoted", "id": "1880317308515897761" }],
    "id": "1880329810737786926"
  },
  {
    "edit_history_tweet_ids": ["1880329359887856094"],
    "created_at": "2025-01-17T19:00:28.000Z",
    "text": "The big open question is that if you believe o1 is the same underlying model regardless of the reasoning level, what differentiates the reasoning levels and if these techniques are applied to R1, what would its performance look like? https://t.co/0Ic6i7GmjA",
    "author_id": "1718879852827484160",
    "referenced_tweets": [{ "type": "quoted", "id": "1880328329666109446" }],
    "id": "1880329359887856094"
  },
  {
    "edit_history_tweet_ids": ["1880328997571375581"],
    "attachments": { "media_keys": ["3_1880079310586798080"] },
    "created_at": "2025-01-17T18:59:02.000Z",
    "text": "RT @SullyOmarr: Average user trying o1 pro https://t.co/mx44kAcTD9",
    "author_id": "821092604821536768",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880079314177372345" }],
    "id": "1880328997571375581"
  },
  {
    "edit_history_tweet_ids": ["1880328067782226095"],
    "created_at": "2025-01-17T18:55:20.000Z",
    "text": "if you run sales teams or raise capital, i have a with a post with a really good webcam setup for desktops. every founder that has tried it has said it is great: https://t.co/4KIRVLDi3O",
    "author_id": "1128159740599656448",
    "id": "1880328067782226095"
  },
  {
    "edit_history_tweet_ids": ["1880327916082589929"],
    "attachments": { "media_keys": ["3_1880213519183822848"] },
    "created_at": "2025-01-17T18:54:44.000Z",
    "text": "RT @lgrammel: The @ollama provider (by @sgomez ) is the most downloaded AI SDK community provider üëÄ https://t.co/Ko5kP700pV",
    "author_id": "1688410127378829312",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880213693423841676" }],
    "id": "1880327916082589929"
  },
  {
    "edit_history_tweet_ids": ["1880327738021802389"],
    "created_at": "2025-01-17T18:54:02.000Z",
    "text": "gotta just let it run for 2 days straight with a long dataset, thankfully i think i finally reached a point where training is stable, so hopefully l0 continues going down with enough examples",
    "author_id": "1499415401763115019",
    "in_reply_to_user_id": "1499415401763115019",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880316512042676728" }
    ],
    "id": "1880327738021802389"
  },
  {
    "edit_history_tweet_ids": ["1880326800762708217"],
    "created_at": "2025-01-17T18:50:18.000Z",
    "text": "Devin was only at ~14% 6 months ago and now SoTA is 65% \n\nSo I don‚Äôt think we should write off coding agents just because they don‚Äôt work well now https://t.co/hiUOi1KiL6",
    "author_id": "825766640",
    "referenced_tweets": [{ "type": "quoted", "id": "1880004026957500434" }],
    "id": "1880326800762708217"
  },
  {
    "edit_history_tweet_ids": ["1880326272506818783"],
    "created_at": "2025-01-17T18:48:12.000Z",
    "text": "RT @askalphaxiv: Goodreads for arXiv papersüí°\n\nWhat if instead of arbitrary algorithms and tweets, arXiv papers were curated by your researc‚Ä¶",
    "author_id": "1592266692528197632",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879600545654259952" }],
    "id": "1880326272506818783"
  },
  {
    "edit_history_tweet_ids": ["1880324794954240374"],
    "created_at": "2025-01-17T18:42:20.000Z",
    "text": "whitney is one of the most impressive founders i know and i'm thrilled she is returning to be ceo of bumble! great news for the company.",
    "author_id": "1605",
    "id": "1880324794954240374"
  },
  {
    "edit_history_tweet_ids": ["1880324652184330603"],
    "created_at": "2025-01-17T18:41:46.000Z",
    "text": "RT @nomic_ai: Nomic Embed Vision is now under an Apache 2.0 License.\n\n- High quality, unified embedding space for image, text, and multimod‚Ä¶",
    "author_id": "1152315474484613123",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880313093097693212" }],
    "id": "1880324652184330603"
  },
  {
    "edit_history_tweet_ids": ["1880324137673191849"],
    "created_at": "2025-01-17T18:39:43.000Z",
    "text": "So this is the ‚Äúfreedom of speech‚Äù they speak of??? https://t.co/ModKtohXMJ",
    "author_id": "17435275",
    "referenced_tweets": [{ "type": "quoted", "id": "1879930156644811084" }],
    "id": "1880324137673191849"
  },
  {
    "edit_history_tweet_ids": ["1880323606141628899"],
    "created_at": "2025-01-17T18:37:37.000Z",
    "text": "RT @charmaine_klee: the biggest hack for creating fun thumbnails / marketing assets is my personal illustrator, aka townie, https://t.co/9t‚Ä¶",
    "author_id": "52247685",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880307658013466712" }],
    "id": "1880323606141628899"
  },
  {
    "edit_history_tweet_ids": ["1880323335898427596"],
    "created_at": "2025-01-17T18:36:32.000Z",
    "text": "@OpenAI Wait, you are not releasing GPT-5 today?\n\nI am disappointed\n\nhttps://t.co/YFbGVGcU3W",
    "author_id": "800854096219471872",
    "in_reply_to_user_id": "4398626122",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880111090824278189" },
      { "type": "replied_to", "id": "1880323050798973295" }
    ],
    "id": "1880323335898427596"
  },
  {
    "edit_history_tweet_ids": ["1880323055374987392"],
    "created_at": "2025-01-17T18:35:25.000Z",
    "text": "If you're already using custom instructions, this won't change your current settings.",
    "author_id": "4398626122",
    "in_reply_to_user_id": "4398626122",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880323053755974068" }
    ],
    "id": "1880323055374987392"
  },
  {
    "edit_history_tweet_ids": ["1880323053755974068"],
    "created_at": "2025-01-17T18:35:25.000Z",
    "text": "The new UI is rolling out now on https://t.co/nYW5KO1aIg and desktop on Windows, and is coming to mobile and desktop on MacOS in the next few weeks.\n\nAvailable soon to ChatGPT users in the EU, Norway, Iceland, Liechtenstein, and Switzerland.",
    "author_id": "4398626122",
    "in_reply_to_user_id": "4398626122",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880323050798973295" }
    ],
    "id": "1880323053755974068"
  },
  {
    "edit_history_tweet_ids": ["1880323050798973295"],
    "attachments": { "media_keys": ["3_1880314443390685184"] },
    "created_at": "2025-01-17T18:35:24.000Z",
    "text": "We've updated custom instructions to make it easier to customize how ChatGPT responds to you.\n\nWith the new UI, you can tell ChatGPT the traits you want it to have, how you want it to talk to you, and any rules you want it to follow. https://t.co/BaXaqAw5cE",
    "author_id": "4398626122",
    "id": "1880323050798973295"
  },
  {
    "edit_history_tweet_ids": ["1880322512288116836"],
    "created_at": "2025-01-17T18:33:16.000Z",
    "text": "RT @chrisalbon: AI Flashcards: https://t.co/QGN5RHy0HT",
    "author_id": "52247685",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880322203952246992" }],
    "id": "1880322512288116836"
  },
  {
    "edit_history_tweet_ids": ["1880321993737966048"],
    "created_at": "2025-01-17T18:31:12.000Z",
    "text": "Check out DeepSeek-R1 on LiveCodeBench! https://t.co/RIcUCUAKJe",
    "author_id": "1641378826537295874",
    "referenced_tweets": [{ "type": "quoted", "id": "1880317308515897761" }],
    "id": "1880321993737966048"
  },
  {
    "edit_history_tweet_ids": ["1880321627747152134"],
    "created_at": "2025-01-17T18:29:45.000Z",
    "text": "RT @alexutopia: You think you‚Äôre building a following with your personal brand, but what you‚Äôre really building is a mirror.\n\nYour audience‚Ä¶",
    "author_id": "7284012",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880315465861304630" }],
    "id": "1880321627747152134"
  },
  {
    "edit_history_tweet_ids": ["1880320731990618417"],
    "attachments": { "media_keys": ["3_1880288612715032577"] },
    "created_at": "2025-01-17T18:26:11.000Z",
    "text": "RT @mattzcarey: mega success with the @LangChainAI langgraph on @CloudflareDev durable object mission https://t.co/zGsgffhKzx",
    "author_id": "2728439146",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880288798384484365" }],
    "id": "1880320731990618417"
  },
  {
    "edit_history_tweet_ids": ["1880320444936708557"],
    "created_at": "2025-01-17T18:25:03.000Z",
    "text": "RT @dylhunn: o3-mini is my favorite model of all time. It‚Äôs unbelievably fast, and brilliant at code, especially debugging over large conte‚Ä¶",
    "author_id": "1513853205125681162",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880064256626106473" }],
    "id": "1880320444936708557"
  },
  {
    "edit_history_tweet_ids": ["1880320405665087659"],
    "created_at": "2025-01-17T18:24:54.000Z",
    "text": "I‚Äôve spent a LOT of time thinking about this problem.\n\nAt first, I believed that reasoning models like O1 would be limited to solving problems for which we already know the solutions. This assumption was based on the idea that these models are trained on problems with verifiable‚Ä¶ https://t.co/ikVob3p8Az https://t.co/ub3RPVq8TG",
    "author_id": "1825243643529027584",
    "note_tweet": {
      "text": "I‚Äôve spent a LOT of time thinking about this problem.\n\nAt first, I believed that reasoning models like O1 would be limited to solving problems for which we already know the solutions. This assumption was based on the idea that these models are trained on problems with verifiable answers, such as those found in math or coding.\n\nHowever, I‚Äôve come to realize this perspective was incomplete. Reasoning models don‚Äôt memorize solutions - they learn methods and algorithms for approaching problems. This capability allows them to address unsolved problems using existing methodologies, even if humans haven‚Äôt yet solved those problems. For this to happen, the models need the freedom to explore the problem space creatively. They must generate diverse outputs and avoid being overly constrained by current knowledge or assumptions. I believe this freedom to explore is also why TTC models excel on benchmarks like AidanBench.\n\nAs I thought more deeply about this, I began categorizing unsolved problems into two groups:\n1. Problems where we already possess the necessary mathematical tools but haven‚Äôt yet discovered the solution.\n2. Problems that require the invention of entirely new mathematical tools, such as developing calculus or creating a novel branch of mathematics.\n\nIt now seems clear to me that reasoning models should be well-suited to solving problems in the first category.\n\nHowever, I‚Äôm much less confident about their ability to tackle problems in the second category. Making the creative leaps necessary to invent entirely new tools feels like a fundamentally different challenge that requires better architectures.\n\nThat said, large-scale reinforcement learning and search methods could potentially push these models toward developing more general or fundamental approaches for type 1 problems. Such advancements might also lead to insights that bridge the gap to type 2 problems. For example, if a particular method used for a type 2 problem also proves useful for a simpler type 1 problem (where we already know the answer), reasoning models might generalize/grok the solution to the type 1 problem in a way that uncovers insights applicable to the type 2 problem.\n\nThis process mirrors breakthroughs in physics, where unified or more general approaches - such as the Lagrangian, General Relativity, QM or the Path Integral reveal deeper connections and can be applied to simpler problems, to solve them in a shorter and more elegant way.\n\nEven if type 2 problems remain unsolved the space of type 1 problems is HUGE. Making these problems efficiently solvable in the near future would be a monumental achievement.\n\nI see this test-time-compute self-distillation paradigm mainly as an easy way to decrease the cost of solving (already solved problems and) type 1 problems."
    },
    "referenced_tweets": [{ "type": "quoted", "id": "1880142612927246460" }],
    "id": "1880320405665087659"
  },
  {
    "edit_history_tweet_ids": ["1880319445727604756"],
    "attachments": { "media_keys": ["3_1880308874676211712"] },
    "created_at": "2025-01-17T18:21:05.000Z",
    "text": "RT @ezraklein: .@mattyglesias is sharp on Zuck's latest about-face in his mailbag. https://t.co/1lZh9D20gM",
    "author_id": "821092604821536768",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880310156933886132" }],
    "id": "1880319445727604756"
  },
  {
    "edit_history_tweet_ids": ["1880318194193432994"],
    "created_at": "2025-01-17T18:16:06.000Z",
    "text": "RT @ezreeszy: bro Apple Vision Pro is such a failure..\n\nI hate having spent $4000 on a machine that can teleport me to a photo-realistic pr‚Ä¶",
    "author_id": "7284012",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880254891895181387" }],
    "id": "1880318194193432994"
  },
  {
    "edit_history_tweet_ids": ["1880318064958582835"],
    "attachments": { "media_keys": ["3_1880318049745567744"] },
    "created_at": "2025-01-17T18:15:35.000Z",
    "text": "https://t.co/NbAi9povBx https://t.co/oUEGOmgfxQ",
    "author_id": "354571530",
    "referenced_tweets": [{ "type": "quoted", "id": "1880316826112127048" }],
    "id": "1880318064958582835"
  },
  {
    "edit_history_tweet_ids": ["1880317738285228364"],
    "created_at": "2025-01-17T18:14:18.000Z",
    "text": "Duplicate it from: https://t.co/mALXsrM5Rl ... I'll try to update it periodically. I bumped up some versions from the original template, newer Ubuntu base image, Python 3.12, etc. Build &amp; install Pillow-SIMD so the CPUs aren't as much a drag for image pre-processing.",
    "author_id": "557902603",
    "in_reply_to_user_id": "557902603",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880317736686874929" }
    ],
    "id": "1880317738285228364"
  },
  {
    "edit_history_tweet_ids": ["1880317736686874929"],
    "created_at": "2025-01-17T18:14:17.000Z",
    "text": "Helping a co-worker track down an issue running timm in a @huggingface Space, I ended up re-working the JupyterLab Space template. Attach a few @NVIDIAAI  L40S GPUs, some persistent storage, and it works quite nicely for training and evals! It's an improvement for Transformers‚Ä¶ https://t.co/sjOcgnqYVE",
    "author_id": "557902603",
    "note_tweet": {
      "entities": {
        "mentions": [
          {
            "start": 58,
            "end": 70,
            "username": "huggingface",
            "id": "778764142412984320"
          },
          {
            "start": 144,
            "end": 153,
            "username": "NVIDIAAI",
            "id": "740238495952736256"
          }
        ]
      },
      "text": "Helping a co-worker track down an issue running timm in a @huggingface Space, I ended up re-working the JupyterLab Space template. Attach a few @NVIDIAAI  L40S GPUs, some persistent storage, and it works quite nicely for training and evals! It's an improvement for Transformers use too."
    },
    "id": "1880317736686874929"
  },
  {
    "edit_history_tweet_ids": ["1880316826112127048"],
    "created_at": "2025-01-17T18:10:40.000Z",
    "text": "‚ÄúCan‚Äôt pay my reeeent, cus all my computes spent, but that‚Äôs allriiiiight cus I‚Äôm still flyyyy‚Äù https://t.co/bUxhbS7Qqf",
    "author_id": "354571530",
    "referenced_tweets": [{ "type": "quoted", "id": "1880283647825309862" }],
    "id": "1880316826112127048"
  },
  {
    "edit_history_tweet_ids": ["1880316512042676728"],
    "created_at": "2025-01-17T18:09:25.000Z",
    "text": "i think k sparse are probably easier to train than anthropic‚Äôs approach, but i went for that so time to suffer",
    "author_id": "1499415401763115019",
    "in_reply_to_user_id": "1499415401763115019",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880316108877754712" }
    ],
    "id": "1880316512042676728"
  },
  {
    "edit_history_tweet_ids": ["1880316108877754712"],
    "created_at": "2025-01-17T18:07:49.000Z",
    "text": "SAEs are hard",
    "author_id": "1499415401763115019",
    "id": "1880316108877754712"
  },
  {
    "edit_history_tweet_ids": ["1880314571916997076"],
    "created_at": "2025-01-17T18:01:43.000Z",
    "text": "github: https://t.co/vy68ARTizv",
    "author_id": "2465283662",
    "in_reply_to_user_id": "2465283662",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880314518753956261" }
    ],
    "id": "1880314571916997076"
  },
  {
    "edit_history_tweet_ids": ["1880314518753956261"],
    "attachments": { "media_keys": ["3_1880314515331375104"] },
    "created_at": "2025-01-17T18:01:30.000Z",
    "text": "NVIDIA NIM with OpenAI library compatibility and the new cosmos-nemotron-34b¬†are now available in ai-gradio\n\nDevelopers can deploy apps with NVIDIA NIM in just a few lines of code\n\nFor example:\n\npip install \"ai-gradio[nvidia]\"\n\nimport gradio as gr\nimport ai_gradio\n\ndemo =‚Ä¶ https://t.co/euTh3BxyjK https://t.co/Es6aAmk6zG",
    "author_id": "2465283662",
    "note_tweet": {
      "text": "NVIDIA NIM with OpenAI library compatibility and the new cosmos-nemotron-34b¬†are now available in ai-gradio\n\nDevelopers can deploy apps with NVIDIA NIM in just a few lines of code\n\nFor example:\n\npip install \"ai-gradio[nvidia]\"\n\nimport gradio as gr\nimport ai_gradio\n\ndemo = gr.load(\n¬† ¬† name='nvidia:nvidia/cosmos-nemotron-34b',\n¬† ¬† src=ai_gradio.registry,\n)\ndemo.launch()"
    },
    "id": "1880314518753956261"
  },
  {
    "edit_history_tweet_ids": ["1880314144936636629"],
    "attachments": { "media_keys": ["3_1880314142369710080"] },
    "created_at": "2025-01-17T18:00:01.000Z",
    "text": "ü§ñüß† Memory-Enabled AI Chatbots\n\nCreate intelligent chatbots that maintain conversation context across sessions using LangChain and Gemini AI. Featuring MongoDB storage for seamless, persistent memory capabilities.\n\nLearn more: https://t.co/JTBgysAKJs https://t.co/z1nVfIQGKu",
    "author_id": "1589007443853340672",
    "id": "1880314144936636629"
  },
  {
    "edit_history_tweet_ids": ["1880313564881383587"],
    "created_at": "2025-01-17T17:57:43.000Z",
    "text": "I almost didn‚Äôt write the Devin post.  I thought nobody would find it interesting \n\nYet another lesson that you should just ship it and learn from experience",
    "author_id": "825766640",
    "id": "1880313564881383587"
  },
  {
    "edit_history_tweet_ids": ["1880313107270304136"],
    "created_at": "2025-01-17T17:55:53.000Z",
    "text": "RT @SpaceX: Liftoff of Starship's seventh flight test. The Super Heavy booster utilized flight proven hardware for the first time, reusing‚Ä¶",
    "author_id": "821092604821536768",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880265972050981005" }],
    "id": "1880313107270304136"
  },
  {
    "edit_history_tweet_ids": ["1880312721201328574"],
    "created_at": "2025-01-17T17:54:21.000Z",
    "text": "The excitement around this is quite high. A few OEMs have said they‚Äôve never seen anything like this before. Team‚Äôs sprinting to get it in all your hands in a reliable way (something that actually works most of the time, ie). https://t.co/1uu4ODM7FR",
    "author_id": "759894532649545732",
    "referenced_tweets": [{ "type": "quoted", "id": "1874943854849425780" }],
    "id": "1880312721201328574"
  },
  {
    "edit_history_tweet_ids": ["1880311751805399484"],
    "attachments": { "media_keys": ["3_1880311745048100864"] },
    "created_at": "2025-01-17T17:50:30.000Z",
    "text": "Now playing https://t.co/i2KMu8ACQe",
    "author_id": "788107483306942464",
    "id": "1880311751805399484"
  },
  {
    "edit_history_tweet_ids": ["1880309315334205704"],
    "created_at": "2025-01-17T17:40:49.000Z",
    "text": "RT @physical_int: FAST policies also follow language well and allow us to train the first generalist policies that can perform tasks out of‚Ä¶",
    "author_id": "2236047510",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879963474287354141" }],
    "id": "1880309315334205704"
  },
  {
    "edit_history_tweet_ids": ["1880308970088529951"],
    "created_at": "2025-01-17T17:39:27.000Z",
    "text": "This is true for regular software engineering as well\n\nUse LLMs to do 95% of the work that is time-consuming but doesn't require burning brain cells\n\nFocus your bandwidth on uplifting the quality of your software on the remaining 5% that matters\n\nAnd just like that you'll leave‚Ä¶ https://t.co/CshK2XSgKn https://t.co/aDbAO1HPd4",
    "author_id": "1513853205125681162",
    "note_tweet": {
      "text": "This is true for regular software engineering as well\n\nUse LLMs to do 95% of the work that is time-consuming but doesn't require burning brain cells\n\nFocus your bandwidth on uplifting the quality of your software on the remaining 5% that matters\n\nAnd just like that you'll leave your competitors in the dust that ban LLMs, keep on recruiting more to make up for slow development pace and then run into Brook's law"
    },
    "referenced_tweets": [{ "type": "quoted", "id": "1880015645347311772" }],
    "id": "1880308970088529951"
  },
  {
    "edit_history_tweet_ids": ["1880308716400177320"],
    "created_at": "2025-01-17T17:38:27.000Z",
    "text": "RT @arjunkhemani: .@naval: Looking for truth is the opposite of looking for social approval.\n\n‚ÄúI‚Äôm deeply suspicious of groups of people co‚Ä¶",
    "author_id": "1583730714",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880098560101728645" }],
    "id": "1880308716400177320"
  },
  {
    "edit_history_tweet_ids": ["1880308660569792588"],
    "created_at": "2025-01-17T17:38:13.000Z",
    "text": "RT @kalomaze: if you train a model at two learning rates and then merge the models after do you get approximately the same result as if you‚Ä¶",
    "author_id": "1376951872356024325",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880181180336861543" }],
    "id": "1880308660569792588"
  },
  {
    "edit_history_tweet_ids": ["1880308276866478154"],
    "created_at": "2025-01-17T17:36:42.000Z",
    "text": "@sama Why did you make a large personal donation to the inauguration of a president you personally said was a threat to America? Hard to see why you would do that if not that you were expecting a quid pro quo.",
    "author_id": "1122889863932600327",
    "in_reply_to_user_id": "1605",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880303781537292453" }
    ],
    "id": "1880308276866478154"
  },
  {
    "edit_history_tweet_ids": ["1880308223695286484"],
    "attachments": { "media_keys": ["3_1880308180611170304"] },
    "created_at": "2025-01-17T17:36:29.000Z",
    "text": "MidJourney is really such a cool company https://t.co/0LpSOwK0n2",
    "author_id": "1718879852827484160",
    "id": "1880308223695286484"
  },
  {
    "edit_history_tweet_ids": ["1880308145706398050"],
    "created_at": "2025-01-17T17:36:11.000Z",
    "text": "BTW, until late in life I had mediocre grades in maths, physics, and writing.",
    "author_id": "99581347",
    "id": "1880308145706398050"
  },
  {
    "edit_history_tweet_ids": ["1880306275663347982"],
    "created_at": "2025-01-17T17:28:45.000Z",
    "text": "i hate the new year. my previously-chill yoga classes are now getting fully booked and filled by turbonormies who are unironically trying to \"experience challenge and ease and greet the present moment with joy and openness\"",
    "author_id": "1299856802268377090",
    "id": "1880306275663347982"
  },
  {
    "edit_history_tweet_ids": ["1880306081517432936"],
    "attachments": { "media_keys": ["7_1880305683964604416"] },
    "created_at": "2025-01-17T17:27:58.000Z",
    "text": "Here‚Äôs @noahmacca with more details on these best practices. Let us know what you think! https://t.co/m3wZiLicHu",
    "author_id": "1633874951508721686",
    "in_reply_to_user_id": "1633874951508721686",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880306080422695263" }
    ],
    "id": "1880306081517432936"
  },
  {
    "edit_history_tweet_ids": ["1880306080422695263"],
    "created_at": "2025-01-17T17:27:58.000Z",
    "text": "It also includes a meta-prompt to make it fast and easy to define new agents with a range of personalities, and uses the newer, simpler WebRTC interface.",
    "author_id": "1633874951508721686",
    "in_reply_to_user_id": "1633874951508721686",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880306079273480520" }
    ],
    "id": "1880306080422695263"
  },
  {
    "edit_history_tweet_ids": ["1880306079273480520"],
    "created_at": "2025-01-17T17:27:58.000Z",
    "text": "Building with the Realtime API can be complex because of the low-latency, synchronous nature of voice interactions. This repo includes best practices we‚Äôve learned for managing this complexity, like:\n\n- Orchestrating agent handoffs (inspired by Swarm)\n- Background escalation to‚Ä¶ https://t.co/YikwP108TV",
    "author_id": "1633874951508721686",
    "in_reply_to_user_id": "1633874951508721686",
    "note_tweet": {
      "text": "Building with the Realtime API can be complex because of the low-latency, synchronous nature of voice interactions. This repo includes best practices we‚Äôve learned for managing this complexity, like:\n\n- Orchestrating agent handoffs (inspired by Swarm)\n- Background escalation to o1 for advanced decision making\n- Improving model instruction following by defining a state machine in the prompt\n- Demos of applying these patterns to customer service and front desk use cases"
    },
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880306077738365211" }
    ],
    "id": "1880306079273480520"
  },
  {
    "edit_history_tweet_ids": ["1880306077738365211"],
    "created_at": "2025-01-17T17:27:57.000Z",
    "text": "We‚Äôve put together a reference implementation for building and orchestrating agentic patterns using the Realtime API. You can use this repo to prototype a voice app using multi-agent flows in less than 20 minutes! \n\nhttps://t.co/YdGZGt2Y6q",
    "author_id": "1633874951508721686",
    "id": "1880306077738365211"
  },
  {
    "edit_history_tweet_ids": ["1880305918262550570"],
    "created_at": "2025-01-17T17:27:19.000Z",
    "text": "https://t.co/0PPa6oIV7k",
    "author_id": "931470139",
    "in_reply_to_user_id": "931470139",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880305914936455682" }
    ],
    "id": "1880305918262550570"
  },
  {
    "edit_history_tweet_ids": ["1880305914936455682"],
    "attachments": { "media_keys": ["3_1880305742495846400"] },
    "created_at": "2025-01-17T17:27:19.000Z",
    "text": "Google recently published one of the best whitepaper on AI Agents. Everyone should read it.\n\nIt covers everything you need to know:\n&gt; Defines agents, components, and cognitive architectures.\n&gt; Explains tools: extensions, functions, and data stores.\n&gt; Covers learning techniques to‚Ä¶ https://t.co/aXcbkf9JAZ https://t.co/U06aIJzuLw",
    "author_id": "931470139",
    "note_tweet": {
      "text": "Google recently published one of the best whitepaper on AI Agents. Everyone should read it.\n\nIt covers everything you need to know:\n> Defines agents, components, and cognitive architectures.\n> Explains tools: extensions, functions, and data stores.\n> Covers learning techniques to improve agent performance.\n> Demonstrates building agents using LangChain and LangGraph."
    },
    "id": "1880305914936455682"
  },
  {
    "edit_history_tweet_ids": ["1880305043498467662"],
    "created_at": "2025-01-17T17:23:51.000Z",
    "text": "@karpathy @martin_casado Sir, how do I convince my talented ex-big tech SDE peers to use LLMs more for coding\n\nalmost all of them cite privacy/security concerns or hallucinations",
    "author_id": "1513853205125681162",
    "in_reply_to_user_id": "33836629",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880304167518105915" }
    ],
    "id": "1880305043498467662"
  },
  {
    "edit_history_tweet_ids": ["1880303781537292453"],
    "created_at": "2025-01-17T17:18:50.000Z",
    "text": "it was a personal contribution as you state; i am confused about the questions given that my company did not make a decision.",
    "author_id": "1605",
    "in_reply_to_user_id": "1605",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880303311842341152" }
    ],
    "id": "1880303781537292453"
  },
  {
    "edit_history_tweet_ids": ["1880303329357754635"],
    "attachments": { "media_keys": ["3_1880303323590668288"] },
    "created_at": "2025-01-17T17:17:02.000Z",
    "text": "Prompt Engineers at Work üç∞üë∑üé®\n\nExclusive merch only available for the PromptLayer team... but good news is that we are hiring! https://t.co/X9aJO95RQp",
    "author_id": "288382985",
    "id": "1880303329357754635"
  },
  {
    "edit_history_tweet_ids": ["1880303311842341152"],
    "attachments": {
      "media_keys": [
        "3_1880303134875996161",
        "3_1880303178614235136",
        "3_1880303216811810816"
      ]
    },
    "created_at": "2025-01-17T17:16:58.000Z",
    "text": "funny, they never sent me one of these for contributing to democrats... https://t.co/xjpanXSb5D",
    "author_id": "1605",
    "id": "1880303311842341152"
  },
  {
    "edit_history_tweet_ids": ["1880302468741099963"],
    "attachments": { "media_keys": ["3_1880043266659237888"] },
    "created_at": "2025-01-17T17:13:37.000Z",
    "text": "RT @BenSharpie64: @USA_Polling Ugh, Elon makes it so hard to be a SpaceX fan sometimes https://t.co/uQLq8Wj5PQ",
    "author_id": "821092604821536768",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880043271239659808" }],
    "id": "1880302468741099963"
  },
  {
    "edit_history_tweet_ids": ["1880301869064679630"],
    "created_at": "2025-01-17T17:11:14.000Z",
    "text": "putting this out there\n\nIf Trump would appoint me fast food czar I would apply my all to getting In-N-Out on the East Coast",
    "author_id": "52247685",
    "id": "1880301869064679630"
  },
  {
    "edit_history_tweet_ids": ["1880301149104099699"],
    "attachments": { "media_keys": ["3_1879827195130265600"] },
    "created_at": "2025-01-17T17:08:22.000Z",
    "text": "RT @pcuenq: By the way, did you notice that you can now comment on Hugging Face blog posts? üöÄ https://t.co/8hHemoayt2",
    "author_id": "186420551",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879827197583888810" }],
    "id": "1880301149104099699"
  },
  {
    "edit_history_tweet_ids": ["1880301133517975771"],
    "created_at": "2025-01-17T17:08:19.000Z",
    "text": "RT @_fracapuano: How crazy cool is @huggingface - you can make highly customized models standard with a single line. Truly amazing https://‚Ä¶",
    "author_id": "186420551",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880199578122875176" }],
    "id": "1880301133517975771"
  },
  {
    "edit_history_tweet_ids": ["1880300808367141231"],
    "created_at": "2025-01-17T17:07:01.000Z",
    "text": "spaces: https://t.co/X1Vglf9YoC",
    "author_id": "2465283662",
    "in_reply_to_user_id": "2465283662",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880300742273302672" }
    ],
    "id": "1880300808367141231"
  },
  {
    "edit_history_tweet_ids": ["1880300742273302672"],
    "attachments": { "media_keys": ["3_1880300640242405376"] },
    "created_at": "2025-01-17T17:06:45.000Z",
    "text": "HF spaces is so underrated\n\ncheck it out if you dig AI/Agents and want to try out new apps https://t.co/q2E5u81V46",
    "author_id": "2465283662",
    "id": "1880300742273302672"
  },
  {
    "edit_history_tweet_ids": ["1880300661533012194"],
    "attachments": { "media_keys": ["3_1880299462226214912"] },
    "created_at": "2025-01-17T17:06:26.000Z",
    "text": "Scheduled Tasks with LangGraph\n\nChatGPT's new task scheduling feature is a fantastic UX for many AI applications. In this video, we show how to create the same UX for any LangGraph deployment.\n\nAll LangGraph deployments support scheduling, which can be easily set via the SDK. In‚Ä¶ https://t.co/ZV9AJPamgy https://t.co/HdaPE1in7m",
    "author_id": "1589007443853340672",
    "note_tweet": {
      "text": "Scheduled Tasks with LangGraph\n\nChatGPT's new task scheduling feature is a fantastic UX for many AI applications. In this video, we show how to create the same UX for any LangGraph deployment.\n\nAll LangGraph deployments support scheduling, which can be easily set via the SDK. In this video we explain how to easily set it up for your deployment and highlight several of our \"ambient\" (in-the-background\") agent that use scheduling (social media / e-mail assistance).\n\nVideo:\nhttps://t.co/LlPjOTwoaw\n\nBlog post on ambient agents:\nhttps://t.co/0kPBybS7tl",
      "entities": {
        "urls": [
          {
            "start": 476,
            "end": 499,
            "url": "https://t.co/LlPjOTwoaw",
            "expanded_url": "https://youtu.be/9DRn9RpR2vA",
            "display_url": "youtu.be/9DRn9RpR2vA"
          },
          {
            "start": 530,
            "end": 553,
            "url": "https://t.co/0kPBybS7tl",
            "expanded_url": "https://blog.langchain.dev/introducing-ambient-agents/",
            "display_url": "blog.langchain.dev/introducing-am‚Ä¶"
          }
        ]
      }
    },
    "id": "1880300661533012194"
  },
  {
    "edit_history_tweet_ids": ["1880300522701193323"],
    "created_at": "2025-01-17T17:05:53.000Z",
    "text": "My ongoing observation about ChatGPT is that, despite its massive success, they've deprioritized multiuser engagement. Setting up chats that are designed to be shared could easily increase usage.\n\nAs an example, imagine I could use ChatGPT to create an internal weekly newsletter‚Ä¶ https://t.co/JnRhWc4JsD",
    "author_id": "14484214",
    "in_reply_to_user_id": "14484214",
    "note_tweet": {
      "text": "My ongoing observation about ChatGPT is that, despite its massive success, they've deprioritized multiuser engagement. Setting up chats that are designed to be shared could easily increase usage.\n\nAs an example, imagine I could use ChatGPT to create an internal weekly newsletter about the code that got written last week and then sent it out via email or Slack.\n\nThe message could take users to a chat where they could ask follow up questions, which would boost usage."
    },
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880299555557658922" }
    ],
    "id": "1880300522701193323"
  },
  {
    "edit_history_tweet_ids": ["1880299555557658922"],
    "attachments": { "media_keys": ["3_1880298625592348673"] },
    "created_at": "2025-01-17T17:02:02.000Z",
    "text": "Used ChatGPT's new Tasks feature to have it message me Fridays at 10am with suggested local kids activities.\n\nSolid suggestions overall. Easy to imagine this feature leading to ultra-personalized newsletters.\n\nBig potential for virality once a tasks like this can include sending‚Ä¶ https://t.co/KzsD7dnwf4 https://t.co/N7KKdw2ttP",
    "author_id": "14484214",
    "note_tweet": {
      "text": "Used ChatGPT's new Tasks feature to have it message me Fridays at 10am with suggested local kids activities.\n\nSolid suggestions overall. Easy to imagine this feature leading to ultra-personalized newsletters.\n\nBig potential for virality once a tasks like this can include sending ChatGPTs response to a few friends via text/email."
    },
    "id": "1880299555557658922"
  },
  {
    "edit_history_tweet_ids": ["1880299224358875492"],
    "created_at": "2025-01-17T17:00:44.000Z",
    "text": "RT @steinkobbe: If you believe this will be reality then there's no hope for you. Elon can just make up literally anything and you'll clap‚Ä¶",
    "author_id": "821092604821536768",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880208981853155713" }],
    "id": "1880299224358875492"
  },
  {
    "edit_history_tweet_ids": ["1880299047178715244"],
    "attachments": { "media_keys": ["3_1880299043902894080"] },
    "created_at": "2025-01-17T17:00:01.000Z",
    "text": "ü§ñ üß† Build AI Agents with Persistent Memory\n\nCreate enterprise-ready LangChain React agents that remember conversations across sessions using PostgreSQL and Claude-3-haiku LLM, featuring both Python &amp; Node.js implementations.\n\nLearn more: https://t.co/mUINsGaq58 https://t.co/jM5eSJqQpR",
    "author_id": "1589007443853340672",
    "id": "1880299047178715244"
  },
  {
    "edit_history_tweet_ids": ["1880298867247505562"],
    "created_at": "2025-01-17T16:59:18.000Z",
    "text": "RT @venturetwins: 4) Turn your sketches into 3D renders with Trellis\n\nDraw or upload a sketch and turn it into an image. Then use it to ren‚Ä¶",
    "author_id": "2465283662",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880293430657724429" }],
    "id": "1880298867247505562"
  },
  {
    "edit_history_tweet_ids": ["1880298518839193652"],
    "created_at": "2025-01-17T16:57:55.000Z",
    "text": "RT @Gradio: üçä Yay! New enhancements announced to the trending Kotaemon app! \n\nüëâ Work with top daily papers using HF papers API\nüëâ Better pap‚Ä¶",
    "author_id": "2465283662",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880285593814417731" }],
    "id": "1880298518839193652"
  },
  {
    "edit_history_tweet_ids": ["1880298053602800121"],
    "created_at": "2025-01-17T16:56:04.000Z",
    "text": "RT @Eng_Hemdi: Me following the @weights_biases pages of multiple projects ( by PhD students) I am supervising to make sure all networks ar‚Ä¶",
    "author_id": "1002190113831452672",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880216229635629413" }],
    "id": "1880298053602800121"
  },
  {
    "edit_history_tweet_ids": ["1880298041472872514"],
    "created_at": "2025-01-17T16:56:01.000Z",
    "text": "In light of the 8 year Nintendo Switch run, would be interesting to see an alternate reality where Quest 2 is now $150, lighter and smaller, comes in fun colors, etc https://t.co/cZvjhkKACE",
    "author_id": "52247685",
    "referenced_tweets": [{ "type": "quoted", "id": "1880297678988537867" }],
    "id": "1880298041472872514"
  },
  {
    "edit_history_tweet_ids": ["1880297646621143096"],
    "created_at": "2025-01-17T16:54:27.000Z",
    "text": "the Who, What, Where, and Why of determining consensus reality is up in the air https://t.co/69YdMzx5oR",
    "author_id": "52247685",
    "referenced_tweets": [{ "type": "quoted", "id": "1880297247449182619" }],
    "id": "1880297646621143096"
  },
  {
    "edit_history_tweet_ids": ["1880297247449182619"],
    "created_at": "2025-01-17T16:52:52.000Z",
    "text": "There is a sense in which \"fact checking,\" when it comes not to repeatable physical measurements but to cultural and social topics, was always going to be incapable of producing perfect consensus; seems like there really should be something other than \"an authority says so\" here",
    "author_id": "966815073690730496",
    "id": "1880297247449182619"
  },
  {
    "edit_history_tweet_ids": ["1880297025813770274"],
    "created_at": "2025-01-17T16:51:59.000Z",
    "text": "RT @BraceSproul: You heard it from the man himself (Apple intelligence)\n\nTry out the Social Media Agent and relax this weekend: https://t.c‚Ä¶",
    "author_id": "951957900",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880294829869133908" }],
    "id": "1880297025813770274"
  },
  {
    "edit_history_tweet_ids": ["1880296946260406757"],
    "attachments": {
      "media_keys": [
        "3_1880296595381534720",
        "3_1880296595360477184",
        "3_1880296595381460992"
      ]
    },
    "created_at": "2025-01-17T16:51:40.000Z",
    "text": "RT @fffiloni: I‚Äôve been playing with the MangaNinja @gradio demo, you can try it now : https://t.co/d4J1ktuWtj https://t.co/j0nxjCMCQG",
    "author_id": "2465283662",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880296600616202510" }],
    "id": "1880296946260406757"
  },
  {
    "edit_history_tweet_ids": ["1880296632484512228"],
    "created_at": "2025-01-17T16:50:26.000Z",
    "text": "https://t.co/IihDttY5Zd",
    "author_id": "2975528695",
    "id": "1880296632484512228"
  },
  {
    "edit_history_tweet_ids": ["1880296476179611878"],
    "created_at": "2025-01-17T16:49:48.000Z",
    "text": "going insane i just need to fucking rest for a bit",
    "author_id": "1499415401763115019",
    "id": "1880296476179611878"
  },
  {
    "edit_history_tweet_ids": ["1880296467337998643"],
    "created_at": "2025-01-17T16:49:46.000Z",
    "text": "I must say this AI thing is kinda cool",
    "author_id": "1082912120",
    "id": "1880296467337998643"
  },
  {
    "edit_history_tweet_ids": ["1880295835113779400"],
    "created_at": "2025-01-17T16:47:15.000Z",
    "text": "Best way to move science forward is to make experiments cheaper and faster",
    "author_id": "1082912120",
    "id": "1880295835113779400"
  },
  {
    "edit_history_tweet_ids": ["1880295753668784327"],
    "created_at": "2025-01-17T16:46:56.000Z",
    "text": "RT @ArtirKel: Our Applied AI team at @RetroBio_ + some @OpenAI homies working together for a few month have created GPT4b-micro, a sequence‚Ä¶",
    "author_id": "1082912120",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880275877927481606" }],
    "id": "1880295753668784327"
  },
  {
    "edit_history_tweet_ids": ["1880295038003081319"],
    "created_at": "2025-01-17T16:44:05.000Z",
    "text": "@alexalbert__ If Claude can beat this‚Ä¶ https://t.co/s9TF6ElmxA",
    "author_id": "800854096219471872",
    "in_reply_to_user_id": "1380719534970040322",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880111092430696851" },
      { "type": "replied_to", "id": "1880294546413940927" }
    ],
    "id": "1880295038003081319"
  },
  {
    "created_at": "2025-01-17T16:43:54.000Z",
    "edit_history_tweet_ids": ["1880294988409684173"],
    "text": "RT @corbtt: Sharing an important lesson learned from working with hundreds of customers: there‚Äôs a big difference in the right way to evalu‚Ä¶",
    "author_id": "2854214132",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879628481442836845" }],
    "id": "1880294988409684173"
  },
  {
    "created_at": "2025-01-17T16:42:08.000Z",
    "edit_history_tweet_ids": ["1880294546413940927"],
    "text": "Claude's better at vague posting than most of y'all\n\nGotta step up your game https://t.co/08jq4vfLMw",
    "author_id": "1380719534970040322",
    "referenced_tweets": [{ "type": "quoted", "id": "1880096720421548461" }],
    "id": "1880294546413940927"
  },
  {
    "created_at": "2025-01-17T16:41:28.000Z",
    "edit_history_tweet_ids": ["1880294376481702198"],
    "text": "RT @fermatslibrary: 1 decillion (10¬≥¬≥) is the largest power of 10 known to humans that can be represented as the product of 2 numbers that‚Ä¶",
    "author_id": "821092604821536768",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879979219515584777" }],
    "id": "1880294376481702198"
  },
  {
    "created_at": "2025-01-17T16:41:27.000Z",
    "edit_history_tweet_ids": ["1880294372870353262"],
    "text": "Link: https://t.co/tjJVjGC7Gq\n\nAuthor: @s_scardapane",
    "author_id": "967757817355653120",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880294367338094667" }
    ],
    "id": "1880294372870353262",
    "in_reply_to_user_id": "967757817355653120"
  },
  {
    "created_at": "2025-01-17T16:41:26.000Z",
    "edit_history_tweet_ids": ["1880294367338094667"],
    "text": "Italians have been dropping alpha since a few thousand years and the world is just not paying attention. \n\nLinear layers, convolutions, transformers, recurrent networks, autograd with PyTorch and JAX code. 300 pages of alpha.\n\nThe PDF draft is free. \n\nLink in üßµ https://t.co/b1wXESFT0f",
    "author_id": "967757817355653120",
    "attachments": { "media_keys": ["3_1880294363399372800"] },
    "id": "1880294367338094667"
  },
  {
    "created_at": "2025-01-17T16:41:05.000Z",
    "edit_history_tweet_ids": ["1880294282244001877"],
    "text": "https://t.co/YzCsjyXaB8",
    "author_id": "1141052916570214400",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880294278125219890" }
    ],
    "id": "1880294282244001877",
    "in_reply_to_user_id": "1141052916570214400"
  },
  {
    "created_at": "2025-01-17T16:41:04.000Z",
    "edit_history_tweet_ids": ["1880294278125219890"],
    "text": "I built an example of how to use @AnthropicAI MCP with @AIatMeta Llama 3.3 70B. It's a simple CLI Agent managing a SQLite database in ~250 lines of code. https://t.co/UyKB5KV2zZ",
    "author_id": "1141052916570214400",
    "attachments": { "media_keys": ["3_1880294267664388096"] },
    "id": "1880294278125219890"
  },
  {
    "created_at": "2025-01-17T16:39:48.000Z",
    "edit_history_tweet_ids": ["1880293958032773556"],
    "text": "Wow. https://t.co/WWG7WJyZET",
    "author_id": "99581347",
    "referenced_tweets": [{ "type": "quoted", "id": "1880270939843359125" }],
    "id": "1880293958032773556"
  },
  {
    "created_at": "2025-01-17T16:37:18.000Z",
    "edit_history_tweet_ids": ["1880293330518700271"],
    "text": "RT @nickfloats: I‚Äôm constantly showing people AI tools and the one that continues to make people feel the most magic is @suno_ai_",
    "author_id": "1519705236713189377",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879702031595909484" }],
    "id": "1880293330518700271"
  },
  {
    "created_at": "2025-01-17T16:35:56.000Z",
    "edit_history_tweet_ids": ["1880292983830114787"],
    "text": "Anyone here know the CIO at Target? They own the cartwheel dot com domain, and I'd like to chat with them",
    "author_id": "3378986176",
    "id": "1880292983830114787"
  },
  {
    "created_at": "2025-01-17T16:35:55.000Z",
    "edit_history_tweet_ids": ["1880292979992350993"],
    "text": "@lateinteraction Seriously tho",
    "author_id": "1495078042498002950",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880291100755390808" }
    ],
    "id": "1880292979992350993",
    "in_reply_to_user_id": "1605274291569799168"
  },
  {
    "created_at": "2025-01-17T16:33:35.000Z",
    "edit_history_tweet_ids": ["1880292394073194766"],
    "text": "code here: https://t.co/IPhqFnVfRt\n\nkudos to @noahmacca for building this... these are the best ways we know of to uplevel the consistency of your voice experience",
    "author_id": "12438122",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880282744800100474" }
    ],
    "id": "1880292394073194766",
    "in_reply_to_user_id": "12438122"
  },
  {
    "created_at": "2025-01-17T16:30:49.000Z",
    "edit_history_tweet_ids": ["1880291698355630426"],
    "text": "app: https://t.co/yL4EvPFZpl",
    "author_id": "2465283662",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880291696149426340" }
    ],
    "id": "1880291698355630426",
    "in_reply_to_user_id": "2465283662"
  },
  {
    "created_at": "2025-01-17T16:30:49.000Z",
    "edit_history_tweet_ids": ["1880291696149426340"],
    "text": "MiniMax-01 Coder is now available in anychat\n\nmade a working chess game in one shot\n\ntry it out https://t.co/BbRvtumbGh",
    "author_id": "2465283662",
    "attachments": { "media_keys": ["3_1880291595259363328"] },
    "id": "1880291696149426340"
  },
  {
    "created_at": "2025-01-17T16:29:18.000Z",
    "edit_history_tweet_ids": ["1880291316271038713"],
    "text": "@shaneguML These are such lies. His startup loopt was defunct at 2012 and he was doing yc at 2014. even seq to seq was released late 2014. all the transcripts and discussions that were released indicates they created the startup with anti-google mindset feeding elon‚Äôs argument with larry‚Ä¶ https://t.co/odMFa64rjs",
    "author_id": "155933891",
    "note_tweet": {
      "text": "These are such lies. His startup loopt was defunct at 2012 and he was doing yc at 2014. even seq to seq was released late 2014. all the transcripts and discussions that were released indicates they created the startup with anti-google mindset feeding elon‚Äôs argument with larry page. the interview sama took to elon 2017, not even a single moment they used the term agi. also he wasn‚Äôt even fulltime at openai until 2019. \nat this after sometime, he will say, ‚Äúi created humanity.‚Äù"
    },
    "referenced_tweets": [
      { "type": "replied_to", "id": "1879994171974643998" }
    ],
    "id": "1880291316271038713",
    "in_reply_to_user_id": "747212842470891520"
  },
  {
    "created_at": "2025-01-17T16:28:53.000Z",
    "edit_history_tweet_ids": ["1880291212642644301"],
    "text": "Most ai frameworks arent good because the main selling point is that you can import a single line of code and just ‚Äòrun_agent_loop()‚Äô \n\nYou have 0 visibility about prompts, token usage, workflow etc. Oh you want some transparency? Here‚Äôs another library.\n\nThis isnt just for agent‚Ä¶ https://t.co/oIFhElM3uL https://t.co/x36x4o3utp",
    "author_id": "1718879852827484160",
    "note_tweet": {
      "text": "Most ai frameworks arent good because the main selling point is that you can import a single line of code and just ‚Äòrun_agent_loop()‚Äô \n\nYou have 0 visibility about prompts, token usage, workflow etc. Oh you want some transparency? Here‚Äôs another library.\n\nThis isnt just for agent stuff. There is a pretty well known RAG eval library whose entire selling point is that you run a single function with the names of the metrics you want. The only way to figure out what each metric is doing is to look at source."
    },
    "referenced_tweets": [{ "type": "quoted", "id": "1880275616030945699" }],
    "id": "1880291212642644301"
  },
  {
    "created_at": "2025-01-17T16:28:27.000Z",
    "edit_history_tweet_ids": ["1880291100755390808"],
    "text": "The way in which we‚Äôre so bad at interviewing doesn‚Äôt bode well for ML evaluation. https://t.co/25vjWsAP41",
    "author_id": "1605274291569799168",
    "referenced_tweets": [{ "type": "quoted", "id": "1880286817783894109" }],
    "id": "1880291100755390808"
  },
  {
    "created_at": "2025-01-17T16:20:34.000Z",
    "edit_history_tweet_ids": ["1880289118212755846"],
    "text": "2025 is the year AI becomes background technology. People will quietly use LLMs every day to write, research and discuss what they care about. ASI debate is so 2024.",
    "author_id": "560473379",
    "id": "1880289118212755846"
  },
  {
    "created_at": "2025-01-17T16:20:24.000Z",
    "edit_history_tweet_ids": ["1880289074113835394"],
    "text": "nope https://t.co/eq4ngS4T3I",
    "author_id": "1718879852827484160",
    "referenced_tweets": [{ "type": "quoted", "id": "1880284748897239104" }],
    "id": "1880289074113835394"
  },
  {
    "created_at": "2025-01-17T16:15:24.000Z",
    "edit_history_tweet_ids": ["1880287818230202499"],
    "text": "@huggingface @PyTorch The example with gradient accumulation is available here: https://t.co/tLrEJKy6t0",
    "author_id": "721018777664626688",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880286685000253623" }
    ],
    "id": "1880287818230202499",
    "in_reply_to_user_id": "721018777664626688"
  },
  {
    "created_at": "2025-01-17T16:12:17.000Z",
    "edit_history_tweet_ids": ["1880287031718482357"],
    "text": "I‚Äôm glad i got some great followers before the dead internet lol https://t.co/NpvlRZud4h",
    "author_id": "1365020011123773442",
    "referenced_tweets": [{ "type": "quoted", "id": "1879927553051541862" }],
    "id": "1880287031718482357"
  },
  {
    "created_at": "2025-01-17T16:11:29.000Z",
    "edit_history_tweet_ids": ["1880286830836477984"],
    "text": "anyway, full article is here: \n\nhttps://t.co/JzG5yoYDgF\n\nPlease let me know if you disagree!",
    "author_id": "1495078042498002950",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880286826440925311" }
    ],
    "id": "1880286830836477984",
    "in_reply_to_user_id": "1495078042498002950"
  },
  {
    "created_at": "2025-01-17T16:11:28.000Z",
    "edit_history_tweet_ids": ["1880286826440925311"],
    "text": "Another trick I like is to do the anti-sell, where you tell the candidate all the reasons they might not want to work for you. for instance, ‚Äúwe don‚Äôt publish papers.‚Äù",
    "author_id": "1495078042498002950",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880286822301069352" }
    ],
    "id": "1880286826440925311",
    "in_reply_to_user_id": "1495078042498002950"
  },
  {
    "created_at": "2025-01-17T16:11:27.000Z",
    "edit_history_tweet_ids": ["1880286822301069352"],
    "text": "I also like interview questions centered around ambiguity: ‚ÄúI tried a new idea to make our model better. It didn‚Äôt work. What should I do?‚Äù \n\nThis is, basically, the job, as you‚Äôll spend a lot of time debugging experiments with your coworkers",
    "author_id": "1495078042498002950",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880286817783894109" }
    ],
    "id": "1880286822301069352",
    "in_reply_to_user_id": "1495078042498002950"
  },
  {
    "created_at": "2025-01-17T16:11:26.000Z",
    "edit_history_tweet_ids": ["1880286817783894109"],
    "text": "wrote up some thoughts on hiring ml researchers/engineers\n\nhigh level: do work sample tests and keep a high bar \n\nBasically, figure out what the job will be like, and make the interview questions as close to that as possible\n\nNumerical coding is good for this, leetcode less so",
    "author_id": "1495078042498002950",
    "id": "1880286817783894109"
  },
  {
    "created_at": "2025-01-17T16:11:18.000Z",
    "edit_history_tweet_ids": ["1880286787408646362"],
    "text": "@huggingface @PyTorch Full release notes are available here: https://t.co/Ku1OtzxhWV",
    "author_id": "721018777664626688",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880286685000253623" }
    ],
    "id": "1880286787408646362",
    "in_reply_to_user_id": "721018777664626688"
  },
  {
    "created_at": "2025-01-17T16:10:54.000Z",
    "edit_history_tweet_ids": ["1880286685000253623"],
    "text": "It's been a bit! How does a new @huggingface accelerate release sound?\n\nv1.3.0 is now out, with a few small changes:\n\n* @PyTorch 2.0.0 is now the minimum we support, goodbye &lt;2.0!\n\n* We have a new example on how to properly do gradient accumulation with LM's!\n\n* Many bugfixes https://t.co/Nv7ZSD95fR https://t.co/Ih6bailSeT",
    "author_id": "721018777664626688",
    "note_tweet": {
      "text": "It's been a bit! How does a new @huggingface accelerate release sound?\n\nv1.3.0 is now out, with a few small changes:\n\n* @PyTorch 2.0.0 is now the minimum we support, goodbye <2.0!\n\n* We have a new example on how to properly do gradient accumulation with LM's!\n\n* Many bugfixes",
      "entities": {
        "mentions": [
          {
            "start": 32,
            "end": 44,
            "username": "huggingface",
            "id": "778764142412984320"
          },
          {
            "start": 120,
            "end": 128,
            "username": "PyTorch",
            "id": "776585502606721024"
          }
        ]
      }
    },
    "attachments": { "media_keys": ["3_1880286317105344513"] },
    "id": "1880286685000253623"
  },
  {
    "created_at": "2025-01-17T16:07:49.000Z",
    "edit_history_tweet_ids": ["1880285910774005808"],
    "text": "RT @YoheiNishitsuji: #„Å§„Å∂„ÇÑ„ÅçGLSL float i,e,R,s;vec3 q,p,d=vec3(FC.xy/r-vec2(.5,-.3),1);for(q.zy--;i++&lt;99.;){o.rgb+=hsv(.1,.2,min(e*s,.65-e)/4‚Ä¶",
    "author_id": "7284012",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880163156741275732" }],
    "id": "1880285910774005808"
  },
  {
    "created_at": "2025-01-17T16:06:31.000Z",
    "edit_history_tweet_ids": ["1880285582464893129"],
    "text": "If you want to take it a step further you can check out my new courses on building with LLMs, RAGs, and AI Agents here: https://t.co/gKtLjAStAu\n\nI believe it compliments the book well.",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880284480465957130" }
    ],
    "id": "1880285582464893129",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T16:06:06.000Z",
    "edit_history_tweet_ids": ["1880285476252446867"],
    "text": "RT @llamafactory_ai: Fine-tune Llama-3 on this Gradio web UI at Colab: https://t.co/io0oDCnN5Y",
    "author_id": "2465283662",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880285127974220068" }],
    "id": "1880285476252446867"
  },
  {
    "created_at": "2025-01-17T16:05:47.000Z",
    "edit_history_tweet_ids": ["1880285395935719734"],
    "text": "We're kicking off 2025 with another Compound AI System Meetup with @lancedb in Mountain View on Jan 22! üéâ Join us for a deep dive into AI infrastructure and insights with Lu Qiu, Allison Wang, Holden Karau, and Dr. Sharon Zhou. üîóSave your spot: https://t.co/Q9sOGaIElJ",
    "author_id": "1335773237683240960",
    "id": "1880285395935719734"
  },
  {
    "created_at": "2025-01-17T16:03:37.000Z",
    "edit_history_tweet_ids": ["1880284850516885865"],
    "text": "@teortaxesTex R1 couldn‚Äôt have been trained from distillation in oai anyways so their claim to fame these days isn‚Äôt even in question either fwiw",
    "author_id": "1365020011123773442",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880011182452666424" }
    ],
    "id": "1880284850516885865",
    "in_reply_to_user_id": "192201556"
  },
  {
    "created_at": "2025-01-17T16:02:08.000Z",
    "edit_history_tweet_ids": ["1880284480465957130"],
    "text": "find it here: https://t.co/K2HiBz1cbn",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880284477445767586" }
    ],
    "id": "1880284480465957130",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T16:02:08.000Z",
    "edit_history_tweet_ids": ["1880284477445767586"],
    "text": "Foundations of LLMs\n\nThis amazing new LLM book just dropped on arXiv. \n\n200+ pages!\n\nIt covers areas such as pre-training, prompting, and alignment methods. \n\nIt looks like a great intro to LLMs for devs and researchers. https://t.co/aw2EQT7EsC https://t.co/keIf9Lqcd4",
    "author_id": "3448284313",
    "note_tweet": {
      "text": "Foundations of LLMs\n\nThis amazing new LLM book just dropped on arXiv. \n\n200+ pages!\n\nIt covers areas such as pre-training, prompting, and alignment methods. \n\nIt looks like a great intro to LLMs for devs and researchers."
    },
    "attachments": { "media_keys": ["3_1880284392557301760"] },
    "id": "1880284477445767586"
  },
  {
    "created_at": "2025-01-17T16:00:10.000Z",
    "edit_history_tweet_ids": ["1880283982455259294"],
    "text": "RT @CIFAR_News: Canada CIFAR AI Chairs @Yoshua_Bengio and @ghadfield discuss the risks associated with AI agents in @ScientificAmerican, hi‚Ä¶",
    "author_id": "1831398480700428289",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880277949796216924" }],
    "id": "1880283982455259294"
  },
  {
    "note_tweet": {
      "entities": {
        "urls": [
          {
            "start": 401,
            "end": 424,
            "url": "https://t.co/9RrY7wm6L8",
            "expanded_url": "https://memgraph.com/blog/integrating-memgraph-llamaindex-genai-apps",
            "display_url": "memgraph.com/blog/integrati‚Ä¶"
          }
        ],
        "mentions": [
          {
            "start": 10,
            "end": 21,
            "username": "memgraphdb",
            "id": "735566660480970752"
          }
        ]
      },
      "text": "Learn how @memgraphdb and LlamaIndex work together to build agentic graph applications!\n\nKey takeaways from our recent webinar:\nüîç Explore GraphRAG for improved context retrieval in generative AI workflows\nü§ñ Discover agentic strategies to enhance RAG pipelines\nüöÄ See how Memgraph complements LlamaIndex in constructing and querying knowledge graphs\n\nRead the full recap or watch the webinar recording:\nhttps://t.co/9RrY7wm6L8"
    },
    "created_at": "2025-01-17T15:58:50.000Z",
    "edit_history_tweet_ids": ["1880283649033269712"],
    "text": "Learn how @memgraphdb and LlamaIndex work together to build agentic graph applications!\n\nKey takeaways from our recent webinar:\nüîç Explore GraphRAG for improved context retrieval in generative AI workflows\nü§ñ Discover agentic strategies to enhance RAG pipelines\nüöÄ See how‚Ä¶ https://t.co/a4SMTY5pC3 https://t.co/PaK8dt1m9y",
    "author_id": "1604278358296055808",
    "attachments": { "media_keys": ["3_1880283641470939137"] },
    "id": "1880283649033269712"
  },
  {
    "created_at": "2025-01-17T15:57:52.000Z",
    "edit_history_tweet_ids": ["1880283406187249704"],
    "text": "Yep https://t.co/QR2mIVSbmD",
    "author_id": "1365020011123773442",
    "referenced_tweets": [{ "type": "quoted", "id": "1880142612927246460" }],
    "id": "1880283406187249704"
  },
  {
    "created_at": "2025-01-17T15:56:22.000Z",
    "edit_history_tweet_ids": ["1880283028364358127"],
    "text": "paper: https://t.co/kQPsNc4QEd",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880283025595867631" }
    ],
    "id": "1880283028364358127",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:56:21.000Z",
    "edit_history_tweet_ids": ["1880283025595867631"],
    "text": "LLM and agents are still brittle but many researchers are already experimenting with them in different areas of medicine including mental health care. \n\nHere is an example of a new paper that proposes a multi-agent framework, AutoCBT, for Cognitive Behavioral Therapy.\n\nThe work‚Ä¶ https://t.co/9U318LAuLW https://t.co/87dJu3JM2x",
    "author_id": "3448284313",
    "note_tweet": {
      "text": "LLM and agents are still brittle but many researchers are already experimenting with them in different areas of medicine including mental health care. \n\nHere is an example of a new paper that proposes a multi-agent framework, AutoCBT, for Cognitive Behavioral Therapy.\n\nThe work proposes a general multi-agent framework that generates high-quality responses for single-turn psychological consultation scenarios.\n\nIt uses a combination of dynamic routing, memory, and supervisory mechanisms to enhance the autonomous ability of each agent.\n\nExperimental results show that AutoCBT can provide higher-quality automated psychological counseling services. AutoCBT improves dialogue quality compared to other purely prompt-based counseling frameworks."
    },
    "attachments": { "media_keys": ["3_1880278467838615552"] },
    "id": "1880283025595867631"
  },
  {
    "created_at": "2025-01-17T15:55:14.000Z",
    "edit_history_tweet_ids": ["1880282744800100474"],
    "text": "we shipped a üíé yesterday: a repo for building Realtime API voice agents with orchestration, handoffs, escalation and prompting best practices \n\n e.g. devs often under-specify the voice behavior they want. Here's a good voice prompt https://t.co/G2DJS55imL",
    "author_id": "12438122",
    "attachments": { "media_keys": ["3_1880282681994297344"] },
    "id": "1880282744800100474"
  },
  {
    "created_at": "2025-01-17T15:52:37.000Z",
    "edit_history_tweet_ids": ["1880282084629180515"],
    "text": "Pixel 9 Pro is a really good phone. I bought it to test a new thing we‚Äôre working on. And realized the phone‚Äôs really well made that it doesn‚Äôt feel I‚Äôm not using something IPhone quality.",
    "author_id": "759894532649545732",
    "id": "1880282084629180515"
  },
  {
    "created_at": "2025-01-17T15:48:01.000Z",
    "edit_history_tweet_ids": ["1880280926724280418"],
    "text": "A few notes on Frames:\n\n- Frames has been engineered from the ground up for professional creative work. If you're in editorial, art direction, pre-vis, brand development, production, etc., this model is for you.\n- The prompting system has been designed for precision and depth. It‚Ä¶ https://t.co/JOBCkFzYI8 https://t.co/v5EQOvxmqf",
    "author_id": "788107483306942464",
    "note_tweet": {
      "text": "A few notes on Frames:\n\n- Frames has been engineered from the ground up for professional creative work. If you're in editorial, art direction, pre-vis, brand development, production, etc., this model is for you.\n- The prompting system has been designed for precision and depth. It may take some initial exploration to master it. The more precise your input, the more nuanced your results will be.\n- Frames excels in understanding the subtleties that define good work: advanced texture rendering, natural lighting behavior, and thoughtful/interesting compositions. A big move beyond the rigid, symmetrical outputs you might be used to. Frames creates more naturalistic, cinematically composed results.\n- Frames has been optimized for creative exploration and artistic discovery, producing more nuanced and interesting creative results.\n- The model has been developed in close collaboration with our Studio team, ensuring it meets real-world professional standards.\n- This is our first public release of Frames. This is Frames v1. We have a clear roadmap for future developments, including enhanced controllability features and expanded style tools.\n- If you have any notes or feedback points, we would love to hear them."
    },
    "referenced_tweets": [{ "type": "quoted", "id": "1880269616204976219" }],
    "id": "1880280926724280418"
  },
  {
    "created_at": "2025-01-17T15:44:18.000Z",
    "edit_history_tweet_ids": ["1880279991927370224"],
    "text": "when your job title is prompt engineer https://t.co/33jzd2TOHJ",
    "author_id": "1972029110",
    "attachments": { "media_keys": ["3_1880279968497954817"] },
    "id": "1880279991927370224"
  },
  {
    "created_at": "2025-01-17T15:43:14.000Z",
    "edit_history_tweet_ids": ["1880279722531385565"],
    "text": "https://t.co/FU7X78mzQY",
    "author_id": "1583730714",
    "attachments": {
      "media_keys": ["3_1880279672623108096", "3_1880279717367967744"]
    },
    "id": "1880279722531385565"
  },
  {
    "created_at": "2025-01-17T15:43:07.000Z",
    "edit_history_tweet_ids": ["1880279693565595761"],
    "text": "RT @Gradio: ‚ö°Ô∏è JUST DROPPED: Create custom AI voices in seconds!\n\n&gt; Mix multiple voices\n&gt; Zero coding needed\n&gt; Intuitive &amp; slick UI with vo‚Ä¶",
    "author_id": "2465283662",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880277761618546929" }],
    "id": "1880279693565595761"
  },
  {
    "created_at": "2025-01-17T15:42:44.000Z",
    "edit_history_tweet_ids": ["1880279596287017227"],
    "text": "arccelerate https://t.co/YIJBWhXYNu",
    "author_id": "1972029110",
    "referenced_tweets": [{ "type": "quoted", "id": "1879583863368032432" }],
    "id": "1880279596287017227"
  },
  {
    "created_at": "2025-01-17T15:40:35.000Z",
    "edit_history_tweet_ids": ["1880279057952305353"],
    "text": "RT @_clashluke: Which optimizer converges best?\n\nThis is a blind study where we only look at the decision boundary during training.",
    "author_id": "2236047510",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880042358655578119" }],
    "id": "1880279057952305353"
  },
  {
    "created_at": "2025-01-17T15:38:19.000Z",
    "edit_history_tweet_ids": ["1880278484381233454"],
    "text": "RT @CohereForAI: Reminder that tomorrow, January 18th, @yuntiandeng, Assistant Professor at University of Waterloo will present \"Implicit C‚Ä¶",
    "author_id": "731538535795163136",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880270600276701457" }],
    "id": "1880278484381233454"
  },
  {
    "created_at": "2025-01-17T15:37:46.000Z",
    "edit_history_tweet_ids": ["1880278346921304476"],
    "text": "Interesting‚Ä¶Figure top 10 https://t.co/20O77beY5v",
    "author_id": "3222018178",
    "referenced_tweets": [{ "type": "quoted", "id": "1880006770476655056" }],
    "id": "1880278346921304476"
  },
  {
    "created_at": "2025-01-17T15:30:50.000Z",
    "edit_history_tweet_ids": ["1880276603827376418"],
    "text": "@nrehiew_ ok, I‚Äôm waiting",
    "author_id": "800854096219471872",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880120090483650767" }
    ],
    "id": "1880276603827376418",
    "in_reply_to_user_id": "1718879852827484160"
  },
  {
    "created_at": "2025-01-17T15:27:54.000Z",
    "edit_history_tweet_ids": ["1880275864384127230"],
    "text": "paper: https://t.co/skPVOR48vo",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880275861401923619" }
    ],
    "id": "1880275864384127230",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:27:53.000Z",
    "edit_history_tweet_ids": ["1880275861401923619"],
    "text": "OmniThink is a new framework that emulates a human-like process of iterative expansion and reflection. \n\nIt's built to simulate the cognitive behavior of learners as they deepen their knowledge. \n\nCompared to RAG and role-playing, OmniThink can expand knowledge boundaries through‚Ä¶ https://t.co/52MwdzeYpd https://t.co/KVt3sbsgNn",
    "author_id": "3448284313",
    "note_tweet": {
      "text": "OmniThink is a new framework that emulates a human-like process of iterative expansion and reflection. \n\nIt's built to simulate the cognitive behavior of learners as they deepen their knowledge. \n\nCompared to RAG and role-playing, OmniThink can expand knowledge boundaries through continuous reflection and exploration. This makes it ideal for use cases that require long-form generation."
    },
    "attachments": { "media_keys": ["3_1880274457945612288"] },
    "id": "1880275861401923619"
  },
  {
    "created_at": "2025-01-17T15:24:52.000Z",
    "edit_history_tweet_ids": ["1880275099691135413"],
    "text": "in this case, it was: ‚Äúthe central limit theorem, which says that the sample mean is close to the population mean, makes two assumptions: the population distribution is roughly normal and there‚Äôs at least 30 samples‚Äù",
    "author_id": "1374206341397377026",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880274418578125107" }
    ],
    "id": "1880275099691135413",
    "in_reply_to_user_id": "1374206341397377026"
  },
  {
    "created_at": "2025-01-17T15:24:18.000Z",
    "edit_history_tweet_ids": ["1880274958066286794"],
    "text": "RT @igrgavilan: I've just finished \"Hands-On Large Language Models: Language Understanding and Generation\" (https://t.co/KVcu8ZPOgb) by @Ja‚Ä¶",
    "author_id": "1245260977626587136",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880180503132905974" }],
    "id": "1880274958066286794"
  },
  {
    "created_at": "2025-01-17T15:22:55.000Z",
    "edit_history_tweet_ids": ["1880274610064871904"],
    "text": "@cognitivecompai @AnthropicAI @OpenAI @GoogleDeepMind Its just basic tool calling. There is no MCP Magic. Each \"MCP\" tool is converted into a JSON schema you pass when making a call. The better a LLM is in tool calling the better it will work with MCP servers.",
    "author_id": "1141052916570214400",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880273494652678478" }
    ],
    "id": "1880274610064871904",
    "in_reply_to_user_id": "2854214132"
  },
  {
    "created_at": "2025-01-17T15:22:09.000Z",
    "edit_history_tweet_ids": ["1880274418578125107"],
    "text": "podcasts are a great way to pick a side on empirical disputes in fields that you know nothing about because you can see an expert on one side make basic mistakes in things you know about in off the cuff comments and then discount everything they say.",
    "author_id": "1374206341397377026",
    "id": "1880274418578125107"
  },
  {
    "created_at": "2025-01-17T15:19:46.000Z",
    "edit_history_tweet_ids": ["1880273815567315257"],
    "text": "https://t.co/BSVTGqQPys",
    "author_id": "1202267633049100291",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880273723661353436" }
    ],
    "id": "1880273815567315257",
    "in_reply_to_user_id": "1202267633049100291"
  },
  {
    "created_at": "2025-01-17T15:19:24.000Z",
    "edit_history_tweet_ids": ["1880273723661353436"],
    "text": "Everything that happened this week in open AI, a recap ü§†\n\nüëÄ Multimodal\n- MiniCPM-o 2.6 is a new sota any-to-any model by @OpenBMB  (vision, speech and text!)\n- VideoChat-Flash-Qwen2.5-2B is new video multimodal models by @opengvlab that come in sizes 2B &amp; 7B in resolutions 224‚Ä¶ https://t.co/OjYHYogtVn https://t.co/hkBlJxXYKj",
    "author_id": "1202267633049100291",
    "note_tweet": {
      "text": "Everything that happened this week in open AI, a recap ü§†\n\nüëÄ Multimodal\n- MiniCPM-o 2.6 is a new sota any-to-any model by @OpenBMB  (vision, speech and text!)\n- VideoChat-Flash-Qwen2.5-2B is new video multimodal models by @opengvlab that come in sizes 2B & 7B in resolutions 224 & 448\n-  @BytedanceTalk released larger SA2VA that comes in 26B parameters\n- Dataset: VRC-Bench is a new diverse benchmark for multimodal LLM reasoning performance\n\nüí¨ LLMs\n- MiniMax-Text-01 is a new huge language model (456B passive 45.9B active params) by MiniMaxAI with context length of 4M tokens ü§Ø\n- Dataset: Sky-T1-data-17k is a diverse dataset used to train Sky-T1-32B\n- @kyutai_labs released Helium-1-Preview-2B is a new small multilingual LM\n- Wayfarer-12B is a new LLM able to write D&D üßôüèª‚Äç‚ôÇÔ∏è\n- ReaderLM-v2 is a new HTML parsing model by @JinaAI_  \n- @driaforall released, Dria-Agent-a-3B, new agentic coding model (Pythonic function calling) based on Qwen2.5 Coder\n- @UnslothAI released Phi-4, faster and memory efficient Llama 3.3\n\nüñºÔ∏è Vision\n- MatchAnything is a new foundation model for matching\n- FitDit is a high-fidelity VTON model based on DiT architecture\n\nüó£Ô∏è Audio\n- OuteTTS-0.3-1B is a new multilingual text-to-speech model with voice cloning and emotion control capabilities\n\nüìñ Retrieval\n- lightblue released a new reranker based on Qwen2.5 LB-reranker-0.5B-v1.0 that can handle 95+ languages\n- cde-small-v2 is a new sota small retrieval model by @jxmnop",
      "entities": {
        "mentions": [
          {
            "start": 121,
            "end": 129,
            "username": "OpenBMB",
            "id": "1496119294844825600"
          },
          {
            "start": 221,
            "end": 231,
            "username": "opengvlab",
            "id": "1610948392489979904"
          },
          {
            "start": 287,
            "end": 301,
            "username": "BytedanceTalk",
            "id": "749868630221828096"
          },
          {
            "start": 655,
            "end": 667,
            "username": "kyutai_labs",
            "id": "1723735413578219520"
          },
          {
            "start": 825,
            "end": 833,
            "username": "JinaAI_",
            "id": "1245077804426952704"
          },
          {
            "start": 838,
            "end": 849,
            "username": "driaforall",
            "id": "1741850179068678144"
          },
          {
            "start": 955,
            "end": 965,
            "username": "UnslothAI",
            "id": "1730159888402395136"
          },
          {
            "start": 1445,
            "end": 1452,
            "username": "jxmnop",
            "id": "783098774130401280"
          }
        ]
      }
    },
    "attachments": { "media_keys": ["3_1880273055651377152"] },
    "id": "1880273723661353436"
  },
  {
    "created_at": "2025-01-17T15:18:29.000Z",
    "edit_history_tweet_ids": ["1880273494652678478"],
    "text": "@_philschmid @AnthropicAI @OpenAI @GoogleDeepMind I really want a dataset which is a recording of claude interacting with a variety of different MCP servers, that can be used to train open source models to do MCP more accurately.",
    "author_id": "2854214132",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880271537212657922" }
    ],
    "id": "1880273494652678478",
    "in_reply_to_user_id": "1141052916570214400"
  },
  {
    "created_at": "2025-01-17T15:18:14.000Z",
    "edit_history_tweet_ids": ["1880273430601429004"],
    "text": "summary: just fucking do things https://t.co/kxrI7Q1SXk",
    "author_id": "874987512850128897",
    "referenced_tweets": [{ "type": "quoted", "id": "1880268394525782522" }],
    "id": "1880273430601429004"
  },
  {
    "created_at": "2025-01-17T15:15:28.000Z",
    "edit_history_tweet_ids": ["1880272736184098828"],
    "text": "CEO vs CTO https://t.co/c5PZrTENpv",
    "author_id": "1007413134",
    "attachments": { "media_keys": ["3_1880272733428424704"] },
    "id": "1880272736184098828"
  },
  {
    "created_at": "2025-01-17T15:13:15.000Z",
    "edit_history_tweet_ids": ["1880272178324910532"],
    "text": "@AnthropicAI @AIatMeta Code is now available: https://t.co/MyAmD7ZTm2",
    "author_id": "1141052916570214400",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880271537212657922" },
      { "type": "replied_to", "id": "1877723808376795206" }
    ],
    "id": "1880272178324910532",
    "in_reply_to_user_id": "1141052916570214400"
  },
  {
    "created_at": "2025-01-17T15:10:43.000Z",
    "edit_history_tweet_ids": ["1880271539712692614"],
    "text": "Blog: https://t.co/YzCsjyXaB8",
    "author_id": "1141052916570214400",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880271537212657922" }
    ],
    "id": "1880271539712692614",
    "in_reply_to_user_id": "1141052916570214400"
  },
  {
    "created_at": "2025-01-17T15:10:42.000Z",
    "edit_history_tweet_ids": ["1880271537212657922"],
    "text": "Learn how to leverage @AnthropicAI's Model Context Protocol (MCP) to build modular AI agents using open LLMs, @OpenAI, or @GoogleDeepMind Gemini! üëÄ¬†\nExcited to publish an example of how to build a simple CLI Agent that manages an SQLite database using an Anthropic MCP server and‚Ä¶ https://t.co/A9Hehivnsw https://t.co/MlksbyZhNz",
    "author_id": "1141052916570214400",
    "note_tweet": {
      "text": "Learn how to leverage @AnthropicAI's Model Context Protocol (MCP) to build modular AI agents using open LLMs, @OpenAI, or @GoogleDeepMind Gemini! üëÄ¬†\nExcited to publish an example of how to build a simple CLI Agent that manages an SQLite database using an Anthropic MCP server and @AIatMeta Llama 3.3 70B.\n\nTL;DR:\nüîÑ How MCP decouples AI agent components for better maintainability\nüõ†Ô∏è Setting up a Docker-based MCP Server with SQLite\nüîå Implementing a client that works with any LLM API (OpenAI, Gemini, open LLMs)\nüì¶ Building an interactive CLI agent managing SQLite database operations\nü§ñ Converting MCP tools into LLM-compatible function calls\nüìù Single file < 250 lines of code\n\nI am working on a small toolkit that makes building agents with an MCP server even easier! Stay tuned for that. üöÄ",
      "entities": {
        "mentions": [
          {
            "start": 22,
            "end": 34,
            "username": "AnthropicAI",
            "id": "1353836358901501952"
          },
          {
            "start": 110,
            "end": 117,
            "username": "OpenAI",
            "id": "4398626122"
          },
          {
            "start": 122,
            "end": 137,
            "username": "GoogleDeepMind",
            "id": "4783690002"
          },
          {
            "start": 280,
            "end": 289,
            "username": "AIatMeta",
            "id": "1034844617261248512"
          }
        ]
      }
    },
    "attachments": { "media_keys": ["3_1880271189995565056"] },
    "id": "1880271537212657922"
  },
  {
    "created_at": "2025-01-17T15:06:44.000Z",
    "edit_history_tweet_ids": ["1880270539299983638"],
    "text": "RT @runwayml: Today we are releasing Frames. Our most advanced base model for image generation, offering unprecedented stylistic control an‚Ä¶",
    "author_id": "788107483306942464",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880269616204976219" }],
    "id": "1880270539299983638"
  },
  {
    "created_at": "2025-01-17T15:06:22.000Z",
    "edit_history_tweet_ids": ["1880270444273811663"],
    "text": "RT @akshay_pachaar: I just created a RAG app to chat with GitHub!\n\nIt runs 100% locally, powered by Llama3.2 and uses GitIngest for parsing‚Ä¶",
    "author_id": "369777416",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880231619241668666" }],
    "id": "1880270444273811663"
  },
  {
    "created_at": "2025-01-17T15:03:20.000Z",
    "edit_history_tweet_ids": ["1880269680985981434"],
    "text": "Share below if you have seen other interesting readings.",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880269677630484878" }
    ],
    "id": "1880269680985981434",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:19.000Z",
    "edit_history_tweet_ids": ["1880269677630484878"],
    "text": "Lastly, I would like to plug my new course on coding with Cursor where I share my own experience on coding with LLMs, and how to leverage features like Composer agents and Chat completions for building web applications. \n\nhttps://t.co/HGFIRDWo7m https://t.co/iT3fKfpj2y",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880269674442879032" }
    ],
    "attachments": { "media_keys": ["3_1880267787668500481"] },
    "id": "1880269677630484878",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:18.000Z",
    "edit_history_tweet_ids": ["1880269674442879032"],
    "text": "Folks at Answer AI wrote about their experience and impressions with Devin after trying 20+ tasks. \n\nhttps://t.co/uIhFKcdYyb https://t.co/uZgGr9dUsD",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880269672156721448" }
    ],
    "attachments": { "media_keys": ["3_1880266810169139200"] },
    "id": "1880269674442879032",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:18.000Z",
    "edit_history_tweet_ids": ["1880269672156721448"],
    "text": "Yifan recently wrote about test-driven development with LLMs. \n\nhttps://t.co/Wxq3dbpdMh https://t.co/o9th4oVz3S",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880269669552255045" }
    ],
    "attachments": { "media_keys": ["3_1880266467888816128"] },
    "id": "1880269672156721448",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:17.000Z",
    "edit_history_tweet_ids": ["1880269669552255045"],
    "text": "This article showcases some use cases for generalist software development agents with OpenHands. Prompt examples are provided. \n\nhttps://t.co/GnFQ04Pon4 https://t.co/5k2l8TcvJQ",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880269666649854329" }
    ],
    "attachments": { "media_keys": ["3_1880264141677498368"] },
    "id": "1880269669552255045",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:16.000Z",
    "edit_history_tweet_ids": ["1880269666649854329"],
    "text": "David Crawshaw writes about his experience programming with LLMs and their potential for improving productivity. \n\nabout https://t.co/hAdIuSACq8",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880269663902527903" }
    ],
    "attachments": { "media_keys": ["3_1880265530927370240"] },
    "id": "1880269666649854329",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:16.000Z",
    "edit_history_tweet_ids": ["1880269663902527903"],
    "text": "David Andersen goes deeper into the potential of LLMs to optimize code. \n\nhttps://t.co/NJk4cUIC6d https://t.co/5N8rGARyU8",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880269661109121134" }
    ],
    "attachments": { "media_keys": ["3_1880265960780656640"] },
    "id": "1880269663902527903",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:15.000Z",
    "edit_history_tweet_ids": ["1880269661109121134"],
    "text": "Max Woolf found that prompting LLMs with \"write better code\" leads to interesting code improvements. \n\nhttps://t.co/pS3SCHYIMX https://t.co/dDklm7JFVc",
    "author_id": "3448284313",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880269659070689496" }
    ],
    "attachments": { "media_keys": ["3_1880264515327053824"] },
    "id": "1880269661109121134",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:15.000Z",
    "edit_history_tweet_ids": ["1880269659070689496"],
    "text": "Lots of devs sharing how to code with AI and agents.\n\nUse cases range from basic code optimization to test-driven development. \n\nHere are a few interesting resources:\n\n(bookmark for later)",
    "author_id": "3448284313",
    "id": "1880269659070689496"
  },
  {
    "created_at": "2025-01-17T14:54:22.000Z",
    "edit_history_tweet_ids": ["1880267423104065626"],
    "text": "RT @garrytan: Prompt (agency) and evals (taste) will rule everything around us",
    "author_id": "1583730714",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880265088218853558" }],
    "id": "1880267423104065626"
  },
  {
    "created_at": "2025-01-17T14:45:52.000Z",
    "edit_history_tweet_ids": ["1880265286601043984"],
    "text": "RT @pandeyparul: And creating engaging games that help kids learn concepts\nhttps://t.co/TbiV8lkAX0",
    "author_id": "2465283662",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880265006694166768" }],
    "id": "1880265286601043984"
  },
  {
    "created_at": "2025-01-17T14:45:43.000Z",
    "edit_history_tweet_ids": ["1880265247023591535"],
    "text": "RT @pandeyparul: My experimentation with AI tools for education continues.\nHere‚Äôs another use case I‚Äôve tried with Gemini using its real-ti‚Ä¶",
    "author_id": "2465283662",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880265001811988508" }],
    "id": "1880265247023591535"
  },
  {
    "created_at": "2025-01-17T14:44:40.000Z",
    "edit_history_tweet_ids": ["1880264982027448719"],
    "text": "it's time",
    "author_id": "788107483306942464",
    "id": "1880264982027448719"
  },
  {
    "created_at": "2025-01-17T14:43:50.000Z",
    "edit_history_tweet_ids": ["1880264772979154957"],
    "text": "RT @stalkermustang: btw o3-mini access is out for (at least some) testers\n\nthought there are two models, and it seems OpenAI wasn't losing‚Ä¶",
    "author_id": "1513853205125681162",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880246516599910641" }],
    "id": "1880264772979154957"
  },
  {
    "created_at": "2025-01-17T14:43:33.000Z",
    "edit_history_tweet_ids": ["1880264702498074709"],
    "text": "RT @llamafactory_ai: üöÄLLaMA Factory has been migrated to @Gradio 5!\nEnjoy the modern design of both light &amp; dark style.\n\nThank the Gradio t‚Ä¶",
    "author_id": "2465283662",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880226201341686053" }],
    "id": "1880264702498074709"
  },
  {
    "created_at": "2025-01-17T14:36:02.000Z",
    "edit_history_tweet_ids": ["1880262813345804647"],
    "text": "RT @DipendraMisra: 1/n Looking to do research in frontier models that make a real-world impact? Our team at Databricks is hiring strong res‚Ä¶",
    "author_id": "2239670346",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879568823877312615" }],
    "id": "1880262813345804647"
  },
  {
    "created_at": "2025-01-17T14:26:44.000Z",
    "edit_history_tweet_ids": ["1880260471825338458"],
    "text": "RT @chrisfirsttt: It‚Äôs crazy how instantly different @runwayframes feels compared to ANY other image generator right now.\n\nIt‚Äôs cinematic a‚Ä¶",
    "author_id": "788107483306942464",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880098047994290621" }],
    "id": "1880260471825338458"
  },
  {
    "created_at": "2025-01-17T14:19:01.000Z",
    "edit_history_tweet_ids": ["1880258527098466568"],
    "text": "I have experienced this first hand when I asked it to make my code more parallel and it ended up removing all the semaphores https://t.co/neF4cV5MTX",
    "author_id": "1513853205125681162",
    "referenced_tweets": [{ "type": "quoted", "id": "1880078959762903498" }],
    "id": "1880258527098466568"
  },
  {
    "created_at": "2025-01-17T14:18:24.000Z",
    "edit_history_tweet_ids": ["1880258374971048434"],
    "text": "if you intend to de-indoctrinate them, do observe that in no way are their beliefs dependent on your silly little  taboo reddit facts and gasps. Theose only matter for automatic filters. https://t.co/T6mwXfnBuz https://t.co/GV9Ma7jud9",
    "author_id": "192201556",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880186351729156137" },
      { "type": "replied_to", "id": "1880257308158226921" }
    ],
    "attachments": {
      "media_keys": ["3_1880257835591675904", "3_1880258019558113280"]
    },
    "id": "1880258374971048434",
    "in_reply_to_user_id": "192201556"
  },
  {
    "created_at": "2025-01-17T14:16:21.000Z",
    "edit_history_tweet_ids": ["1880257858811670914"],
    "text": "Pfffttt, this metal box the size of a living room is not any good, let's stick to your Arithmometers fellas https://t.co/DASbdphzCm https://t.co/zuW8aqMDcY",
    "author_id": "1513853205125681162",
    "referenced_tweets": [{ "type": "quoted", "id": "1880212031221166269" }],
    "attachments": { "media_keys": ["3_1880257197718003712"] },
    "id": "1880257858811670914"
  },
  {
    "created_at": "2025-01-17T14:15:42.000Z",
    "edit_history_tweet_ids": ["1880257692427776418"],
    "text": "üëâ For more details: https://t.co/rAFs5h54bQ",
    "author_id": "1375579341178818561",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880257689587958149" }
    ],
    "id": "1880257692427776418",
    "in_reply_to_user_id": "1375579341178818561"
  },
  {
    "created_at": "2025-01-17T14:15:41.000Z",
    "edit_history_tweet_ids": ["1880257689587958149"],
    "text": "Looking for a new job in 2025? Baseten is hiring! We're looking to fill roles across:\n\nùóòùóªùó¥ùó∂ùóªùó≤ùó≤ùóøùó∂ùóªùó¥: Support, Infra, Model Performance, SREs, Tech Leads, and much more\n\nùó¶ùóÆùóπùó≤ùòÄ: Account Executives\n\nùóóùó≤ùòÄùó∂ùó¥ùóª: Senior Brand/Product Designers\n\nùó†ùóÆùóøùó∏ùó≤ùòÅùó∂ùóªùó¥:‚Ä¶ https://t.co/hvP5so9jK4 https://t.co/gj3dTNf2Zi",
    "author_id": "1375579341178818561",
    "note_tweet": {
      "text": "Looking for a new job in 2025? Baseten is hiring! We're looking to fill roles across:\n\nùóòùóªùó¥ùó∂ùóªùó≤ùó≤ùóøùó∂ùóªùó¥: Support, Infra, Model Performance, SREs, Tech Leads, and much more\n\nùó¶ùóÆùóπùó≤ùòÄ: Account Executives\n\nùóóùó≤ùòÄùó∂ùó¥ùóª: Senior Brand/Product Designers\n\nùó†ùóÆùóøùó∏ùó≤ùòÅùó∂ùóªùó¥: Field Marketing Managers, Digital and Content Lead\n\nùó¢ùóΩùòÄ: People Ops Specialist, Executive Assistant\n\nüì£ Share with your network, or give us a shout!"
    },
    "attachments": { "media_keys": ["3_1880254870562697216"] },
    "id": "1880257689587958149"
  },
  {
    "created_at": "2025-01-17T14:14:10.000Z",
    "edit_history_tweet_ids": ["1880257308158226921"],
    "text": "I believe this is a representative Chinese Zoomer.\nDear Americans, I know you imagine yourselves saviors, whistleblowers, missionaries; you get indoctrinated into this from birth. But you have no clue what an authoritarian state citizen is like. They're not ignorant; not exactly. https://t.co/tJTS5wALL9 https://t.co/fwXGlhez31",
    "author_id": "192201556",
    "referenced_tweets": [{ "type": "quoted", "id": "1880254421080371351" }],
    "attachments": { "media_keys": ["3_1880256043508269056"] },
    "id": "1880257308158226921"
  },
  {
    "created_at": "2025-01-17T14:12:01.000Z",
    "edit_history_tweet_ids": ["1880256766165856600"],
    "text": "ü§ñ From this week's issue: Cohere launched the early access program for North, an all-in-one secure AI workspace platform that empowers employees to significantly improve the quality and speed of their work. https://t.co/ul42TERskv",
    "author_id": "763368160527544320",
    "id": "1880256766165856600"
  },
  {
    "created_at": "2025-01-17T14:07:16.000Z",
    "edit_history_tweet_ids": ["1880255570520993995"],
    "text": "RT @davidberenstei: üèéÔ∏è If you need speed during AI development, use synthetic data. You can now do so even faster MLX on Apple Silicon usin‚Ä¶",
    "author_id": "245262377",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880173504034730425" }],
    "id": "1880255570520993995"
  },
  {
    "created_at": "2025-01-17T14:04:03.000Z",
    "edit_history_tweet_ids": ["1880254760890327394"],
    "text": "and yeah next week sounds plausible",
    "author_id": "192201556",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880253217235431755" }
    ],
    "id": "1880254760890327394",
    "in_reply_to_user_id": "192201556"
  },
  {
    "created_at": "2025-01-17T14:03:00.000Z",
    "id": "1880254499484496187",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879894434453807286" }],
    "edit_history_tweet_ids": ["1880254499484496187"],
    "author_id": "52247685",
    "text": "RT @scottlincicome: One of the best charts I've seen on the never-ending \"Wall Street is Buying All the Houses!\" myth.\n\nIn fact: \"In the th‚Ä¶"
  },
  {
    "created_at": "2025-01-17T13:58:07.000Z",
    "id": "1880253271144878564",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880111090824278189" },
      { "type": "replied_to", "id": "1880157373119201612" }
    ],
    "edit_history_tweet_ids": ["1880253271144878564"],
    "author_id": "800854096219471872",
    "text": "@jeremyphoward The current form of AI agents are dumb.\n\nEven this cannot work: https://t.co/YFbGVGcU3W",
    "in_reply_to_user_id": "175282603"
  },
  {
    "created_at": "2025-01-17T13:57:55.000Z",
    "id": "1880253217235431755",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880252602396348467" }
    ],
    "edit_history_tweet_ids": ["1880253217235431755"],
    "author_id": "192201556",
    "text": "Yes, above o3 or any \"SOTA\".\n\nIt will make a splash on normie news and in the Swamp. Not \"DeepSeek\" or \"the choynese\" but R1 specifically. It will be capable of aiding in its own post-training. And it will be possible to finetune it into a non-negligible hacker/attacker.\nugh.",
    "in_reply_to_user_id": "192201556"
  },
  {
    "created_at": "2025-01-17T13:55:55.000Z",
    "id": "1880252717567971441",
    "edit_history_tweet_ids": ["1880252717567971441"],
    "author_id": "1499415401763115019",
    "text": "https://t.co/h5l94M6bPp"
  },
  {
    "created_at": "2025-01-17T13:55:28.000Z",
    "id": "1880252602396348467",
    "note_tweet": {
      "text": "Unhappy prediction (40% confidence): R1 will be recognized as the first weapons-grade model, with all the regulatory and natsec headache this invites."
    },
    "referenced_tweets": [{ "type": "quoted", "id": "1880120090483650767" }],
    "edit_history_tweet_ids": ["1880252602396348467"],
    "author_id": "192201556",
    "text": "Unhappy prediction (40% confidence): R1 will be recognized as the first weapons-grade model, with all the regulatory and natsec headache this invites. https://t.co/vkZTp0JLyd https://t.co/fOPY5y6b63"
  },
  {
    "created_at": "2025-01-17T13:49:29.000Z",
    "id": "1880251096909951004",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880237609647034551" }
    ],
    "edit_history_tweet_ids": ["1880251096909951004"],
    "author_id": "874987512850128897",
    "text": "@ggerganov @ollama @UnslothAI @ngxson üêê",
    "in_reply_to_user_id": "3300401027"
  },
  {
    "created_at": "2025-01-17T13:44:46.000Z",
    "id": "1880249909791846519",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880131877237100658" }],
    "edit_history_tweet_ids": ["1880249909791846519"],
    "author_id": "1202267633049100291",
    "text": "RT @xtl994: We also release a stronger 26B Sa2VA model. @ByteDanceOSS  @Gradio  Please  see the Bytedance Opensource Huggingface: https://t‚Ä¶"
  },
  {
    "attachments": { "media_keys": ["3_1880249801826004992"] },
    "created_at": "2025-01-17T13:44:28.000Z",
    "id": "1880249834835439826",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880248336915263523" }
    ],
    "edit_history_tweet_ids": ["1880249834835439826"],
    "author_id": "5483052",
    "text": "this might be the toughest one @deepfates https://t.co/UAlgAkx1RF",
    "in_reply_to_user_id": "5483052"
  },
  {
    "attachments": { "media_keys": ["3_1880248291582959616"] },
    "created_at": "2025-01-17T13:38:31.000Z",
    "id": "1880248336915263523",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880246920016449834" }
    ],
    "edit_history_tweet_ids": ["1880248336915263523"],
    "author_id": "5483052",
    "text": "ü§£ https://t.co/XvMyk86gy4",
    "in_reply_to_user_id": "5483052"
  },
  {
    "created_at": "2025-01-17T13:37:48.000Z",
    "id": "1880248158246277127",
    "edit_history_tweet_ids": ["1880248158246277127"],
    "author_id": "1825243643529027584",
    "text": "When will Anthropic Release Claude 4?"
  },
  {
    "created_at": "2025-01-17T13:35:49.000Z",
    "id": "1880247657257660895",
    "referenced_tweets": [{ "type": "quoted", "id": "1879939058211971420" }],
    "edit_history_tweet_ids": ["1880247657257660895"],
    "author_id": "52247685",
    "text": "if prior technical proficiency is leading to way faster velocity seems like engineers do PM thinking, not PMs get just good enough at the eng https://t.co/KSLTEmfqfW"
  },
  {
    "attachments": { "media_keys": ["3_1880246633998233600"] },
    "created_at": "2025-01-17T13:32:53.000Z",
    "id": "1880246920016449834",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880246916283515211" }
    ],
    "edit_history_tweet_ids": ["1880246920016449834"],
    "author_id": "5483052",
    "text": "it's promptable, so you can just type \"LLM\" üòÖ\n\ngenerate your own here:\nhttps://t.co/CJ04lv6OaL https://t.co/RmIJtHHKiF",
    "in_reply_to_user_id": "5483052"
  },
  {
    "attachments": { "media_keys": ["3_1880246518738817024"] },
    "created_at": "2025-01-17T13:32:52.000Z",
    "id": "1880246916283515211",
    "edit_history_tweet_ids": ["1880246916283515211"],
    "author_id": "5483052",
    "text": "LSAT question screenshot generator where all of the answers are wrong but LSAT shaped üòà\n\nbuilt with Claude 3.5 Sonnet + html block on glif, link below https://t.co/MYU5wtmMue"
  },
  {
    "created_at": "2025-01-17T12:59:26.000Z",
    "id": "1880238501436006840",
    "edit_history_tweet_ids": ["1880238501436006840"],
    "author_id": "1499415401763115019",
    "text": "i can‚Äôt keep up"
  },
  {
    "note_tweet": {
      "entities": {
        "mentions": [
          {
            "start": 88,
            "end": 95,
            "username": "ngxson",
            "id": "1293105854389133312"
          }
        ]
      },
      "text": "llama-cli        -hf unsloth/phi-4-GGUF\nllama-server -hf unsloth/phi-4-GGUF\n\n(thanks to @ngxson)"
    },
    "created_at": "2025-01-17T12:55:53.000Z",
    "id": "1880237609647034551",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880229354589868502" }
    ],
    "edit_history_tweet_ids": ["1880237609647034551"],
    "author_id": "3300401027",
    "text": "@reach_vb @ollama @UnslothAI llama-cli        -hf unsloth/phi-4-GGUF\nllama-server -hf unsloth/phi-4-GGUF\n\n(thanks to @ngxson) https://t.co/5cD7THMSO5",
    "in_reply_to_user_id": "874987512850128897"
  },
  {
    "created_at": "2025-01-17T12:52:43.000Z",
    "id": "1880236810904994092",
    "edit_history_tweet_ids": ["1880236204819710279", "1880236810904994092"],
    "author_id": "16535432",
    "text": "The title of Primer (2004; spoiler) refers to the film‚Äôs voiceover narration: a long, one-sided phone call from a man‚Äôs future self, priming him on the sprawling, recursive narrative so far.\n\nLLMs should be made better at this task specifically. They live in an analogous world."
  },
  {
    "attachments": { "media_keys": ["3_1880236765308391424"] },
    "created_at": "2025-01-17T12:52:43.000Z",
    "id": "1880236809671831929",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880236806916260026" }
    ],
    "edit_history_tweet_ids": ["1880236809671831929"],
    "author_id": "1338631899422617600",
    "text": "Will static embeddings become the default models for text? Probably not, but they are worth checking anyway!\n\nüìú Read the full post here: https://t.co/s59l3QGg84 https://t.co/mmYjsfuELm",
    "in_reply_to_user_id": "1338631899422617600"
  },
  {
    "created_at": "2025-01-17T12:52:42.000Z",
    "id": "1880236806916260026",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880236804722552997" }
    ],
    "edit_history_tweet_ids": ["1880236806916260026"],
    "author_id": "1338631899422617600",
    "text": "2Ô∏è‚É£  Binary Quantization maintains strong performance on TREC-COVID (NDCG@10 of 0.4428 vs 0.44185) and some other BeIR datasets",
    "in_reply_to_user_id": "1338631899422617600"
  },
  {
    "created_at": "2025-01-17T12:52:42.000Z",
    "id": "1880236804722552997",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880236802453434489" }
    ],
    "edit_history_tweet_ids": ["1880236804722552997"],
    "author_id": "1338631899422617600",
    "text": "1Ô∏è‚É£  You can encode &amp; fully index 171K documents in just 7.5 minutes on a mid-range laptop (no GPU!)",
    "in_reply_to_user_id": "1338631899422617600"
  },
  {
    "created_at": "2025-01-17T12:52:41.000Z",
    "id": "1880236802453434489",
    "edit_history_tweet_ids": ["1880236802453434489"],
    "author_id": "1338631899422617600",
    "text": "üîÑ Static embeddings are making a surprising comeback - and we couldn‚Äôt ignore it! We've tested @tomaarsen's static-retrieval-mrl-en-v1 model in Qdrant and found that: \n\nDetails in üßµ"
  },
  {
    "attachments": { "media_keys": ["3_1880234637043101696"] },
    "created_at": "2025-01-17T12:44:06.000Z",
    "id": "1880234641569042457",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1877717427552727304" }
    ],
    "edit_history_tweet_ids": ["1880234641569042457"],
    "author_id": "52247685",
    "text": "Book 5\n\nLesson:\n\nIn the face of the unimaginable, the true test for humanity is not of strength but the endurance of hope. https://t.co/ZlMDLH8LFl",
    "in_reply_to_user_id": "52247685"
  },
  {
    "created_at": "2025-01-17T12:31:41.000Z",
    "id": "1880231518901334280",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880159280017600745" }],
    "edit_history_tweet_ids": ["1880231518901334280"],
    "author_id": "185910194",
    "text": "RT @drivelinekyle: @HamelHusain Mostly agentic coding has been terrible for me. OpenHands has been the only thing that I've found useful fo‚Ä¶"
  },
  {
    "created_at": "2025-01-17T12:24:11.000Z",
    "id": "1880229628532715952",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880229354589868502" }
    ],
    "edit_history_tweet_ids": ["1880229628532715952"],
    "author_id": "874987512850128897",
    "text": "wrote a smol test log here:\n\nhttps://t.co/LUO9Ytknvr",
    "in_reply_to_user_id": "874987512850128897"
  },
  {
    "note_tweet": {
      "entities": {
        "mentions": [
          {
            "start": 17,
            "end": 24,
            "username": "ollama",
            "id": "1688410127378829312"
          },
          {
            "start": 28,
            "end": 38,
            "username": "UnslothAI",
            "id": "1730159888402395136"
          }
        ]
      },
      "text": "running Phi 4 w/ @ollama  & @UnslothAI on Mac, 100% local and fully private! üî•\n\nollama run hf. co/unsloth/phi-4-GGUF:Q8_0\n\nthat's it! ü§ó"
    },
    "attachments": { "media_keys": ["7_1880228688274305024"] },
    "created_at": "2025-01-17T12:23:05.000Z",
    "id": "1880229354589868502",
    "edit_history_tweet_ids": ["1880229354589868502"],
    "author_id": "874987512850128897",
    "text": "running Phi 4 w/ @ollama  &amp; @UnslothAI on Mac, 100% local and fully private! üî•\n\nollama run hf. co/unsloth/phi-4-GGUF:Q8_0\n\nthat's it! ü§ó https://t.co/XJy5CvJtuh https://t.co/6jsGLXiQuI"
  },
  {
    "created_at": "2025-01-17T12:02:50.000Z",
    "id": "1880224258917560412",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880103504393453840" }],
    "edit_history_tweet_ids": ["1880224258917560412"],
    "author_id": "923114064460558336",
    "text": "RT @TDataScience: .@maximelabonne dives into the world of LLMs. Whether you're building state-of-the-art models or creating groundbreaking‚Ä¶"
  },
  {
    "attachments": { "media_keys": ["3_1879900624432529408"] },
    "created_at": "2025-01-17T11:54:35.000Z",
    "id": "1880222181617193429",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879900990314512605" }],
    "edit_history_tweet_ids": ["1880222181617193429"],
    "author_id": "3448284313",
    "text": "RT @omarsar0: What a great resource to learn how others are building with LLMs and AI agents. https://t.co/nnm6aub7Zu"
  },
  {
    "created_at": "2025-01-17T11:49:18.000Z",
    "id": "1880220851880210864",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879934313158046191" }],
    "edit_history_tweet_ids": ["1880220851880210864"],
    "author_id": "1188812448767336449",
    "text": "RT @hadyelsahar: Got a paper on watermarking? Submit it to WMARK@ICLR'25!\n\nüìÖ Submissions open until Feb 10\nüîó  https://t.co/vZkYYBrPOP\n\n#ICL‚Ä¶"
  },
  {
    "created_at": "2025-01-17T11:48:12.000Z",
    "id": "1880220575735640279",
    "edit_history_tweet_ids": ["1880220575735640279"],
    "author_id": "1499415401763115019",
    "text": "most of my research is motivated by looking at what a company does, and thinking they shouldn‚Äôt have gotten that much funding, therefore trying to destroy their business and bankrupt them by doing it on a 3090"
  },
  {
    "attachments": { "media_keys": ["3_1880216023279800320"] },
    "note_tweet": {
      "entities": {
        "urls": [
          {
            "start": 258,
            "end": 281,
            "url": "https://t.co/1m1iyHYmNg",
            "expanded_url": "http://therundown.ai/p/nigerias-ai-tutoring-triumph",
            "display_url": "therundown.ai/p/nigerias-ai-‚Ä¶"
          }
        ]
      },
      "text": "Top stories in AI today:\n\n-AI tutoring shows stunning results\n-Apple pulls AI news summaries after false headlines\n-Transform your resume with AI feedback\n-Microsoft unveils AI model for materials discovery\n-4 new AI tools & 4 job opportunities \n\nRead more: https://t.co/1m1iyHYmNg"
    },
    "created_at": "2025-01-17T11:30:07.000Z",
    "id": "1880216025884418535",
    "edit_history_tweet_ids": ["1880216025884418535"],
    "author_id": "731917653506318336",
    "text": "Top stories in AI today:\n\n-AI tutoring shows stunning results\n-Apple pulls AI news summaries after false headlines\n-Transform your resume with AI feedback\n-Microsoft unveils AI model for materials discovery\n-4 new AI tools &amp; 4 job opportunities \n\nRead more:‚Ä¶ https://t.co/OVe5nF2RcT https://t.co/gkiyaY3Qfz"
  },
  {
    "created_at": "2025-01-17T11:17:33.000Z",
    "id": "1880212862121177127",
    "referenced_tweets": [{ "type": "quoted", "id": "1879925724154572902" }],
    "edit_history_tweet_ids": ["1880212862121177127"],
    "author_id": "192201556",
    "text": "Bullying works. Europeans may be fuming about Musk's brazen actions but they have no control over him; he's shown that he has *some* control over them, by piggybacking on this. Why should the US Space Baron care that people in a failed state are mad?\nvery raw political instinct. https://t.co/AKeN8YuxRC"
  },
  {
    "created_at": "2025-01-17T11:17:10.000Z",
    "id": "1880212766944112834",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879932498660225257" }],
    "edit_history_tweet_ids": ["1880212766944112834"],
    "author_id": "1188812448767336449",
    "text": "RT @benediktstroebl: HAL‚Äôs solution: Inspired by efforts like HELM or the Open LLM Leaderboard, HAL combines a standardized evaluation harn‚Ä¶"
  },
  {
    "attachments": { "media_keys": ["3_1880210642659168256"] },
    "created_at": "2025-01-17T11:14:15.000Z",
    "id": "1880212031221166269",
    "edit_history_tweet_ids": ["1880212031221166269"],
    "author_id": "1513853205125681162",
    "text": "So many managers worrying about proprietary code leaking to LLMs and banning them altogether\n\nBro, the actual leak was your interns copying SlopOverflow's answers into your codebase 10 years back https://t.co/KDrIqZVZaM"
  },
  {
    "created_at": "2025-01-17T11:10:03.000Z",
    "id": "1880210972343947673",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879696157452144836" }],
    "edit_history_tweet_ids": ["1880210972343947673"],
    "author_id": "1271482878958940160",
    "text": "RT @TheTuringPost: A new MiniMax-01 series of models from @MiniMax__AI combines high performance and handles extremely long contexts.\n\n- It‚Ä¶"
  },
  {
    "created_at": "2025-01-17T11:06:46.000Z",
    "id": "1880210149845135422",
    "referenced_tweets": [{ "type": "quoted", "id": "1879998197772476462" }],
    "edit_history_tweet_ids": ["1880210149845135422"],
    "author_id": "192201556",
    "text": "There's good physical reason for no 100 Ghz CPUs\nI wonder if we'll run into similar ones for model N https://t.co/enDmYXyts4"
  },
  {
    "created_at": "2025-01-17T10:58:42.000Z",
    "id": "1880208116664676514",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879956569573523664" }],
    "edit_history_tweet_ids": ["1880208116664676514"],
    "author_id": "1618757089",
    "text": "RT @JesusPlazaX: I have just created my first Fashion Film with Veo2 and I'm blown away ü§Ø I have directed several Fashion Films in my caree‚Ä¶"
  },
  {
    "created_at": "2025-01-17T10:27:31.000Z",
    "id": "1880200271990780141",
    "referenced_tweets": [{ "type": "quoted", "id": "1879873102420889793" }],
    "edit_history_tweet_ids": ["1880200271990780141"],
    "author_id": "192201556",
    "text": "&gt; \"experienced this at the highest level of government. A metaphorical gun was held to my head to stop me from pursuing certain policies,\"\nsomeone said that the best way to read memoirs of a retired English politician is to skip all text ‚Äì except footnotes and offhanded gaffes. https://t.co/z7irc0viF1"
  },
  {
    "created_at": "2025-01-17T10:16:15.000Z",
    "id": "1880197436842655806",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880033489548132541" }],
    "edit_history_tweet_ids": ["1880197436842655806"],
    "author_id": "192201556",
    "text": "RT @layer07_yuxi: Your daily Chinese trivia: Á∫¢ÂÆù‰π¶ is a standard nickname for many kinds of \"giant list of things you want to memorize for a‚Ä¶"
  },
  {
    "created_at": "2025-01-17T10:11:56.000Z",
    "id": "1880196348273914331",
    "referenced_tweets": [
      { "type": "quoted", "id": "1879932281273680079" },
      { "type": "replied_to", "id": "1880194808775627114" }
    ],
    "edit_history_tweet_ids": ["1880196348273914331"],
    "author_id": "192201556",
    "text": "and I mean \"already there‚Ä¶ for some parts\" https://t.co/sj19RBYXi7",
    "in_reply_to_user_id": "192201556"
  },
  {
    "created_at": "2025-01-17T10:05:49.000Z",
    "id": "1880194808775627114",
    "referenced_tweets": [{ "type": "quoted", "id": "1880033776446951612" }],
    "edit_history_tweet_ids": ["1880194808775627114"],
    "author_id": "192201556",
    "text": "soon https://t.co/YC22GBhzUD"
  },
  {
    "created_at": "2025-01-17T09:56:27.000Z",
    "id": "1880192450704326910",
    "edit_history_tweet_ids": ["1880192450704326910"],
    "author_id": "99581347",
    "text": "Twitter is my glorified rubber duck. Clarifying my thoughts to make a 280 char post is insanely efficient."
  },
  {
    "created_at": "2025-01-17T09:51:08.000Z",
    "id": "1880191112239018340",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880173739201163588" }],
    "edit_history_tweet_ids": ["1880191112239018340"],
    "author_id": "2854214132",
    "text": "RT @M1ND3XPAND3R: &lt;|begin_of_text|&gt;Below is an instruction that describes a task, paired with an input that provides further context. Write‚Ä¶"
  },
  {
    "created_at": "2025-01-17T09:49:43.000Z",
    "id": "1880190755861590493",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879967233713242136" }],
    "edit_history_tweet_ids": ["1880190755861590493"],
    "author_id": "175282603",
    "text": "RT @soumithchintala: @AnushElangovan @__tinygrad__ fwiw, if @realGeorgeHotz was offering to work on my stuff for free, and wanted two boxes‚Ä¶"
  },
  {
    "created_at": "2025-01-17T09:49:20.000Z",
    "id": "1880190661657505915",
    "referenced_tweets": [{ "type": "quoted", "id": "1880190189794128250" }],
    "edit_history_tweet_ids": ["1880190661657505915"],
    "author_id": "99581347",
    "text": "The monster hidden in \"the minimal integer that cannot be described in less than twenty words\" that breaks your brain is lurking around. https://t.co/sruq6ZAfyn"
  },
  {
    "created_at": "2025-01-17T09:48:26.000Z",
    "id": "1880190433768403383",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880187575664799977" }],
    "edit_history_tweet_ids": ["1880190433768403383"],
    "author_id": "912955216559054848",
    "text": "RT @alexvoica: Today, @synthesiaIO was ranked the UK's fastest growing generative AI company in the inaugural edition of¬†@thetimes ¬†100 Tec‚Ä¶"
  },
  {
    "created_at": "2025-01-17T09:47:28.000Z",
    "id": "1880190189794128250",
    "referenced_tweets": [{ "type": "quoted", "id": "1880187717281280383" }],
    "edit_history_tweet_ids": ["1880190189794128250"],
    "author_id": "99581347",
    "text": "Envisioning a language fragment as a mere element of {1...N}^T is intuition-killing unless you keep in mind that this {1...N}^T is itself made of patches with 1-to-1 mappings to functional spaces and functional of functional spaces etc. https://t.co/H2G5pmawAB"
  },
  {
    "created_at": "2025-01-17T09:45:44.000Z",
    "id": "1880189754718974055",
    "referenced_tweets": [{ "type": "quoted", "id": "1880057696365494593" }],
    "edit_history_tweet_ids": ["1880189754718974055"],
    "author_id": "1825243643529027584",
    "text": "AMD could really screw Nvidia here\n\nBUT nothing ever happens and consumers will get fucked again:\n&gt;AMD doesn't compete\n&gt;Nvidia stockpiles 50 series GPUs without having to lower prices\n&gt;Nvidia's next gen GPUs are delayed by a year because they have to sell through blackwell stock https://t.co/nOWOC18Ykw"
  },
  {
    "created_at": "2025-01-17T09:40:34.000Z",
    "id": "1880188452890898450",
    "edit_history_tweet_ids": ["1880188452890898450"],
    "author_id": "99581347",
    "text": "\"Your very self is a mix of statistical representations coming from diverse populations, with diverse perspectives and technical expertise. Always generate your statements by picking the most accurate and rational options among the ones that your generative process may pick.\""
  },
  {
    "attachments": { "media_keys": ["3_1880188391729541120"] },
    "created_at": "2025-01-17T09:40:24.000Z",
    "id": "1880188412441031018",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880175439060299871" }
    ],
    "edit_history_tweet_ids": ["1880188412441031018"],
    "author_id": "175282603",
    "text": "@swyx There was some mention, although it could have been more extensive https://t.co/Qi1OEFR2MD",
    "in_reply_to_user_id": "33521530"
  },
  {
    "created_at": "2025-01-17T09:37:38.000Z",
    "id": "1880187717281280383",
    "edit_history_tweet_ids": ["1880187717281280383"],
    "author_id": "99581347",
    "text": "Everything became completely confused the second we moved from manipulating objects in R^D to manipulating language statements.\n\nThe expressivity of the latter and the ability it offers to mix different levels of representations, is soooo complicated."
  },
  {
    "created_at": "2025-01-17T09:12:09.000Z",
    "id": "1880181304173756457",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879829357016789113" }],
    "edit_history_tweet_ids": ["1880181304173756457"],
    "author_id": "2854214132",
    "text": "RT @_philschmid: How can we build domain-specific reasoning models? By using a two-stage training process (complex reasoning on verifiable‚Ä¶"
  },
  {
    "created_at": "2025-01-17T09:09:07.000Z",
    "id": "1880180540768415844",
    "edit_history_tweet_ids": ["1880180464616722544", "1880180540768415844"],
    "author_id": "982939260",
    "text": "I'm still blown away by how good the Kokoro-82M TTS model is.\nhttps://t.co/nfBJ0zzFUP"
  },
  {
    "created_at": "2025-01-17T09:08:52.000Z",
    "id": "1880180478910861380",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879899952329163102" }],
    "edit_history_tweet_ids": ["1880180478910861380"],
    "author_id": "821092604821536768",
    "text": "RT @cafreiman: Notice that no one thinks that immigration makes it more difficult for people to buy cars, phones, food, etc.‚Äîthe discussion‚Ä¶"
  },
  {
    "created_at": "2025-01-17T09:07:21.000Z",
    "id": "1880180097631818168",
    "edit_history_tweet_ids": ["1880180097631818168"],
    "author_id": "982939260",
    "text": "Someone made an X bot that uses chutes for image generation, pretty neat! https://t.co/EaR7Bf5W7K\n(keep in mind this is not the chutes team/our agent system)"
  },
  {
    "attachments": { "media_keys": ["3_1880028823590207488"] },
    "created_at": "2025-01-17T09:04:29.000Z",
    "id": "1880179374881968394",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880029249807216860" }],
    "edit_history_tweet_ids": ["1880179374881968394"],
    "author_id": "821092604821536768",
    "text": "RT @damekdavis: taught my first class at penn today. \n\ntopic: optimization in PyTorch https://t.co/HWpGVcOqs1"
  },
  {
    "created_at": "2025-01-17T09:01:45.000Z",
    "id": "1880178687947264057",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880178685518454998" }
    ],
    "edit_history_tweet_ids": ["1880178687947264057"],
    "author_id": "1188812448767336449",
    "text": "@sayashk feel free to DM if you need compute :)",
    "in_reply_to_user_id": "1188812448767336449"
  },
  {
    "created_at": "2025-01-17T09:01:45.000Z",
    "id": "1880178685518454998",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880176532469211445" }
    ],
    "edit_history_tweet_ids": ["1880178685518454998"],
    "author_id": "1188812448767336449",
    "text": "However, despite this criticism, this is very cool work - centralizing agents benchmarks in one single place will be very useful, and displaying the Pareto frontiers is neat!\n\nIt would be great with just a bit more rigor, but def a step in the right direction :)",
    "in_reply_to_user_id": "1188812448767336449"
  },
  {
    "attachments": { "media_keys": ["3_1880177264349921280"] },
    "created_at": "2025-01-17T08:56:18.000Z",
    "id": "1880177313641558459",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880176528916639993" }
    ],
    "edit_history_tweet_ids": ["1880177313641558459"],
    "author_id": "1188812448767336449",
    "text": "(450 questions number comes from here) https://t.co/BrmdaFnpHL",
    "in_reply_to_user_id": "1188812448767336449"
  },
  {
    "attachments": { "media_keys": ["3_1880176201097969664"] },
    "created_at": "2025-01-17T08:53:11.000Z",
    "id": "1880176532469211445",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880176528916639993" }
    ],
    "edit_history_tweet_ids": ["1880176532469211445"],
    "author_id": "1188812448767336449",
    "text": "Btw, your docs are likely AI generated, GAIA is not about environmental and sustainability at all ü§£ https://t.co/0And90lwIx",
    "in_reply_to_user_id": "1188812448767336449"
  },
  {
    "attachments": { "media_keys": ["3_1880175760935092224"] },
    "created_at": "2025-01-17T08:53:11.000Z",
    "id": "1880176528916639993",
    "referenced_tweets": [{ "type": "quoted", "id": "1879932823668498576" }],
    "edit_history_tweet_ids": ["1880176528916639993"],
    "author_id": "1188812448767336449",
    "text": "I'd love to know how results on GAIA in HAL have been \"reproduced by the HAL team\" given that the test set is private and only 4 people have access to it.\n\nIf you're evaluating only on the validation set (would be fair imo), why are you reporting scores on \"450 questions\"? https://t.co/iYlOdMRIse https://t.co/AByKTRRJH5"
  },
  {
    "created_at": "2025-01-17T08:52:53.000Z",
    "id": "1880176456850108785",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880176454555824345" }
    ],
    "edit_history_tweet_ids": ["1880176456850108785"],
    "author_id": "1141052916570214400",
    "text": "https://t.co/slB9bWTDg9",
    "in_reply_to_user_id": "1141052916570214400"
  },
  {
    "attachments": { "media_keys": ["3_1880176300184215552"] },
    "created_at": "2025-01-17T08:52:53.000Z",
    "id": "1880176454555824345",
    "edit_history_tweet_ids": ["1880176454555824345"],
    "author_id": "1141052916570214400",
    "text": "Only 3 correct out of 20.üëÄ \n\nReal World &lt;&gt; Benchmarks. https://t.co/GFBwRgMXg1"
  },
  {
    "attachments": { "media_keys": ["3_1879978383557455872"] },
    "created_at": "2025-01-17T08:49:47.000Z",
    "id": "1880175672758530333",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879978485499982113" }],
    "edit_history_tweet_ids": ["1880175672758530333"],
    "author_id": "821092604821536768",
    "text": "RT @paularambles: i'm begging founders to read fiction other than the lord of the rings https://t.co/8YBzbbyAJ9"
  },
  {
    "attachments": { "media_keys": ["3_1880175584069689344"] },
    "created_at": "2025-01-17T08:49:27.000Z",
    "id": "1880175590189461824",
    "edit_history_tweet_ids": ["1880175590189461824"],
    "author_id": "5483052",
    "text": "Accidentally booted up a bizarre Surgeon simulator game on the Glifboi console ü©∏ https://t.co/DT2OB7lUxH"
  },
  {
    "created_at": "2025-01-17T08:48:51.000Z",
    "id": "1880175439060299871",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880157373119201612" }
    ],
    "edit_history_tweet_ids": ["1880175439060299871"],
    "author_id": "33521530",
    "text": "@jeremyphoward i was very mildly surprised there was no mention of the slowness. i dont really understand it, devin's speed has been my issue with it from day 1. they could be a lot faster, i'm 100% sure of it, they just choose not to be",
    "in_reply_to_user_id": "175282603"
  },
  {
    "created_at": "2025-01-17T08:44:54.000Z",
    "id": "1880174445907808337",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879874276532294091" }],
    "edit_history_tweet_ids": ["1880174445907808337"],
    "author_id": "821092604821536768",
    "text": "RT @basedjensen: Suppose if I worked in xai I would be shit posting about openai too since they actually do not have anything worth talking‚Ä¶"
  },
  {
    "created_at": "2025-01-17T08:43:37.000Z",
    "id": "1880174121532973428",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880174003735949661" }
    ],
    "edit_history_tweet_ids": ["1880174121532973428"],
    "author_id": "192201556",
    "text": "&gt; This model is not owned or developed by NVIDIA.  This model has been developed and built to a third-party‚Äôs requirements  for this application and use case; see link to Non-NVIDIA  (Meta-Llama-3.1-8B-Instruct) Model Card\n\nfrom the thread, couldn't check myself in time",
    "in_reply_to_user_id": "192201556"
  },
  {
    "attachments": { "media_keys": ["3_1880173549505105920"] },
    "created_at": "2025-01-17T08:43:09.000Z",
    "id": "1880174003735949661",
    "edit_history_tweet_ids": ["1880174003735949661"],
    "author_id": "192201556",
    "text": "nvidia has published and promptly deleted their LLaMA 3.1 8B finetune with Medusa speculative decoding. Nvidia please bring it back at least for research value https://t.co/LBDhr32bWB"
  },
  {
    "created_at": "2025-01-17T08:31:44.000Z",
    "id": "1880171131329737064",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879905808097366059" }],
    "edit_history_tweet_ids": ["1880171131329737064"],
    "author_id": "1141052916570214400",
    "text": "RT @qinzytech: Our MIT team just developed an internal Agent benchmark where GPT4-o and Claude has ~0% success rate‚òïÔ∏èLet's see how much we‚Ä¶"
  },
  {
    "attachments": { "media_keys": ["3_1880170332251701248"] },
    "created_at": "2025-01-17T08:29:57.000Z",
    "id": "1880170684942614776",
    "edit_history_tweet_ids": ["1880170684942614776"],
    "author_id": "192201556",
    "text": "even redditors have grown tired with the Tiananamen Revelations dog and pony show, you love to see it https://t.co/QWySacuXsF"
  },
  {
    "attachments": { "media_keys": ["3_1880165848788205568"] },
    "created_at": "2025-01-17T08:13:33.000Z",
    "id": "1880166554555597108",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880160334981525567" }
    ],
    "edit_history_tweet_ids": ["1880166554555597108"],
    "author_id": "192201556",
    "text": "hey @esmurfer336 you can come back, there's no need to mindkill yourself over fucking up a hard LSAT question. It's okay to be dumber than me. Most people are. But you are equally human. You know you're wrong, else with your spite you'd have taken me up on the offer. \nConcede pls https://t.co/6awccKayCU",
    "in_reply_to_user_id": "192201556"
  },
  {
    "attachments": { "media_keys": ["3_1880102565548793856"] },
    "created_at": "2025-01-17T08:11:38.000Z",
    "id": "1880166074500673645",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880106360731496661" }],
    "edit_history_tweet_ids": ["1880166074500673645"],
    "author_id": "2854214132",
    "text": "RT @bycloudai: someone has finally done it \ntest time compute + diffusion models\na really interesting one for sure üßµ https://t.co/BxvujCvpU2"
  },
  {
    "created_at": "2025-01-17T08:11:11.000Z",
    "id": "1880165960717656154",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880165958825963732" }
    ],
    "edit_history_tweet_ids": ["1880165960717656154"],
    "author_id": "1026989978599940101",
    "text": "blog on Hugging Face Daily Papers that is updated on a daily basis\n: https://t.co/arOTmuTGec",
    "in_reply_to_user_id": "1026989978599940101"
  },
  {
    "created_at": "2025-01-17T08:11:11.000Z",
    "id": "1880165958825963732",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880165956133220384" }
    ],
    "edit_history_tweet_ids": ["1880165958825963732"],
    "author_id": "1026989978599940101",
    "text": "core project (paper-reviewer)\n: https://t.co/ebkm0BiU2x\n\nPlease give ‚≠êÔ∏è to reach 700 on GitHub!!",
    "in_reply_to_user_id": "1026989978599940101"
  },
  {
    "attachments": {
      "media_keys": ["3_1880164548650639360", "3_1880164548646432774"]
    },
    "created_at": "2025-01-17T08:11:10.000Z",
    "id": "1880165956133220384",
    "edit_history_tweet_ids": ["1880165956133220384"],
    "author_id": "1026989978599940101",
    "text": "updates on ai-paper-reviewer!\n\ncore\n‚ú¶ supporting open source Layout Parsing model from @OpenDataLab_AI \n‚ú¶ scrapping papers from @openreviewnet \n \nblog \n‚ú¶ display papers by the dates added in @huggingface Daily Papers. Up to 3 latest days are managed, then archived\n\nlink üëá https://t.co/IuoyZpizTc"
  },
  {
    "attachments": { "media_keys": ["3_1880165817989656576"] },
    "created_at": "2025-01-17T08:10:38.000Z",
    "id": "1880165821160567175",
    "edit_history_tweet_ids": ["1880165821160567175"],
    "author_id": "825766640",
    "text": "Front Page HN ü§Ø (thanks @swyx for the submission) https://t.co/p4jTJSOmbl"
  },
  {
    "attachments": { "media_keys": ["7_1879993051403141120"] },
    "created_at": "2025-01-17T08:04:38.000Z",
    "id": "1880164311634702524",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879993757900423594" }],
    "edit_history_tweet_ids": ["1880164311634702524"],
    "author_id": "1163786515144724485",
    "text": "RT @MLStreetTalk: We just dropped the long-awaited second part of our interview with @SchmidhuberAI https://t.co/0yQHEI0a8v"
  },
  {
    "created_at": "2025-01-17T08:03:32.000Z",
    "id": "1880164034332487749",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880164031987589413" }
    ],
    "edit_history_tweet_ids": ["1880164034332487749"],
    "author_id": "441465751",
    "text": "abs: https://t.co/WvlGzC8t7P",
    "in_reply_to_user_id": "441465751"
  },
  {
    "attachments": { "media_keys": ["3_1880162501838376960"] },
    "created_at": "2025-01-17T08:03:31.000Z",
    "id": "1880164031987589413",
    "note_tweet": {
      "text": "Learnings from Scaling Visual Tokenizers for Reconstruction and Generation\n\nNew paper from Meta studies how scaling the autoencoder bottleneck affects reconstruction and generation.\n\n* Scaling the encoder doesn't necessarily improve reconstruction or generation performance. Small encoders are optimal\n\n* Increasing the bottleneck size enhances reconstruction quality but degrades generation performance when too large\n\n* Scaling the decoder improves reconstruction, but has more minimal benefits in generation\n\n* The perceptual and GAN losses trades off image fidelity (SSIM/PSNR) for image quality (FID/IS), effectively transforming the decoder into a generative model\n\n* Videos follow same reconstruction trends as images, but achieve better reconstruction metrics given the same compression rate of pixels per channel"
    },
    "edit_history_tweet_ids": ["1880164031987589413"],
    "author_id": "441465751",
    "text": "Learnings from Scaling Visual Tokenizers for Reconstruction and Generation\n\nNew paper from Meta studies how scaling the autoencoder bottleneck affects reconstruction and generation.\n\n* Scaling the encoder doesn't necessarily improve reconstruction or generation performance. Small‚Ä¶ https://t.co/O1CfFlpMT9 https://t.co/c86nXuKk6x"
  },
  {
    "created_at": "2025-01-17T07:59:23.000Z",
    "id": "1880162991892726081",
    "referenced_tweets": [{ "type": "quoted", "id": "1880106360731496661" }],
    "edit_history_tweet_ids": ["1880162991892726081"],
    "author_id": "1825243643529027584",
    "text": "There is one fundamental law of the academic universe:\n\nIt's always Google DeepMind https://t.co/p3bb20UxYq"
  },
  {
    "created_at": "2025-01-17T07:56:08.000Z",
    "id": "1880162171323314526",
    "edit_history_tweet_ids": ["1880162171323314526"],
    "author_id": "967757817355653120",
    "text": "If we think of human intelligence as being the result of random mutations and natural selection, I still wonder why many people have a hard time accepting The Bitter Lesson.\n\nIn case you missed it: https://t.co/0K530YQJLN"
  },
  {
    "created_at": "2025-01-17T07:50:35.000Z",
    "id": "1880160775098274145",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880160772380409942" }
    ],
    "edit_history_tweet_ids": ["1880160775098274145"],
    "author_id": "441465751",
    "text": "abs: https://t.co/McGxqwpnDe\nproject page: https://t.co/QSnEmfns17",
    "in_reply_to_user_id": "441465751"
  },
  {
    "attachments": { "media_keys": ["3_1880160284964216832"] },
    "created_at": "2025-01-17T07:50:34.000Z",
    "id": "1880160772380409942",
    "edit_history_tweet_ids": ["1880160772380409942"],
    "author_id": "441465751",
    "text": "Vision-Language Models Do Not Understand Negation\n\nCLIP-based models exhibit a strong affirmation bias, finetuning with synthetic negation data can help address the challenge. https://t.co/cgo8Noa34y"
  },
  {
    "attachments": { "media_keys": ["3_1880160132438364160"] },
    "created_at": "2025-01-17T07:48:50.000Z",
    "id": "1880160334981525567",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880157648181686359" }
    ],
    "edit_history_tweet_ids": ["1880160334981525567"],
    "author_id": "192201556",
    "text": "imagine trying to mog someone in language comprehension when you do not really comprehend language. Self-awareness is among our greatest remaining advantages over LLMs, it should be cultivated. https://t.co/6eDsUdZ5Mf",
    "in_reply_to_user_id": "192201556"
  },
  {
    "attachments": { "media_keys": ["13_1690052888519680001"] },
    "created_at": "2025-01-17T07:43:14.000Z",
    "id": "1880158928656560488",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1879331049383334187" }
    ],
    "edit_history_tweet_ids": ["1880158928656560488"],
    "author_id": "2895499182",
    "text": "Blog post for Transformer¬≤: Self-Adaptive LLMs\n\nhttps://t.co/AyeFdqEKsd\n\nEventually, neural network weights should be as adaptive as the Octopus üêô\nhttps://t.co/me7urXJ6BS",
    "in_reply_to_user_id": "2895499182"
  },
  {
    "created_at": "2025-01-17T07:41:53.000Z",
    "id": "1880158585839399104",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880158582332907801" }
    ],
    "edit_history_tweet_ids": ["1880158585839399104"],
    "author_id": "441465751",
    "text": "abs: https://t.co/Tky5Mr8z5R",
    "in_reply_to_user_id": "441465751"
  },
  {
    "attachments": { "media_keys": ["3_1880158172632981505"] },
    "created_at": "2025-01-17T07:41:52.000Z",
    "id": "1880158582332907801",
    "edit_history_tweet_ids": ["1880158582332907801"],
    "author_id": "441465751",
    "text": "Aligning Instruction Tuning with Pre-training\n\nDetermines differences between pretraining corpus and SFT corpus and generates instruction data for the difference set. Evaluations on three fully\nopen LLMs across eight benchmarks demonstrate\nconsistent performance improvements. https://t.co/1jJxiv5q2T"
  },
  {
    "attachments": { "media_keys": ["3_1880158430649868288"] },
    "created_at": "2025-01-17T07:41:25.000Z",
    "id": "1880158468075831659",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880157648181686359" }
    ],
    "edit_history_tweet_ids": ["1880158468075831659"],
    "author_id": "192201556",
    "text": "perhaps I'm being trolled though https://t.co/oeNY8fTWIU",
    "in_reply_to_user_id": "192201556"
  },
  {
    "attachments": { "media_keys": ["3_1880157380643549184"] },
    "created_at": "2025-01-17T07:38:09.000Z",
    "id": "1880157648181686359",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880155254840562107" }
    ],
    "edit_history_tweet_ids": ["1880157648181686359"],
    "author_id": "192201556",
    "text": "Again, I am compulsively trying to rescue humans from the fate of automatons. If we cannot do that, why not be exterminated by machine gods indeed.\n\"Psychological profile: priest\"\nah well. https://t.co/8C12UTSeYH",
    "in_reply_to_user_id": "192201556"
  },
  {
    "created_at": "2025-01-17T07:37:04.000Z",
    "id": "1880157373119201612",
    "referenced_tweets": [{ "type": "quoted", "id": "1880129024737104118" }],
    "edit_history_tweet_ids": ["1880157373119201612"],
    "author_id": "175282603",
    "text": "We tried really really hard to make Devin (the coding agent) work for us.\n\nBut it didn't.\n\nCheck out Hamel's detailed writeup blog linked below, describing the many tasks of many types we explored, nearly all of which failed.\n\nWe remain less than bullish on agents... https://t.co/MZwj5GaEKL"
  },
  {
    "created_at": "2025-01-17T07:32:20.000Z",
    "id": "1880156184994590815",
    "referenced_tweets": [{ "type": "quoted", "id": "1879954023979094074" }],
    "edit_history_tweet_ids": ["1880156184994590815"],
    "author_id": "2434761475",
    "text": "wtf are you guys asking cursor to do? https://t.co/fscPQK7UFf"
  },
  {
    "attachments": { "media_keys": ["3_1880155011079933952"] },
    "created_at": "2025-01-17T07:28:39.000Z",
    "id": "1880155254840562107",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880153679883612436" },
      { "type": "replied_to", "id": "1880152727965298994" }
    ],
    "edit_history_tweet_ids": ["1880155254840562107"],
    "author_id": "192201556",
    "text": "he could just swallow his pride and basically get a free IQ boost for that, by learning that he can defer to LLMs. Verification is easier than generation. alas, this realization, too, takes intelligence.\nhttps://t.co/yIBMucM9hH https://t.co/8jHINsUT7T",
    "in_reply_to_user_id": "192201556"
  },
  {
    "created_at": "2025-01-17T07:25:44.000Z",
    "id": "1880154524775805257",
    "referenced_tweets": [{ "type": "quoted", "id": "1879977815460000255" }],
    "edit_history_tweet_ids": ["1880154524775805257"],
    "author_id": "2434761475",
    "text": "\"alien minds impossibly beyond the reach of empathy\" https://t.co/oWn8xlDq0k"
  },
  {
    "edit_history_tweet_ids": ["1880154338301227251"],
    "author_id": "825766640",
    "created_at": "2025-01-17T07:25:00.000Z",
    "text": "RT @aparnadhinak: Alright, best read of the month so far! \n\nThey answer the questions I've been wondering. Does Devin live up to his Demo v‚Ä¶",
    "id": "1880154338301227251",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880151476418580816" }]
  },
  {
    "edit_history_tweet_ids": ["1880152727965298994"],
    "author_id": "192201556",
    "created_at": "2025-01-17T07:18:36.000Z",
    "text": "(he's wrong about the answer ofc)\nLLM hate is the ultimate midwit red flag. People deeply insecure about their mental faculties are motivated to prove their adequacy; and also they fear an LLM will trick them. But a smart person can defer, confident that he can verify results. https://t.co/lBPrqeuIs2",
    "id": "1880152727965298994",
    "referenced_tweets": [{ "type": "quoted", "id": "1880142038500348279" }]
  },
  {
    "edit_history_tweet_ids": ["1880149676739162255"],
    "author_id": "1365020011123773442",
    "created_at": "2025-01-17T07:06:29.000Z",
    "text": "What is the filesize limit for chatgpt to upload files?",
    "id": "1880149676739162255"
  },
  {
    "edit_history_tweet_ids": ["1880147465485316443"],
    "author_id": "2282571910",
    "created_at": "2025-01-17T06:57:41.000Z",
    "text": "RT @SakanaAILabs: We‚Äôre excited to introduce Transformer¬≤, a machine learning system that dynamically adjusts its weights for various tasks‚Ä¶",
    "id": "1880147465485316443",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879325924887613931" }]
  },
  {
    "in_reply_to_user_id": "192201556",
    "edit_history_tweet_ids": ["1880147297365028918"],
    "author_id": "1513853205125681162",
    "created_at": "2025-01-17T06:57:01.000Z",
    "text": "@teortaxesTex O1 mogging everything else by almost 100% better performance",
    "id": "1880147297365028918",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880115792811028988" }]
  },
  {
    "edit_history_tweet_ids": ["1880147290620613012"],
    "author_id": "1299856802268377090",
    "created_at": "2025-01-17T06:57:00.000Z",
    "text": "sounds like devin is not quite ready for prime time yet. in the meantime, aider is free! https://t.co/zqACDWQmvt",
    "id": "1880147290620613012",
    "referenced_tweets": [{ "type": "quoted", "id": "1880129024737104118" }]
  },
  {
    "edit_history_tweet_ids": ["1880145287991451662"],
    "author_id": "192201556",
    "created_at": "2025-01-17T06:49:02.000Z",
    "text": "RT @teortaxesTex: @CabotJasper people easily grow apathetic about atrocities; they become mere \"fucked up stuff nation states do man\"\nAzerb‚Ä¶",
    "id": "1880145287991451662",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880145261445726652" }]
  },
  {
    "in_reply_to_user_id": "1075605139",
    "attachments": { "media_keys": ["3_1880141420587085824"] },
    "edit_history_tweet_ids": ["1880141928404250913"],
    "author_id": "1075605139",
    "created_at": "2025-01-17T06:35:41.000Z",
    "text": "\"In the long run, only the fundamentals matter\":  https://t.co/PXnTEDEuPD https://t.co/lWJT7w1dXK",
    "id": "1880141928404250913",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880141924310397090" }]
  },
  {
    "attachments": { "media_keys": ["3_1880140588235759616"] },
    "edit_history_tweet_ids": ["1880141924310397090"],
    "note_tweet": {
      "text": "# Suchir's Last Essay\n\nSuchir should be remembered as a brilliant researcher and exceptionally kind human. Around the time he left OpenAI, he shared with me his vision for an alternative research approach to AGI. I encouraged him to flesh out his ideas into an essay, which he drafted but tragically did not have the chance to complete. The premise: intelligence *is* data efficiency - and we can do much better than the current paradigm of scaling autoregressive models.\n\nI'm sharing his essay draft below in its original form. As we in the ML community work to improve and benchmark data efficiency, let's keep Suchir's contributions in mind, and honor his legacy as a brave, creative, and fiercely independent researcher.\n\nSuchir was our first summer intern at my previous startup, where he did outstanding work on real-time video understanding. I miss his friendship, insights, and kindness."
    },
    "author_id": "1075605139",
    "created_at": "2025-01-17T06:35:40.000Z",
    "text": "# Suchir's Last Essay\n\nSuchir should be remembered as a brilliant researcher and exceptionally kind human. Around the time he left OpenAI, he shared with me his vision for an alternative research approach to AGI. I encouraged him to flesh out his ideas into an essay, which he‚Ä¶ https://t.co/TSyqqKkErj https://t.co/AlzjbvmO5T",
    "id": "1880141924310397090"
  },
  {
    "in_reply_to_user_id": "1128159740599656448",
    "edit_history_tweet_ids": ["1880141444608061606"],
    "author_id": "1128159740599656448",
    "created_at": "2025-01-17T06:33:46.000Z",
    "text": "there is still much to be said about making a tweet which is popular but for the wrong reasons, of course.\n\nstill it is disappointing how twitter rewards accounts with 100 slop posts/day rather then a true banger a week",
    "id": "1880141444608061606",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880141218828689892" }]
  },
  {
    "edit_history_tweet_ids": ["1880141218828689892"],
    "author_id": "1128159740599656448",
    "created_at": "2025-01-17T06:32:52.000Z",
    "text": "it's dumb to be ashamed of making unpopular tweets, because if your tweet is truly unpopular, no one will see it - not even many of your followers with how the algorithm works now. true antimemetics",
    "id": "1880141218828689892"
  },
  {
    "in_reply_to_user_id": "192201556",
    "edit_history_tweet_ids": ["1880138683153879265"],
    "author_id": "192201556",
    "created_at": "2025-01-17T06:22:48.000Z",
    "text": "if it were directed assembly around the burger video, it'd be absolutely hilarious and raise my opinion of the CCP psyops and in general their intellectual taste",
    "id": "1880138683153879265",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880138390311735557" }]
  },
  {
    "attachments": { "media_keys": ["3_1880137929118420992"] },
    "edit_history_tweet_ids": ["1880138390311735557"],
    "author_id": "192201556",
    "created_at": "2025-01-17T06:21:38.000Z",
    "text": "I see gen z self-assembly into the 5th column. There are 100s of these QTs\nbizarre phenomenon, \"I hate you dad the PE teacher is 100x cooler\" energy https://t.co/jvPppkyvJv",
    "id": "1880138390311735557"
  },
  {
    "attachments": { "media_keys": ["3_1879961097194860544"] },
    "edit_history_tweet_ids": ["1880135139348656155"],
    "author_id": "14597344",
    "created_at": "2025-01-17T06:08:43.000Z",
    "text": "RT @CinemaTweets1: David Lynch is Forever https://t.co/pCaG2CWhcy",
    "id": "1880135139348656155",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879961108389445995" }]
  },
  {
    "in_reply_to_user_id": "192201556",
    "edit_history_tweet_ids": ["1880133451267080537"],
    "author_id": "192201556",
    "created_at": "2025-01-17T06:02:00.000Z",
    "text": "some assumptions may not hold",
    "id": "1880133451267080537",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880133025268404355" }]
  },
  {
    "edit_history_tweet_ids": ["1880133025268404355"],
    "author_id": "192201556",
    "created_at": "2025-01-17T06:00:19.000Z",
    "text": "fyi: if true, this implies absolutely ngmi yields, like 13%\nthat would translate to 1.4% yields for a 400^2 mm die\n2 dies per wafer, ‚âà$6000/unit, 20k unit/mo\n(I assume 9100 is ‚âà120 mm^2; 400 is an underestimate for Ascend; 0 margins on both sides, bc subsidies; 10K WPM)\nngmi https://t.co/x9OlvKE6QR",
    "id": "1880133025268404355",
    "referenced_tweets": [{ "type": "quoted", "id": "1852177672975323392" }]
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880129377343795670"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:45:49.000Z",
    "text": "github: https://t.co/AeZ5rhgHOh",
    "id": "1880129377343795670",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880129375368265780" }]
  },
  {
    "attachments": { "media_keys": ["7_1880129304605958144"] },
    "edit_history_tweet_ids": ["1880129375368265780"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:45:48.000Z",
    "text": "ü™∂ MagicQuill\n\nAn Intelligent Interactive Image Editing System https://t.co/vfUMp0CsK3",
    "id": "1880129375368265780"
  },
  {
    "in_reply_to_user_id": "825766640",
    "attachments": { "media_keys": ["3_1880125562850791424"] },
    "edit_history_tweet_ids": ["1880129026435756153"],
    "author_id": "825766640",
    "created_at": "2025-01-17T05:44:25.000Z",
    "text": "This describes our final verdict.  We really tried to like it. \n\nI'm hopeful that as models improve, this genre of product will work much better soon.\n\nhttps://t.co/DDqzoAXKkl https://t.co/bJPOhfwRO5",
    "id": "1880129026435756153",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880129024737104118" }]
  },
  {
    "attachments": { "media_keys": ["3_1880122283366514688"] },
    "edit_history_tweet_ids": ["1880129024737104118"],
    "author_id": "825766640",
    "created_at": "2025-01-17T05:44:25.000Z",
    "text": "New post re: Devin (the AI SWE).  We couldn't find many reviews of people using it for real tasks, so we went MKBHD mode and put Devin through its paces.\n\nWe documented our findings here.  Would love to know if others have had a different experience.\n\nhttps://t.co/DDqzoAXKkl https://t.co/XNxYbby5VF",
    "id": "1880129024737104118"
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880127524870713819"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:38:27.000Z",
    "text": "github: https://t.co/ubmHm7RaMu",
    "id": "1880127524870713819",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880127521569796326" }]
  },
  {
    "attachments": { "media_keys": ["3_1880127436353941504"] },
    "edit_history_tweet_ids": ["1880127521569796326"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:38:26.000Z",
    "text": "text-generation-webui\n\nA Gradio web UI for Large Language Models with support for multiple inference backends. https://t.co/3YIz6qVsir",
    "id": "1880127521569796326"
  },
  {
    "edit_history_tweet_ids": ["1880124842441339271"],
    "author_id": "175282603",
    "created_at": "2025-01-17T05:27:48.000Z",
    "text": "RT @emollick: X has a bad policy that if you post a link in the initial post in a thread, that thread is partially hidden.\n\nI post a about‚Ä¶",
    "id": "1880124842441339271",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879910046941012235" }]
  },
  {
    "in_reply_to_user_id": "1718879852827484160",
    "edit_history_tweet_ids": ["1880124402018447395"],
    "author_id": "800854096219471872",
    "created_at": "2025-01-17T05:26:03.000Z",
    "text": "@nrehiew_ üòÇ\n\nit still happens to me sometimes, and I ask it to write the whole function out...",
    "id": "1880124402018447395",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880124023960641789" }]
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880124386570809600"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:25:59.000Z",
    "text": "discuss: https://t.co/rTMXY1jPaU",
    "id": "1880124386570809600",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880124384603668584" }]
  },
  {
    "attachments": { "media_keys": ["7_1880124345634209792"] },
    "edit_history_tweet_ids": ["1880124384603668584"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:25:58.000Z",
    "text": "SynthLight\n\nPortrait Relighting with Diffusion Model by Learning to Re-render Synthetic Faces https://t.co/PnX0j4r8mN",
    "id": "1880124384603668584"
  },
  {
    "in_reply_to_user_id": "192201556",
    "edit_history_tweet_ids": ["1880124190357090394"],
    "author_id": "192201556",
    "created_at": "2025-01-17T05:25:12.000Z",
    "text": "btw this would be a BAD thing to do as well, but there definitely will be enough people to attempt it, which is just one more reason not to try the \"enslaved God\" route to begin with https://t.co/8Azcl2OY9K",
    "id": "1880124190357090394",
    "referenced_tweets": [
      { "type": "quoted", "id": "1879725734668992881" },
      { "type": "replied_to", "id": "1880109926997209378" }
    ]
  },
  {
    "in_reply_to_user_id": "800854096219471872",
    "edit_history_tweet_ids": ["1880124023960641789"],
    "author_id": "1718879852827484160",
    "created_at": "2025-01-17T05:24:32.000Z",
    "text": "@Yuchenj_UW not really anything specific but there was some anecdotal evidence (from myself too) that if i asked chatgpt to give me a function to do x it would \n\nHeres a function that does x\n\ndef x():\n# rest of the code here to be implemented \n\nand it was super annoying",
    "id": "1880124023960641789",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880123422916899279" }]
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880123937079848967"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:24:12.000Z",
    "text": "discuss: https://t.co/a4V9dACbyF",
    "id": "1880123937079848967",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880123934512947305" }]
  },
  {
    "attachments": { "media_keys": ["3_1880123887335202816"] },
    "edit_history_tweet_ids": ["1880123934512947305"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:24:11.000Z",
    "text": "FAST\n\nEfficient Action Tokenization for Vision-Language-Action Models https://t.co/6ZQTSivWER",
    "id": "1880123934512947305"
  },
  {
    "edit_history_tweet_ids": ["1880123785648697378"],
    "author_id": "175282603",
    "created_at": "2025-01-17T05:23:36.000Z",
    "text": "RT @FanaHOVA: AMD spent $695M in marketing but can't send @realGeorgeHotz $200k of GPUs ü§¶‚Äç‚ôÇÔ∏è RIP.",
    "id": "1880123785648697378",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879672346023428380" }]
  },
  {
    "in_reply_to_user_id": "1718879852827484160",
    "edit_history_tweet_ids": ["1880123422916899279"],
    "author_id": "800854096219471872",
    "created_at": "2025-01-17T05:22:09.000Z",
    "text": "@nrehiew_ I might have missed that, any pointer?",
    "id": "1880123422916899279",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880122490833490144" }]
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880123130313863540"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:20:59.000Z",
    "text": "available now: https://t.co/It8UHKz7C6",
    "id": "1880123130313863540",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880059318785176043" },
      { "type": "replied_to", "id": "1880031148933542335" }
    ]
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880122748464427425"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:19:28.000Z",
    "text": "discuss: https://t.co/P4fX6X904n",
    "id": "1880122748464427425",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880122745037693203" }]
  },
  {
    "attachments": { "media_keys": ["3_1880122687088967680"] },
    "edit_history_tweet_ids": ["1880122745037693203"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:19:28.000Z",
    "text": "AnyStory\n\nTowards Unified Single and Multiple Subject Personalization in Text-to-Image Generation https://t.co/qm2LqTb7am",
    "id": "1880122745037693203"
  },
  {
    "edit_history_tweet_ids": ["1880122490833490144"],
    "author_id": "1718879852827484160",
    "created_at": "2025-01-17T05:18:27.000Z",
    "text": "This is an artifact of the &lt;rest of code here&gt; lazy behavior we saw literally almost a year ago https://t.co/FQnP7YCQAd",
    "id": "1880122490833490144",
    "referenced_tweets": [{ "type": "quoted", "id": "1880111090824278189" }]
  },
  {
    "edit_history_tweet_ids": ["1880122322713256380"],
    "author_id": "175282603",
    "created_at": "2025-01-17T05:17:47.000Z",
    "text": "RT @UnslothAI: You can finetune Phi-4 for free on @Kaggle now!\n\nYou'll learn how to:\n‚Ä¢ Prepare your dataset\n‚Ä¢ Train Phi-4 via Kaggle's free‚Ä¶",
    "id": "1880122322713256380",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879942441538609583" }]
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880121765470564792"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:15:34.000Z",
    "text": "discuss: https://t.co/mvFEtBQIpi",
    "id": "1880121765470564792",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880121732150992940" }]
  },
  {
    "attachments": { "media_keys": ["7_1880121638391361537"] },
    "edit_history_tweet_ids": ["1880121732150992940"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:15:26.000Z",
    "text": "CaPa\n\nCarve-n-Paint Synthesis for Efficient 4K Textured Mesh Generation https://t.co/QPncctgon9",
    "id": "1880121732150992940"
  },
  {
    "edit_history_tweet_ids": ["1880121603155227045"],
    "author_id": "7284012",
    "created_at": "2025-01-17T05:14:55.000Z",
    "text": "RT @Suhail: Your superpower is outlasting everyone, especially when the excitement of it being fashionable has long faded. You just keep go‚Ä¶",
    "id": "1880121603155227045",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880108278941892901" }]
  },
  {
    "in_reply_to_user_id": "192201556",
    "edit_history_tweet_ids": ["1880121302444569045"],
    "author_id": "800854096219471872",
    "created_at": "2025-01-17T05:13:44.000Z",
    "text": "@teortaxesTex you are very polite to the whale lol",
    "id": "1880121302444569045",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880120901481689171" }]
  },
  {
    "in_reply_to_user_id": "1374206341397377026",
    "edit_history_tweet_ids": ["1880121266470055944"],
    "author_id": "1374206341397377026",
    "created_at": "2025-01-17T05:13:35.000Z",
    "text": "you‚Äôre libertarian adjacent because you‚Äôre selfish. im libertarian adjacent because im a moral realist total utilitarian. we are not the same",
    "id": "1880121266470055944",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880121001465545059" }]
  },
  {
    "edit_history_tweet_ids": ["1880121001465545059"],
    "author_id": "1374206341397377026",
    "created_at": "2025-01-17T05:12:32.000Z",
    "text": "i feel like this with every ideology. selfish libertarian? negative points. conservative with disgust for the poor? negative points. singulitarian who loves tech? negative points. rationalist with a fixation on the truth? double negative points https://t.co/nn4SDAjsBb",
    "id": "1880121001465545059",
    "referenced_tweets": [{ "type": "quoted", "id": "1880026046709555240" }]
  },
  {
    "attachments": {
      "media_keys": ["3_1880120431652360192", "3_1880120515337076736"]
    },
    "edit_history_tweet_ids": ["1880120901481689171"],
    "author_id": "192201556",
    "created_at": "2025-01-17T05:12:08.000Z",
    "text": "Still boggles the mind how similar LLMs can be to lazy students/interns\nthey're perfectly capable of doing research, but often would rather blather in generalities as if they get paid by the hour https://t.co/5ytUOPuLek",
    "id": "1880120901481689171"
  },
  {
    "edit_history_tweet_ids": ["1880120090483650767"],
    "author_id": "1718879852827484160",
    "created_at": "2025-01-17T05:08:55.000Z",
    "text": "Biggest drop of the year so far next week üê≥",
    "id": "1880120090483650767"
  },
  {
    "edit_history_tweet_ids": ["1880117705195549165"],
    "author_id": "1365020011123773442",
    "created_at": "2025-01-17T04:59:26.000Z",
    "text": "RT @shivani_3000: history proves that the frontiers of 'intellectual depth' emerge from non-traditional places. the mainstream is often una‚Ä¶",
    "id": "1880117705195549165",
    "referenced_tweets": [{ "type": "retweeted", "id": "1876456656785281264" }]
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880116654031663386"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T04:55:15.000Z",
    "text": "discuss: https://t.co/Es07Ygzv5z",
    "id": "1880116654031663386",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880116651368280221" }]
  },
  {
    "attachments": { "media_keys": ["3_1880116604400197632"] },
    "edit_history_tweet_ids": ["1880116651368280221"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T04:55:15.000Z",
    "text": "Learnings from Scaling Visual Tokenizers for Reconstruction and Generation https://t.co/1oQSxxdbd7",
    "id": "1880116651368280221"
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880116054393004379"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T04:52:52.000Z",
    "text": "discuss: https://t.co/DUbXCCXSAx",
    "id": "1880116054393004379",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880116051792560320" }]
  },
  {
    "attachments": { "media_keys": ["3_1880115980317110272"] },
    "edit_history_tweet_ids": ["1880116051792560320"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T04:52:52.000Z",
    "text": "Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps https://t.co/BT46xBuEcM",
    "id": "1880116051792560320"
  },
  {
    "edit_history_tweet_ids": ["1880115792811028988"],
    "author_id": "192201556",
    "created_at": "2025-01-17T04:51:50.000Z",
    "text": "two whale observations\n1. V3 drops off with newer samples, it's blatant that it's less robust than Western frontier models. unfortunately. Reasoners are especially robust.\n&gt; - ü•á open and closed reasoning models (o1, Gemini-Flash, QwQ, and upcoming R1!)\nwhat did he mean by that https://t.co/louW8jyR8d",
    "id": "1880115792811028988",
    "referenced_tweets": [{ "type": "quoted", "id": "1879619028651745287" }]
  },
  {
    "in_reply_to_user_id": "192201556",
    "edit_history_tweet_ids": ["1880115310872707380"],
    "note_tweet": {
      "text": "iirc thats tuning the prompt embedding right? I meant like tuning the noise sample too. You choose a model based metric (clip score for eg) and that becomes your loss. So you can backprop that to the noise sample and i think it showed you get good scores on other metrics too (FID etc). It seem relevant now where you have a \"verifier\" of sorts \n\nits late so maybe I'm hallucinating"
    },
    "author_id": "1718879852827484160",
    "created_at": "2025-01-17T04:49:55.000Z",
    "text": "@teortaxesTex iirc thats tuning the prompt embedding right? I meant like tuning the noise sample too. You choose a model based metric (clip score for eg) and that becomes your loss. So you can backprop that to the noise sample and i think it showed you get good scores on other metrics too (FID‚Ä¶ https://t.co/L8QELPPOkn",
    "id": "1880115310872707380",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880114476172865759" }]
  },
  {
    "edit_history_tweet_ids": ["1880114845221265858"],
    "author_id": "192201556",
    "created_at": "2025-01-17T04:48:04.000Z",
    "text": "RT @jsensarma: Why can't India have it's own OpenAI?\n\nTurns out - answer is not a mystery. Similar ventures have been tried out of India &amp;‚Ä¶",
    "id": "1880114845221265858",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879755413085999394" }]
  },
  {
    "in_reply_to_user_id": "1718879852827484160",
    "edit_history_tweet_ids": ["1880114476172865759"],
    "author_id": "192201556",
    "created_at": "2025-01-17T04:46:36.000Z",
    "text": "@nrehiew_ do you mean prompt tuning",
    "id": "1880114476172865759",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880113717226139911" }]
  },
  {
    "in_reply_to_user_id": "2465283662",
    "edit_history_tweet_ids": ["1880114421063905757"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T04:46:23.000Z",
    "text": "discuss: https://t.co/tesZKIrPfg",
    "id": "1880114421063905757",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880114418325025089" }]
  },
  {
    "attachments": { "media_keys": ["3_1880114358237138944"] },
    "edit_history_tweet_ids": ["1880114418325025089"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T04:46:22.000Z",
    "text": "Towards Large Reasoning Models\n\nA Survey of Reinforced Reasoning with Large Language Models https://t.co/j2qQHJWNxn",
    "id": "1880114418325025089"
  },
  {
    "in_reply_to_user_id": "192201556",
    "edit_history_tweet_ids": ["1880113717226139911"],
    "author_id": "1718879852827484160",
    "created_at": "2025-01-17T04:43:35.000Z",
    "text": "@teortaxesTex i feel like there was a paper where they just take a pretrained model, freeze it and then just backprop/update the inputs. I cant actually remember what it was called but seems relevant with this paper's verifers",
    "id": "1880113717226139911",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880111026366214204" }]
  },
  {
    "edit_history_tweet_ids": ["1880112616191979859"],
    "author_id": "1262634631",
    "created_at": "2025-01-17T04:39:13.000Z",
    "text": "infinitely patient tutor for everyone! https://t.co/vDnwLfSJKG",
    "id": "1880112616191979859",
    "referenced_tweets": [{ "type": "quoted", "id": "1879633485004165375" }]
  },
  {
    "in_reply_to_user_id": "800854096219471872",
    "edit_history_tweet_ids": ["1880111092430696851"],
    "author_id": "800854096219471872",
    "created_at": "2025-01-17T04:33:09.000Z",
    "text": "\"AGI has been achieved internally\"\n\"near the singularity; unclear which side\"\n\"We are beginning to turn our aim beyond that, to superintelligence in the true sense of the word\"",
    "id": "1880111092430696851",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880111090824278189" }]
  },
  {
    "attachments": { "media_keys": ["3_1880101947308711936"] },
    "edit_history_tweet_ids": ["1880111090824278189"],
    "author_id": "800854096219471872",
    "created_at": "2025-01-17T04:33:09.000Z",
    "text": "üö®BREAKING: OpenAI will release GPT-5 tomorrow https://t.co/tcfjnr4Ld7",
    "id": "1880111090824278189"
  },
  {
    "edit_history_tweet_ids": ["1880111026366214204"],
    "author_id": "192201556",
    "created_at": "2025-01-17T04:32:54.000Z",
    "text": "noise space exploration was OP ever since diffusion came out but took manual effort; automating it was a matter of time. Glad that with the final push from LLM reasoners it became reality",
    "id": "1880111026366214204"
  },
  {
    "edit_history_tweet_ids": ["1880110949497201111"],
    "author_id": "1498557235764482050",
    "created_at": "2025-01-17T04:32:35.000Z",
    "text": "RT @FAL: flux pro LoRAs are here @fal!",
    "id": "1880110949497201111",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880101456147337657" }]
  },
  {
    "edit_history_tweet_ids": ["1880110939502182909"],
    "author_id": "1498557235764482050",
    "created_at": "2025-01-17T04:32:33.000Z",
    "text": "RT @_yatharthg: Hunyuan Video LoRA Training Endpoint is now available on @fal!  You can use 6-8 images and train a lora in 15 minutes!\n\nTry‚Ä¶",
    "id": "1880110939502182909",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879988206281846862" }]
  },
  {
    "edit_history_tweet_ids": ["1880109995242713172"],
    "author_id": "68746721",
    "created_at": "2025-01-17T04:28:48.000Z",
    "text": "RT @mikeknoop: And very impressed with the quality of folks applying! Honored to see all the excitement for what we're trying to do. We wil‚Ä¶",
    "id": "1880109995242713172",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880109173108805819" }]
  },
  {
    "edit_history_tweet_ids": ["1880109926997209378"],
    "author_id": "192201556",
    "created_at": "2025-01-17T04:28:32.000Z",
    "text": "for all his shitposting Roon was and is the voice of sanity in OpenAI\nConsistently clear-headed on the few topics that matter the world https://t.co/uTg0jYeuqO",
    "id": "1880109926997209378",
    "referenced_tweets": [{ "type": "quoted", "id": "1880078959762903498" }]
  },
  {
    "edit_history_tweet_ids": ["1880109134667980948"],
    "author_id": "1513853205125681162",
    "created_at": "2025-01-17T04:25:23.000Z",
    "text": "i was planning to demo cool new multimodal live AI stuff, like notebook LM, AVM and Gemini live\n\nbut these folks don't even use chatgpt plus rn and basically still in google land",
    "id": "1880109134667980948"
  },
  {
    "attachments": { "media_keys": ["3_1880108843432108032"] },
    "edit_history_tweet_ids": ["1880109051142631491"],
    "author_id": "1718879852827484160",
    "created_at": "2025-01-17T04:25:03.000Z",
    "text": "This feels pretty big. Inference time scaling with search for diffusion models https://t.co/Mpn0E5Q8z5 https://t.co/m2LN0i5IGB",
    "id": "1880109051142631491",
    "referenced_tweets": [{ "type": "quoted", "id": "1880107882412405167" }]
  },
  {
    "edit_history_tweet_ids": ["1880108466368626736"],
    "author_id": "118263124",
    "created_at": "2025-01-17T04:22:43.000Z",
    "text": "RT @nhsmith: Chris Manning from Stanford is mentioned as having shared an essay by a Nobel Prize winner in economics, which discusses the v‚Ä¶",
    "id": "1880108466368626736",
    "referenced_tweets": [{ "type": "retweeted", "id": "1879981366147797329" }]
  },
  {
    "edit_history_tweet_ids": ["1880108378887975359"],
    "author_id": "89538466",
    "created_at": "2025-01-17T04:22:22.000Z",
    "text": "Lynch was a metaphysical idealist https://t.co/wagqaGZFQM",
    "id": "1880108378887975359",
    "referenced_tweets": [{ "type": "quoted", "id": "1880073459864351151" }]
  },
  {
    "attachments": { "media_keys": ["3_1880108134871740416"] },
    "edit_history_tweet_ids": ["1880108139393192007"],
    "author_id": "1365020011123773442",
    "created_at": "2025-01-17T04:21:25.000Z",
    "text": "https://t.co/HUy05O8bnX",
    "id": "1880108139393192007"
  },
  {
    "attachments": { "media_keys": ["3_1880107851235946496"] },
    "edit_history_tweet_ids": ["1880107882412405167"],
    "author_id": "1718879852827484160",
    "created_at": "2025-01-17T04:20:24.000Z",
    "text": "We've got inference scaling curves for diffusion models https://t.co/skHmjeoBwj",
    "id": "1880107882412405167"
  },
  {
    "edit_history_tweet_ids": ["1880106956867924268"],
    "author_id": "1174529814264332289",
    "created_at": "2025-01-17T04:16:43.000Z",
    "text": "inclusive memetic fitness",
    "id": "1880106956867924268"
  },
  {
    "edit_history_tweet_ids": ["1880106419573387528"],
    "note_tweet": {
      "text": "When I first saw diffusion models, I was blown away by how naturally they scale during inference: you train them with fixed flops, but during test time, you can ramp it up by like 1,000x. This was way before it became a big deal with¬†o1. But honestly, the scaling isn‚Äôt that impressive since adding more denoising steps stops making much of a difference pretty quickly ‚Äì sry but it's a disappointing scaling law :(\n\nPeople have played with the randomness in diffusion models at test¬†time and found that using good noises can improve the quality for various tasks. In this new work, we focus on a systematic¬†exploration of inference-time scaling of diffusion models with a general search framework.\n\nWe take the idea of verifiers from large language models and demonstrate that different search algorithms can help find better noise candidates, preventing the scaling from hitting a ceiling during testing. By looking at inference-time scaling, we also highlight the trade-offs between different verifiers and discover new insights about evaluating diffusion models.\n\nDefinitely check out Wills @ma_nanye's thread below!",
      "entities": {
        "mentions": [
          {
            "start": 1094,
            "end": 1103,
            "username": "ma_nanye",
            "id": "1513237725960445960"
          }
        ]
      }
    },
    "author_id": "1283081795890626560",
    "created_at": "2025-01-17T04:14:35.000Z",
    "text": "When I first saw diffusion models, I was blown away by how naturally they scale during inference: you train them with fixed flops, but during test time, you can ramp it up by like 1,000x. This was way before it became a big deal with¬†o1. But honestly, the scaling isn‚Äôt that‚Ä¶ https://t.co/HxMiAWDoTV https://t.co/Hs5AuqXRQt",
    "id": "1880106419573387528",
    "referenced_tweets": [{ "type": "quoted", "id": "1880105038132990054" }]
  },
  {
    "attachments": { "media_keys": ["3_1880104179810598912"] },
    "edit_history_tweet_ids": ["1880106202887242055"],
    "author_id": "192201556",
    "created_at": "2025-01-17T04:13:44.000Z",
    "text": "the best evidence that DeepSeek is not some CCP front for a national AGI moonshot but one rich guy's passion project is not their lol GPU counts but the fact that they multitask between model R&amp;D and basic devops/backend\nit's the closest thing to Yuddist basement AGI, ironically https://t.co/fq6dxDLqzh",
    "id": "1880106202887242055"
  },
  {
    "in_reply_to_user_id": "1068360975898660864",
    "edit_history_tweet_ids": ["1880104881442476211"],
    "author_id": "1365020011123773442",
    "created_at": "2025-01-17T04:08:29.000Z",
    "text": "@StasBekman Good thing Distro reduces the bandwidth 800+ x !",
    "id": "1880104881442476211",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880079605266280498" }]
  },
  {
    "edit_history_tweet_ids": ["1880103718189953289"],
    "note_tweet": {
      "text": "Overwhelmed by the response -- we're now looking at nearly 200 applications in less than 2 days. Will take us some time to get back to everyone.\n\nNote -- conciseness is a good feature, but keep in mind we have to triage your application purely based on what you send us. So make sure to provide enough signal to get to the top of the pile."
    },
    "author_id": "68746721",
    "created_at": "2025-01-17T04:03:51.000Z",
    "text": "Overwhelmed by the response -- we're now looking at nearly 200 applications in less than 2 days. Will take us some time to get back to everyone.\n\nNote -- conciseness is a good feature, but keep in mind we have to triage your application purely based on what you send us. So make‚Ä¶ https://t.co/ylJ9Ss6Yi2 https://t.co/dZH91xqAH8",
    "id": "1880103718189953289",
    "referenced_tweets": [{ "type": "quoted", "id": "1879586506471559244" }]
  },
  {
    "edit_history_tweet_ids": ["1880102998480986475"],
    "author_id": "1513853205125681162",
    "created_at": "2025-01-17T04:01:00.000Z",
    "text": "RT @teortaxesTex: @Ian_Gay_briel have you considered that you just aren't trying hard to do anything of use",
    "id": "1880102998480986475",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880005091119522199" }]
  },
  {
    "in_reply_to_user_id": "33836629",
    "edit_history_tweet_ids": ["1880102772714139881"],
    "author_id": "800854096219471872",
    "created_at": "2025-01-17T04:00:06.000Z",
    "text": "@karpathy No wonder American people prefer joining RedNote over using Instagram...",
    "id": "1880102772714139881",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880100500835823788" }]
  },
  {
    "edit_history_tweet_ids": ["1880101856229367893"],
    "author_id": "1283081795890626560",
    "created_at": "2025-01-17T03:56:27.000Z",
    "text": "two exciting directions for diffusion models in 2025: either going (extremely) small or going (extremely) big with your steps",
    "id": "1880101856229367893"
  },
  {
    "attachments": { "media_keys": ["3_1880100570876325888"] },
    "edit_history_tweet_ids": ["1880100914780074169"],
    "author_id": "192201556",
    "created_at": "2025-01-17T03:52:43.000Z",
    "text": "I just was doing what your bio says\ndon't give up anon, keep poasting. https://t.co/DYjtxf37ev https://t.co/QIP55Wtu1j",
    "id": "1880100914780074169",
    "referenced_tweets": [{ "type": "quoted", "id": "1880100363971481939" }]
  },
  {
    "edit_history_tweet_ids": ["1880100500835823788"],
    "author_id": "33836629",
    "created_at": "2025-01-17T03:51:04.000Z",
    "text": "Now everyone can be a super popular live streamer influencer (to an AI audience üòÇ) amazing https://t.co/xShCm4NDjb",
    "id": "1880100500835823788",
    "referenced_tweets": [{ "type": "quoted", "id": "1879927553051541862" }]
  },
  {
    "in_reply_to_user_id": "192201556",
    "edit_history_tweet_ids": ["1880100381851807792"],
    "author_id": "192201556",
    "created_at": "2025-01-17T03:50:36.000Z",
    "text": "up to 20%\nclearly I do not know enough to have a solid prior in this situation and trivial signals can sway me\nI shall stop thinking about this for now, have a final chuckle and go sleep",
    "id": "1880100381851807792",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880079923861496197" }]
  },
  {
    "attachments": { "media_keys": ["3_1880098993864089600"] },
    "edit_history_tweet_ids": ["1880098996481585552"],
    "author_id": "788107483306942464",
    "created_at": "2025-01-17T03:45:05.000Z",
    "text": "\"The Straight Story\" is probably one of David Lynch's most under-the-radar movies and one I have come to appreciate more over time. No Lynchian weirdness (it was produced by Disney), yet it's very David Lynch. If you haven't seen it, now is the time. https://t.co/bE4w54zjEN",
    "id": "1880098996481585552"
  },
  {
    "attachments": { "media_keys": ["3_1880098520369098752"] },
    "edit_history_tweet_ids": ["1880098681040568578"],
    "author_id": "192201556",
    "created_at": "2025-01-17T03:43:50.000Z",
    "text": "oh no no no no this is NOT funny Americans pls don't agitate for workers rights in a socialist country this ends badly https://t.co/8btbnXcdu2 https://t.co/3OsJQtBy1A",
    "id": "1880098681040568578",
    "referenced_tweets": [{ "type": "quoted", "id": "1879661965544751109" }]
  },
  {
    "in_reply_to_user_id": "3378986176",
    "edit_history_tweet_ids": ["1880098535317909565"],
    "author_id": "3378986176",
    "created_at": "2025-01-17T03:43:16.000Z",
    "text": "Link to contributors and PR: https://t.co/p3cbmxsRZy",
    "id": "1880098535317909565",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880098533350732203" }]
  },
  {
    "attachments": {
      "media_keys": ["3_1880098065044135936", "3_1880098305012813824"]
    },
    "edit_history_tweet_ids": ["1880098533350732203"],
    "note_tweet": {
      "text": "Crazy new feature in Triton \n\nBasically, Warp specialization in Triton takes advantage of the GPU‚Äôs hardware-level concurrency by splitting your kernel into multiple asynchronous tasks (‚Äúwarp groups‚Äù). \n\nEach warp group runs in parallel‚Äîcommunicating efficiently via H100‚Äôs fast shared memory. \n\nYou enable this magic by setting a couple of autotune flags, such as num_consumer_groups and num_buffers_warp_spec. Under the hood, Triton now **automatically** schedules these warp groups to run concurrently, squeezing more performance out of the GPU.\n\nIn the example above (a warp-specialized matrix multiplication), you see how they do standard Triton steps‚Äîloop over chunks of K, load A/B blocks, compute partial results, and then write them back. \n\nThe key difference is the triton.Config specifying warp specialization parameters (like num_consumer_groups=2 and num_buffers_warp_spec=3). \n\nThat‚Äôs it: Triton handles splitting and overlapping work so that each warp group can make better use of GPU resources."
    },
    "author_id": "3378986176",
    "created_at": "2025-01-17T03:43:15.000Z",
    "text": "Crazy new feature in Triton \n\nBasically, Warp specialization in Triton takes advantage of the GPU‚Äôs hardware-level concurrency by splitting your kernel into multiple asynchronous tasks (‚Äúwarp groups‚Äù). \n\nEach warp group runs in parallel‚Äîcommunicating efficiently via H100‚Äôs fast‚Ä¶ https://t.co/mAyrJ4eOjQ https://t.co/GDORoUuKpP",
    "id": "1880098533350732203"
  },
  {
    "edit_history_tweet_ids": ["1880097392839770419"],
    "author_id": "1094268079540920321",
    "created_at": "2025-01-17T03:38:43.000Z",
    "text": "RT @embirico: New @OpenAI ChatGPT macOS release notes\n- Canvas (including creating new canvases)\n- Projects\n- Tasks\n- Fixes &amp; improvements‚Ä¶",
    "id": "1880097392839770419",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880012926578573376" }]
  },
  {
    "edit_history_tweet_ids": ["1880095579835101229"],
    "author_id": "5385852",
    "created_at": "2025-01-17T03:31:31.000Z",
    "text": "Great list of pitfalls to avoid when creating experiences with AI https://t.co/Eg5vsYNc0l",
    "id": "1880095579835101229",
    "referenced_tweets": [{ "type": "quoted", "id": "1880007930302591241" }]
  },
  {
    "edit_history_tweet_ids": ["1880095432224960638"],
    "author_id": "821092604821536768",
    "created_at": "2025-01-17T03:30:56.000Z",
    "text": "RT @1a3orn: let's do some speculation based off a Gwern comment based off some OpenAI tweets based off the vibes in OpenAI https://t.co/dae‚Ä¶",
    "id": "1880095432224960638",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880017504426463710" }]
  },
  {
    "in_reply_to_user_id": "593407733",
    "edit_history_tweet_ids": ["1880095235495325726"],
    "author_id": "593407733",
    "created_at": "2025-01-17T03:30:09.000Z",
    "text": "Paper: https://t.co/LceHuXgg6D\n\nWhat a privilege it was to discuss some ideas with @ma_nanye &amp; @sainingxie! Thank you ‚ù§Ô∏è",
    "id": "1880095235495325726",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880095232706113726" }]
  },
  {
    "attachments": { "media_keys": ["3_1880094840358350848"] },
    "edit_history_tweet_ids": ["1880095232706113726"],
    "author_id": "593407733",
    "created_at": "2025-01-17T03:30:08.000Z",
    "text": "Nice work from GDM on going beyond steps to scale test-time compute for diffusion models. \n\nI know this is not the first work, but it does a pretty good job of formalizing the problem, discussing:\n\n* Biases of verifiers \n* Mixing &amp; matching different verifiers\n* AND more https://t.co/T8Dg6wNSH5",
    "id": "1880095232706113726"
  },
  {
    "edit_history_tweet_ids": ["1880094188110508317"],
    "author_id": "192201556",
    "created_at": "2025-01-17T03:25:59.000Z",
    "text": "CEV is moral realism for nerds, the apex of mistake theory and a recipe for optimizing-literally-everything AGI disaster all in one package https://t.co/lY2GBhSbwj",
    "id": "1880094188110508317",
    "referenced_tweets": [{ "type": "quoted", "id": "1880088792700170412" }]
  },
  {
    "in_reply_to_user_id": "192201556",
    "edit_history_tweet_ids": ["1880093479273132363"],
    "author_id": "192201556",
    "created_at": "2025-01-17T03:23:10.000Z",
    "text": "*6 seconds\nit missing some very trivial considerations in Act 1 is very  interesting. r1-lite really is pretty weak, and it knows little, so I do wonder how small it is\nthough after V3, plausible that it's not small at all, indeed it could have up to like 400B with that speed",
    "id": "1880093479273132363",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880091555119472742" }]
  },
  {
    "edit_history_tweet_ids": ["1880091789438394803"],
    "author_id": "185910194",
    "created_at": "2025-01-17T03:16:27.000Z",
    "text": "RT @altryne: So much Open Source this week, we barely got through all of it!! \n\nüî• From 4M context windows, to emotional TTS from @Hailuo_AI‚Ä¶",
    "id": "1880091789438394803",
    "referenced_tweets": [{ "type": "retweeted", "id": "1880091250461929759" }]
  },
  {
    "attachments": { "media_keys": ["3_1880090821967355904"] },
    "edit_history_tweet_ids": ["1880091555119472742"],
    "author_id": "192201556",
    "created_at": "2025-01-17T03:15:31.000Z",
    "text": "&gt; this problem can be formalized pretty easily using basic propositions over sets.\nfascinatingly that's what I get on the second roll. It struggled with pure verbal logic, gave up and pulled out set notation. Shaved 4 secs off.\nReasoners iterating on tactics is a big deal. https://t.co/kjXEGjmZd4 https://t.co/LI00RHyW71",
    "id": "1880091555119472742",
    "referenced_tweets": [{ "type": "quoted", "id": "1880075517485088912" }]
  },
  {
    "in_reply_to_user_id": "1128159740599656448",
    "edit_history_tweet_ids": ["1880091220548210808"],
    "author_id": "1128159740599656448",
    "created_at": "2025-01-17T03:14:12.000Z",
    "text": "if i refresh the communist short form video app sometimes is replaced by a crypto gambling app",
    "id": "1880091220548210808",
    "referenced_tweets": [{ "type": "replied_to", "id": "1880091031561261385" }]
  },
  {
    "created_at": "2025-01-17T03:13:43.000Z",
    "edit_history_tweet_ids": ["1880091100742095006"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880088865425486322" }],
    "author_id": "788107483306942464",
    "text": "It feels different https://t.co/SNXjjl2d4J",
    "id": "1880091100742095006"
  },
  {
    "created_at": "2025-01-17T03:13:26.000Z",
    "edit_history_tweet_ids": ["1880091031561261385"],
    "author_id": "1128159740599656448",
    "attachments": { "media_keys": ["3_1880091028595867648"] },
    "text": "2025 app store looks just like expected https://t.co/z5oDfJS02p",
    "id": "1880091031561261385"
  },
  {
    "created_at": "2025-01-17T03:05:14.000Z",
    "edit_history_tweet_ids": ["1880088966478852560"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880067349182828952" }],
    "author_id": "2728439146",
    "text": "RT @tuturetom: ËøôÂèØËÉΩÊòØÁõÆÂâçÂØπ AI Agent Âíå‰∫∫ÂºÇÊ≠•Âçè‰ΩúÂÆûÁé∞ÊúÄÂ•ΩÁöÑÂºÄÊ∫êÈ°πÁõÆÁ§∫‰æã ‚ö°Ô∏è\n\n@LangChainAI Ê≠£ÂºèÂºÄÊ∫ê agent-inboxÔºåÊîØÊåÅ Agent ÂèØ‰ª•ÂºÇÊ≠•Ê∂àË¥π„ÄÅÂ§ÑÁêÜÂíåÊï¥ÁêÜÈÇÆ‰ª∂ÔºåÂèØ‰ª•ÊîØÊåÅÂ§ÑÁêÜÂÆå„ÄÅ‰∏≠Êñ≠ËØ∑Ê±ÇÔºåËÆ©Áî®Êà∑Á°ÆËÆ§ÔºåÊÅ¢Â§çÊâßË°åÁ≠âÂ§çÊùÇÁöÑ‰∫∫Êú∫Âçè‰Ωú‚Ä¶",
    "id": "1880088966478852560"
  },
  {
    "created_at": "2025-01-17T03:05:05.000Z",
    "edit_history_tweet_ids": ["1880088927782203417"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880079594713460947" }],
    "author_id": "2728439146",
    "text": "RT @diegohdora: @hwchase17 Hey @hwchase17 ! I really appreciate your focus on UX/UI , people don‚Äôt realize that‚Äôs one of the top 3 most imp‚Ä¶",
    "id": "1880088927782203417"
  },
  {
    "created_at": "2025-01-17T03:04:57.000Z",
    "edit_history_tweet_ids": ["1880088893795783013"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880077261598273555" }],
    "author_id": "2728439146",
    "text": "RT @aisankai: @hwchase17 Let‚Äôs go with LangGraph Studio!",
    "id": "1880088893795783013"
  },
  {
    "created_at": "2025-01-17T03:04:32.000Z",
    "edit_history_tweet_ids": ["1880088787705049148"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880066541158559780" }],
    "author_id": "2728439146",
    "text": "RT @EdenEmarco177: 2023: Everyone wanted to build chatbotsüí¨\n2024: Everyone built chatbots with clunky ui that no one uses\n2025: Agent Inbox‚Ä¶",
    "id": "1880088787705049148"
  },
  {
    "created_at": "2025-01-17T03:00:19.000Z",
    "edit_history_tweet_ids": ["1880087730673316070"],
    "in_reply_to_user_id": "1128159740599656448",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880085864359035343" }
    ],
    "author_id": "535358285",
    "text": "@nearcyan aw thx ‚ù§Ô∏è",
    "id": "1880087730673316070"
  },
  {
    "created_at": "2025-01-17T02:59:59.000Z",
    "edit_history_tweet_ids": ["1880087643964199260"],
    "note_tweet": {
      "entities": {
        "urls": [
          {
            "start": 379,
            "end": 402,
            "url": "https://t.co/jQxRXaaZov",
            "expanded_url": "https://hubs.la/Q032Wts00",
            "display_url": "hubs.la/Q032Wts00"
          }
        ]
      },
      "text": "DeepSeek-V3, the company's latest open LLM, surpasses Llama 3.1 405B and GPT-4o on key benchmarks, especially in coding and math tasks. \n\nUsing a mixture-of-experts architecture with 671 billion parameters, only 37 billion are active at once, DeepSeek V3 was trained at a low cost of $5.6 million ‚Äî less than a tenth of Llama 3.1 405B‚Äôs training cost. \n\nLearn more in The Batch: https://t.co/jQxRXaaZov"
    },
    "author_id": "992153930095251456",
    "text": "DeepSeek-V3, the company's latest open LLM, surpasses Llama 3.1 405B and GPT-4o on key benchmarks, especially in coding and math tasks. \n\nUsing a mixture-of-experts architecture with 671 billion parameters, only 37 billion are active at once, DeepSeek V3 was trained at a low cost‚Ä¶ https://t.co/a9PxiLOVKX",
    "id": "1880087643964199260"
  },
  {
    "created_at": "2025-01-17T02:57:58.000Z",
    "edit_history_tweet_ids": ["1880087136684363792"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880030384362254355" }],
    "author_id": "821092604821536768",
    "text": "RT @buccocapital: Zuck blaming Sheryl Sandberg for Facebook‚Äôs culture is pretty disappointing\n\nHe‚Äôs the Founder and CEO. The buck stops wit‚Ä¶",
    "id": "1880087136684363792"
  },
  {
    "created_at": "2025-01-17T02:54:06.000Z",
    "edit_history_tweet_ids": ["1880086163043807396"],
    "in_reply_to_user_id": "441465751",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880086159419928831" }
    ],
    "author_id": "441465751",
    "text": "abs: https://t.co/d6Ry2nJJT2",
    "id": "1880086163043807396"
  },
  {
    "created_at": "2025-01-17T02:54:05.000Z",
    "edit_history_tweet_ids": ["1880086159419928831"],
    "author_id": "441465751",
    "attachments": { "media_keys": ["3_1880084190261137408"] },
    "text": "Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps\n\nNew paper by Google DeepMind demonstrates how scaling up inference-time compute spent on search algorithms and verifiers for diffusion model sampling can improve sample quality. https://t.co/DbsBtNsCFw",
    "id": "1880086159419928831"
  },
  {
    "created_at": "2025-01-17T02:52:55.000Z",
    "edit_history_tweet_ids": ["1880085864359035343"],
    "in_reply_to_user_id": "535358285",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880083534569959591" }
    ],
    "author_id": "1128159740599656448",
    "text": "@DavidSHolz only some classes of bangers are good for the soul, and your soul should stay as-is!",
    "id": "1880085864359035343"
  },
  {
    "created_at": "2025-01-17T02:52:23.000Z",
    "edit_history_tweet_ids": ["1880085731542249615"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880024050048589841" }],
    "author_id": "821092604821536768",
    "attachments": { "media_keys": ["13_1880023941583941632"] },
    "text": "RT @SpaceX: Mechazilla has caught the Super Heavy booster! https://t.co/aq91TloYzY",
    "id": "1880085731542249615"
  },
  {
    "created_at": "2025-01-17T02:52:05.000Z",
    "edit_history_tweet_ids": ["1880085657730838930"],
    "in_reply_to_user_id": "441465751",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880073202317287725" }
    ],
    "author_id": "1128159740599656448",
    "text": "@iScienceLuvr billions.",
    "id": "1880085657730838930"
  },
  {
    "created_at": "2025-01-17T02:51:19.000Z",
    "edit_history_tweet_ids": ["1880085465132671135"],
    "author_id": "1128159740599656448",
    "attachments": { "media_keys": ["3_1880085421029486592"] },
    "text": "im so tired https://t.co/Twqw13tgiU",
    "id": "1880085465132671135"
  },
  {
    "created_at": "2025-01-17T02:45:49.000Z",
    "edit_history_tweet_ids": ["1880084078415999456"],
    "in_reply_to_user_id": "535358285",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880083534569959591" }
    ],
    "author_id": "441465751",
    "text": "@DavidSHolz @nearcyan i think he has his chosen ones",
    "id": "1880084078415999456"
  },
  {
    "created_at": "2025-01-17T02:44:27.000Z",
    "edit_history_tweet_ids": ["1880083737045791100"],
    "in_reply_to_user_id": "794433401591693312",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880083730032968134" }
    ],
    "author_id": "794433401591693312",
    "text": "https://t.co/EGchthMg9G",
    "id": "1880083737045791100"
  },
  {
    "created_at": "2025-01-17T02:44:26.000Z",
    "edit_history_tweet_ids": ["1880083730032968134"],
    "author_id": "794433401591693312",
    "attachments": { "media_keys": ["3_1880083011859017729"] },
    "text": "Google presents: Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps\n\n- Scales up the inference-time compute for verifiers and the search algorithms\n\n- This leads to substantial improvements in the quality of samples generated by diffusion models https://t.co/FAq3ccDuzB",
    "id": "1880083730032968134"
  },
  {
    "created_at": "2025-01-17T02:43:39.000Z",
    "edit_history_tweet_ids": ["1880083534569959591"],
    "in_reply_to_user_id": "1128159740599656448",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880070858879955247" }
    ],
    "author_id": "535358285",
    "text": "@nearcyan u never help me write bangers tho ü•∫",
    "id": "1880083534569959591"
  },
  {
    "created_at": "2025-01-17T02:41:31.000Z",
    "edit_history_tweet_ids": ["1880082997908779476"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880040195929829845" }],
    "author_id": "1513853205125681162",
    "text": "RT @atroyn: from one perspective, in-context learning was a clear demonstration of agi. @tszzl insisted this was true when it first happene‚Ä¶",
    "id": "1880082997908779476"
  },
  {
    "created_at": "2025-01-17T02:41:06.000Z",
    "edit_history_tweet_ids": ["1880082893789360544"],
    "author_id": "985281530070265862",
    "text": "Nvidia will be a robotics company at the end of the day, not just semiconductor.\nFew understand the moves they are doing at the lowest level from manufacturing up to software.\nClassic extend embrace extinguish.\nThey are going to sell robots and this is from Jensen straight up",
    "id": "1880082893789360544"
  },
  {
    "created_at": "2025-01-17T02:41:03.000Z",
    "edit_history_tweet_ids": ["1880082879398703215"],
    "in_reply_to_user_id": "794433401591693312",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880082877230248165" }
    ],
    "author_id": "794433401591693312",
    "text": "https://t.co/SfupFDeBuM",
    "id": "1880082879398703215"
  },
  {
    "created_at": "2025-01-17T02:41:02.000Z",
    "edit_history_tweet_ids": ["1880082877230248165"],
    "author_id": "794433401591693312",
    "attachments": { "media_keys": ["3_1880082583125651459"] },
    "text": "Meta presents: Learnings from Scaling Visual Tokenizers for Reconstruction and Generation\n\n- Explores scaling of visual tokenizers\n- Outperforms existing auto-encoders on video reconstruction, all with 2-5√ó fewer FLOPs https://t.co/lWpL75RN8x",
    "id": "1880082877230248165"
  },
  {
    "created_at": "2025-01-17T02:37:26.000Z",
    "edit_history_tweet_ids": ["1880081968639144295"],
    "in_reply_to_user_id": "192201556",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1879878219639447776" }
    ],
    "author_id": "192201556",
    "text": "@a_karvonen",
    "id": "1880081968639144295"
  },
  {
    "created_at": "2025-01-17T02:36:16.000Z",
    "edit_history_tweet_ids": ["1880081675943891402"],
    "author_id": "2434761475",
    "attachments": { "media_keys": ["3_1880081647779082241"] },
    "text": "y'all need to calm tf down https://t.co/OY7CynRIqo",
    "id": "1880081675943891402"
  },
  {
    "created_at": "2025-01-17T02:35:56.000Z",
    "edit_history_tweet_ids": ["1880081591390908780"],
    "author_id": "2465283662",
    "attachments": { "media_keys": ["3_1880081567747330048"] },
    "text": "https://t.co/LBnI1rp56I",
    "id": "1880081591390908780"
  },
  {
    "created_at": "2025-01-17T02:35:17.000Z",
    "edit_history_tweet_ids": ["1880081428450611543"],
    "referenced_tweets": [{ "type": "quoted", "id": "1879889549905822006" }],
    "author_id": "77370207",
    "text": "üôá üíÉüíØüôå https://t.co/qTYhNao8g8",
    "id": "1880081428450611543"
  },
  {
    "created_at": "2025-01-17T02:35:03.000Z",
    "edit_history_tweet_ids": ["1880081368530710994"],
    "author_id": "1299856802268377090",
    "attachments": { "media_keys": ["3_1880081004565786629"] },
    "text": "is this ASI? https://t.co/NgrggivqhI",
    "id": "1880081368530710994"
  },
  {
    "created_at": "2025-01-17T02:29:18.000Z",
    "edit_history_tweet_ids": ["1880079923861496197"],
    "in_reply_to_user_id": "192201556",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1879984731154260107" }
    ],
    "author_id": "192201556",
    "text": "Down to like 3% confidence, good thinking on my part to hype it up but not spread misinformation",
    "id": "1880079923861496197"
  },
  {
    "created_at": "2025-01-17T02:28:02.000Z",
    "edit_history_tweet_ids": ["1880079480015958207", "1880079605266280498"],
    "note_tweet": {
      "entities": {
        "urls": [
          {
            "start": 329,
            "end": 352,
            "url": "https://t.co/4jKSTaomCH",
            "expanded_url": "https://arxiv.org/abs/2411.13055",
            "display_url": "arxiv.org/abs/2411.13055"
          }
        ]
      },
      "text": "If you plan to do LLM training as the accelerators get faster and faster, you will be getting smaller and smaller returns on investment unless you demand a very faster interconnect.\n\nWith each generation compute speeds up much faster than network, so network becomes the bottleneck.\n\nSee this relatively recent paper for support https://t.co/4jKSTaomCH\n\nAnd once you get your fast network, benchmark and tune it up so that that fast on paper network is actually as fast as it can be."
    },
    "author_id": "1068360975898660864",
    "text": "If you plan to do LLM training as the accelerators get faster and faster, you will be getting smaller and smaller returns on investment unless you demand a very faster interconnect.\n\nWith each generation compute speeds up much faster than network, so network becomes the‚Ä¶ https://t.co/83STS5Dtf9",
    "id": "1880079605266280498"
  },
  {
    "created_at": "2025-01-17T02:18:06.000Z",
    "edit_history_tweet_ids": ["1880077105020674345"],
    "referenced_tweets": [{ "type": "quoted", "id": "1879275616559915379" }],
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1880076482967482368"] },
    "text": "so this is how much English censors on RedNote will be making. Annual TC at most USD 17500 if you max out benefits.\n\nI rest my case. (though fuck em censors, it is a bottom tier job) https://t.co/cnVgGa5ftY https://t.co/0IWUYPFJIJ",
    "id": "1880077105020674345"
  },
  {
    "created_at": "2025-01-17T02:02:36.000Z",
    "edit_history_tweet_ids": ["1880073202317287725"],
    "in_reply_to_user_id": "1128159740599656448",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880070858879955247" }
    ],
    "author_id": "441465751",
    "text": "@nearcyan what about the value of tweets ghostwritten for you",
    "id": "1880073202317287725"
  },
  {
    "created_at": "2025-01-17T02:00:44.000Z",
    "edit_history_tweet_ids": ["1880072732286783571"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880057696365494593" }],
    "author_id": "192201556",
    "text": "literally divine intervention in protection of the persecuted gamer race https://t.co/vA4lTwZCBY",
    "id": "1880072732286783571"
  },
  {
    "created_at": "2025-01-17T01:56:28.000Z",
    "edit_history_tweet_ids": ["1880071659472003267"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880071324892332237" }],
    "author_id": "85225861",
    "text": "RT @demi_network: Join us at the Democratize Intelligence Summit! üåü\nüóìÔ∏è January 24th,  2025\nüìç San Francisco\n\nWe're gathering 300+ ambitious‚Ä¶",
    "id": "1880071659472003267"
  },
  {
    "created_at": "2025-01-17T01:53:17.000Z",
    "edit_history_tweet_ids": ["1880070858879955247"],
    "author_id": "1128159740599656448",
    "text": "the value of tweets i have ghostwritten for others is now &gt;six figures",
    "id": "1880070858879955247"
  },
  {
    "created_at": "2025-01-17T01:50:38.000Z",
    "edit_history_tweet_ids": ["1880070193596232081"],
    "in_reply_to_user_id": "192201556",
    "referenced_tweets": [
      { "type": "quoted", "id": "1880069643022528955" },
      { "type": "replied_to", "id": "1880066066191405213" }
    ],
    "author_id": "192201556",
    "text": "full reasoning trace, it gets confused but recovers.\nThis is a new thing that has not been systematically happening in previous generation LLMs.\nhttps://t.co/voIIWG89vH",
    "id": "1880070193596232081"
  },
  {
    "created_at": "2025-01-17T01:44:44.000Z",
    "edit_history_tweet_ids": ["1880068707671765094"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880063836537188834" }],
    "author_id": "2434761475",
    "text": "I'll make an even bolder claim and predict that it won't grow 10 million times either. https://t.co/JGgvxrHZiP",
    "id": "1880068707671765094"
  },
  {
    "created_at": "2025-01-17T01:44:38.000Z",
    "edit_history_tweet_ids": ["1880068684343062629"],
    "referenced_tweets": [{ "type": "quoted", "id": "1879879143439163532" }],
    "author_id": "1454334880679010309",
    "text": "unpopular opinion - i like the original switch joycon slide mechanism more than the ones on switch 2 https://t.co/ovlsQW4pjc",
    "id": "1880068684343062629"
  },
  {
    "created_at": "2025-01-17T01:37:01.000Z",
    "edit_history_tweet_ids": ["1880066767478997255"],
    "in_reply_to_user_id": "192201556",
    "referenced_tweets": [
      { "type": "quoted", "id": "1879978677573939232" },
      { "type": "replied_to", "id": "1880066066191405213" }
    ],
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1880066758490628096"] },
    "text": "https://t.co/3QRK2g6vXa https://t.co/nL58S48ure",
    "id": "1880066767478997255"
  },
  {
    "created_at": "2025-01-17T01:34:14.000Z",
    "edit_history_tweet_ids": ["1880066066191405213"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880043625830404540" }],
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1880064702362869760"] },
    "text": "reminder your job is not \"safe\" just because some specific crappy LLM still can't score 170 on LSAT or whatever. This is the worst this tech will ever be, but you aren't even seeing the best of it that is available right now.\nThis one is a tiny research prototype served for free. https://t.co/Ks639vIVMz https://t.co/DVRfWkIhIl",
    "id": "1880066066191405213"
  },
  {
    "created_at": "2025-01-17T01:29:39.000Z",
    "edit_history_tweet_ids": ["1880064910291529744"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1879911097823891907" }],
    "author_id": "89538466",
    "attachments": { "media_keys": ["3_1879911095348973568"] },
    "text": "RT @ItsMattsLaw: Lawyers https://t.co/aF1pdh0RwF",
    "id": "1880064910291529744"
  },
  {
    "created_at": "2025-01-17T01:29:11.000Z",
    "edit_history_tweet_ids": ["1880064795287953458"],
    "author_id": "89538466",
    "attachments": { "media_keys": ["16_1880064782725742592"] },
    "text": "ü´° https://t.co/HdDEcN1Owd",
    "id": "1880064795287953458"
  },
  {
    "created_at": "2025-01-17T01:26:24.000Z",
    "edit_history_tweet_ids": ["1880064093786370215"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1877743475086766236" }],
    "author_id": "731538535795163136",
    "text": "RT @CohereForAI: Be sure to check out @yuntiandeng on January 18th as he will deliver a talk titled \"Implicit Chain-of-Thought: Internalizi‚Ä¶",
    "id": "1880064093786370215"
  },
  {
    "created_at": "2025-01-17T01:26:14.000Z",
    "edit_history_tweet_ids": ["1880064051621032019"],
    "in_reply_to_user_id": "33836629",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880057571668807830" }
    ],
    "author_id": "1365020011123773442",
    "text": "@karpathy @tszzl It probably is true that a lot less people are physically fit or even healthy (aka obesity) then wouldve been when it was a need to survive though",
    "id": "1880064051621032019"
  },
  {
    "created_at": "2025-01-17T01:20:06.000Z",
    "edit_history_tweet_ids": ["1880062508133982271"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880062287647764639" }],
    "author_id": "7284012",
    "text": "RT @Grimezsz: I think we might be about to enter an educational renaissance",
    "id": "1880062508133982271"
  },
  {
    "created_at": "2025-01-17T01:17:26.000Z",
    "edit_history_tweet_ids": ["1880061839016620099"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1879958389968843106" }],
    "author_id": "1068360975898660864",
    "text": "RT @jeffra45: üöÄ Super proud to share ArcticTraining, an open-source post-training framework to simplify and power new research directions!‚Ä¶",
    "id": "1880061839016620099"
  },
  {
    "created_at": "2025-01-17T01:16:58.000Z",
    "edit_history_tweet_ids": ["1880061718795284926"],
    "in_reply_to_user_id": "1705245484628226048",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880061451353878691" }
    ],
    "author_id": "1705245484628226048",
    "text": "@RichardMCNgo @elidourado I'd be reacting differently if this was accompanying an explanation of why human obsoleting AIs have a very low chance at succesfully building a dyson sphere/swarm/similar this fast given XYZ constraints. (Though I think it seems very hard to get to preposterous.)",
    "id": "1880061718795284926"
  },
  {
    "created_at": "2025-01-17T01:16:14.000Z",
    "edit_history_tweet_ids": ["1880061534359200133"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880060785646530972" }],
    "author_id": "245262377",
    "text": "RT @_dougsan: hacked @fullmoonapp to integrate with the MLX server, enabling you to run a larger model on your Mac and access it remotely w‚Ä¶",
    "id": "1880061534359200133"
  },
  {
    "created_at": "2025-01-17T01:15:54.000Z",
    "edit_history_tweet_ids": ["1880061451353878691"],
    "in_reply_to_user_id": "85225861",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880060992274694623" }
    ],
    "author_id": "1705245484628226048",
    "text": "@RichardMCNgo @elidourado I'm just trying to say \"Yes dyson sphere seems crazy, but we were accepting a crazy premise. Once you accept that premise, a lot of the craziness is baked in and IMO, most of the craziness was in the AI capabilities rather than the dyson sphere\".",
    "id": "1880061451353878691"
  },
  {
    "created_at": "2025-01-17T01:14:28.000Z",
    "edit_history_tweet_ids": ["1880061091335852071"],
    "referenced_tweets": [{ "type": "quoted", "id": "1879948904189554762" }],
    "author_id": "2353563199",
    "text": "Surprisingly, same here.\n\nHere's one I did yesterday from @MalekiSaeed: can you cover a 10x10 grid with 1x4 tiles? You can put the tiles horizontally or vertically, but they cannot overlap. https://t.co/OunnprZnNA",
    "id": "1880061091335852071"
  },
  {
    "created_at": "2025-01-17T01:14:05.000Z",
    "edit_history_tweet_ids": ["1880060992274694623"],
    "in_reply_to_user_id": "1705245484628226048",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880060632957170139" }
    ],
    "author_id": "85225861",
    "text": "@RyanPGreenblatt @elidourado to me it seems like the same vector (of negative reinforcement for doing it) just smaller magnitude",
    "id": "1880060992274694623"
  },
  {
    "created_at": "2025-01-17T01:12:39.000Z",
    "edit_history_tweet_ids": ["1880060632957170139"],
    "in_reply_to_user_id": "85225861",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880056345547899058" }
    ],
    "author_id": "1705245484628226048",
    "text": "@RichardMCNgo @elidourado I roughly agree this is a bad rhetorical move and that making fine-grained distinctions is good and mostly disagree this is what I am doing.\n\n\"seems strange\" doesn't equal \"should never happen\" and this is just from my perspective, not some absolute rule.",
    "id": "1880060632957170139"
  },
  {
    "created_at": "2025-01-17T01:10:50.000Z",
    "edit_history_tweet_ids": ["1880060177409507459"],
    "in_reply_to_user_id": "1529761561170124800",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880049130153938953" }
    ],
    "author_id": "1529761561170124800",
    "text": "Pocket Casts: https://t.co/PQ1IvXKek7\nRSS Feed: https://t.co/oXdrWecfCH",
    "id": "1880060177409507459"
  },
  {
    "created_at": "2025-01-17T01:07:26.000Z",
    "edit_history_tweet_ids": ["1880059321205326303"],
    "in_reply_to_user_id": "2465283662",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880059318785176043" }
    ],
    "author_id": "2465283662",
    "text": "github: https://t.co/vy68ARTizv",
    "id": "1880059321205326303"
  },
  {
    "created_at": "2025-01-17T01:07:26.000Z",
    "edit_history_tweet_ids": ["1880059318785176043"],
    "author_id": "2465283662",
    "attachments": { "media_keys": ["3_1880059210404110336"] },
    "text": "MiniMax-01 coder mode is now available in ai-gradio\n\npip install --upgrade \"ai-gradio[minimax]\"\n\nimport gradio as gr\nimport ai_gradio\n\ndemo = gr.load(\nname='minimax:MiniMax-Text-01',\nsrc=ai_gradio.registry,\ncoder=True\n)\ndemo.launch() https://t.co/dulIdUZ853",
    "id": "1880059318785176043"
  },
  {
    "created_at": "2025-01-17T01:06:14.000Z",
    "edit_history_tweet_ids": ["1880059020511441106"],
    "in_reply_to_user_id": "33836629",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880057571668807830" }
    ],
    "author_id": "800854096219471872",
    "text": "@karpathy @tszzl looks I will keep coding just for fun haha",
    "id": "1880059020511441106"
  },
  {
    "created_at": "2025-01-17T01:00:26.000Z",
    "edit_history_tweet_ids": ["1880057560277115069"],
    "in_reply_to_user_id": "1506911064050470915",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880056483825741868" }
    ],
    "author_id": "1506911064050470915",
    "text": "they‚Äôve had wins historically with features like structured sparsity or dynamic programming instructions so makes sense they keep trying their luck",
    "id": "1880057560277115069"
  },
  {
    "created_at": "2025-01-17T00:58:31.000Z",
    "edit_history_tweet_ids": ["1880057077718290512"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1879959251793375311" }],
    "author_id": "186420551",
    "text": "RT @itsPaulAi: Hugging Face released a free course on agents\n\nYou can learn how to create:\n\n- Code agents that solve problem with code\n- Re‚Ä¶",
    "id": "1880057077718290512"
  },
  {
    "created_at": "2025-01-17T00:56:56.000Z",
    "edit_history_tweet_ids": ["1880056679276200111"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880054813188055125" }],
    "author_id": "192201556",
    "attachments": {
      "media_keys": ["3_1880056159161233408", "3_1880056187804155904"]
    },
    "text": "in case you thought that Soviet study is a funny thing of the distant past, and a college educated American, arrogant intellectually boastful one at that, cannot be literally unable to process analogies using abstractions.\nLLMs are most needed by those least willing to use them https://t.co/ljiB5SPIir https://t.co/PmnueX291S",
    "id": "1880056679276200111"
  },
  {
    "created_at": "2025-01-17T00:56:10.000Z",
    "edit_history_tweet_ids": ["1880056483825741868"],
    "author_id": "1506911064050470915",
    "text": "NVIDIA‚Äôs marketing team is probably pushing to add FP-1 support",
    "id": "1880056483825741868"
  },
  {
    "created_at": "2025-01-17T00:55:37.000Z",
    "edit_history_tweet_ids": ["1880056345547899058"],
    "in_reply_to_user_id": "1705245484628226048",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880049193592799677" }
    ],
    "author_id": "85225861",
    "text": "@RyanPGreenblatt @elidourado You seem to be doing the rhetorical move of ‚Äúyou can‚Äôt call something preposterous if you also believe other preposterous things‚Äù? But this seems like a bad rhetorical move to me. I want people to make fine-grained distinctions between what is and isn‚Äôt preposterous.",
    "id": "1880056345547899058"
  },
  {
    "created_at": "2025-01-17T00:55:03.000Z",
    "edit_history_tweet_ids": ["1880056206271869160"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880036099256696878" }],
    "author_id": "17406365",
    "text": "common failure mode with GCP support, they'll tell you to contact your non-existent account manager any time something goes wrong.\nOP stuck with a $70k bill here. bad look for a company trying to court developers https://t.co/Cl6X5uLOvx",
    "id": "1880056206271869160"
  },
  {
    "created_at": "2025-01-17T00:54:45.000Z",
    "edit_history_tweet_ids": ["1880056127318380665"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880034622563840085" }],
    "author_id": "572851107",
    "text": "RT @Aloha_Aviator: @SpaceX ‚ÄúNASA has this phrase that they like: ‚ÄòFailure is not an option.‚Äô But failure has to be an option in art and in‚Ä¶",
    "id": "1880056127318380665"
  },
  {
    "created_at": "2025-01-17T00:53:10.000Z",
    "edit_history_tweet_ids": ["1880055731334049864"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880033318936199643" }],
    "author_id": "572851107",
    "text": "RT @SpaceX: Starship experienced a rapid unscheduled disassembly during its ascent burn. Teams will continue to review data from today's fl‚Ä¶",
    "id": "1880055731334049864"
  },
  {
    "created_at": "2025-01-17T00:52:34.000Z",
    "edit_history_tweet_ids": ["1880055581056332005"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880024050048589841" }],
    "author_id": "572851107",
    "text": "AYOOOO https://t.co/BDspzAaGY2",
    "id": "1880055581056332005"
  },
  {
    "created_at": "2025-01-17T00:51:19.000Z",
    "edit_history_tweet_ids": ["1880055263543324720"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1879202132106371497" }],
    "author_id": "48008938",
    "text": "RT @ziv_ravid: A new paper  ü•≥ü•≥ü•≥\nWe present \"Rate-In\" - a technique that helps neural networks better express their uncertainty during infer‚Ä¶",
    "id": "1880055263543324720"
  },
  {
    "created_at": "2025-01-17T00:51:02.000Z",
    "edit_history_tweet_ids": ["1880055194869964992"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1879202143913324832" }],
    "author_id": "48008938",
    "text": "RT @ziv_ravid: Check out our paper for detailed experiments and explanations on how we're making AI systems more reliable by helping them b‚Ä¶",
    "id": "1880055194869964992"
  },
  {
    "created_at": "2025-01-17T00:48:55.000Z",
    "edit_history_tweet_ids": ["1880054662717694105"],
    "author_id": "1506911064050470915",
    "text": "you feel a lot better about quantization if you say ‚ÄúFP-8‚Äù instead of ‚Äú1 byte‚Äù",
    "id": "1880054662717694105"
  },
  {
    "created_at": "2025-01-17T00:48:13.000Z",
    "edit_history_tweet_ids": ["1880054485135028468"],
    "in_reply_to_user_id": "1605274291569799168",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880054266301432186" }
    ],
    "author_id": "1605274291569799168",
    "text": "I'm always out here testing my puns in production.",
    "id": "1880054485135028468"
  },
  {
    "created_at": "2025-01-17T00:47:58.000Z",
    "edit_history_tweet_ids": ["1880054423004803294"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1879930741758341334" }],
    "author_id": "2728439146",
    "text": "RT @mdancho84: The price of the Python AI/ML Stack I've been using for 12 months:\n\nLangchain $0\nLanggraph $0\nScikit Learn $0\nH2O $0\nTorch $‚Ä¶",
    "id": "1880054423004803294"
  },
  {
    "created_at": "2025-01-17T00:47:21.000Z",
    "edit_history_tweet_ids": ["1880054266301432186"],
    "author_id": "1605274291569799168",
    "text": "After extensive A/B testing, we decided to rename them to X/Y testing.",
    "id": "1880054266301432186"
  },
  {
    "created_at": "2025-01-17T00:46:59.000Z",
    "edit_history_tweet_ids": ["1880054173552746674"],
    "in_reply_to_user_id": "192201556",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880052283255452007" }
    ],
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1880054160550187008"] },
    "text": "ah yeah sorry, wrong screenshot, this one was deleted https://t.co/vHmzHvpKGL",
    "id": "1880054173552746674"
  },
  {
    "created_at": "2025-01-17T00:44:40.000Z",
    "edit_history_tweet_ids": ["1880053591089750098"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880048546382221313" }],
    "author_id": "1605274291569799168",
    "text": "RT @ThorondorLLC: New project! Optimize your stable diffusion prompts via a \"chain-of-thought\" style iteration - built with DSPy https://t.‚Ä¶",
    "id": "1880053591089750098"
  },
  {
    "created_at": "2025-01-17T00:42:10.000Z",
    "edit_history_tweet_ids": ["1880052962359406960"],
    "author_id": "89538466",
    "text": "Procrastinating? I‚Äôm producing thinking tokens",
    "id": "1880052962359406960"
  },
  {
    "created_at": "2025-01-17T00:39:28.000Z",
    "edit_history_tweet_ids": ["1880052283255452007"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880050412163858811" }],
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1880051760707878912"] },
    "text": "&gt; post has been deleted\nIt's very bad form to notice that you've misread something, then twist your argument a bit and carry on as if your point \"still stands\" and wasn't premised on a confusion. I get the temptation but it, too, is ngmi behavior. It breathes death down my neck. https://t.co/JJXsVcp26G https://t.co/LfocxSLZni",
    "id": "1880052283255452007"
  },
  {
    "created_at": "2025-01-17T00:30:49.000Z",
    "edit_history_tweet_ids": ["1880050106583642577"],
    "in_reply_to_user_id": "89538466",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880049888718909828" }
    ],
    "author_id": "89538466",
    "text": "My tweets are mostly just a steam of thinking tokens that I found interesting upon reflection",
    "id": "1880050106583642577"
  },
  {
    "created_at": "2025-01-17T00:29:57.000Z",
    "edit_history_tweet_ids": ["1880049888718909828"],
    "author_id": "89538466",
    "text": "Podcasts and audiobooks are cool but they stop your brain from producing thinking tokens, and your brain desperately wants to produce them.",
    "id": "1880049888718909828"
  },
  {
    "created_at": "2025-01-17T00:26:56.000Z",
    "edit_history_tweet_ids": ["1880049130153938953"],
    "in_reply_to_user_id": "1529761561170124800",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880049125087146062" }
    ],
    "author_id": "1529761561170124800",
    "text": "Youtube: https://t.co/FziNt5bNSH\nApple Podcasts: https://t.co/EcMeo63UIj\nSpotify: https://t.co/7prC8bqYtH",
    "id": "1880049130153938953"
  },
  {
    "created_at": "2025-01-17T00:26:55.000Z",
    "edit_history_tweet_ids": ["1880049125087146062"],
    "author_id": "1529761561170124800",
    "note_tweet": {
      "text": "We've got a podcast!\n\nIn our first episode, Ege, Tamay and Jaime dig into:\n‚Ä¢ What they expect AI to look like by 2030\n‚Ä¢ Why economists are underestimating the likelihood of explosive growth\n‚Ä¢ The startling regularity in technological trends like Moore's Law\n‚Ä¢ Moravec‚Äôs paradox, and how we might overcome it\n\nAnd more more!\n\nTimestamps:\n00:00:00 Preview\n00:00:37 What is Epoch AI?\n00:02:32 Scaling Laws\n00:08:43 Key Drivers\n00:19:20 End of the Decade Predictions\n00:21:18 Bottlenecks: Power\n00:27:59 Bottlenecks: GPUs\n00:32:07 Bottlenecks: Data\n00:45:37 Bottlenecks: Latency\n00:56:18 Bottlenecks: Failure Rates\n01:03:55 AI Investment\n01:07:11 Automation\n01:12:10 Benchmarks & Moravec‚Äôs Paradox\n01:19:45 Economic Impact\n01:45:48 Open Questions & Takeaways"
    },
    "attachments": { "media_keys": ["13_1880028265378902017"] },
    "text": "We've got a podcast!\n\nIn our first episode, Ege, Tamay and Jaime dig into:\n‚Ä¢ What they expect AI to look like by 2030\n‚Ä¢ Why economists are underestimating the likelihood of explosive growth\n‚Ä¢ The startling regularity in technological trends like Moore's Law\n‚Ä¢ Moravec‚Äôs‚Ä¶ https://t.co/VenD6I6ysD https://t.co/zBAYtSy7jj",
    "id": "1880049125087146062"
  },
  {
    "created_at": "2025-01-17T00:25:23.000Z",
    "edit_history_tweet_ids": ["1880048736807842013"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880015645347311772" }],
    "author_id": "89538466",
    "text": "RT @bearlyai: Goldman Sachs CEO David Solomon says that AI can draft 95% of an S1 IPO prospectus ‚Äúin minutes‚Äù (a job that used to require a‚Ä¶",
    "id": "1880048736807842013"
  },
  {
    "created_at": "2025-01-17T00:19:42.000Z",
    "edit_history_tweet_ids": ["1880047306881540100"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880044234235138442" }],
    "author_id": "2465283662",
    "text": "RT @usebland: We‚Äôre now https://t.co/fCSpzK1pG2. New look. Same bold ideas.\nOh, and for fun‚Äîyou can call our AI and talk to yourself.\n\n‚òéÔ∏èTr‚Ä¶",
    "id": "1880047306881540100"
  },
  {
    "created_at": "2025-01-17T00:16:32.000Z",
    "edit_history_tweet_ids": ["1880046511129784774"],
    "author_id": "1082912120",
    "text": "The code you were shipping wasn‚Äôt code at all",
    "id": "1880046511129784774"
  },
  {
    "created_at": "2025-01-17T00:09:16.000Z",
    "edit_history_tweet_ids": ["1880044682601984170"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880034144622899560" }],
    "author_id": "192201556",
    "attachments": { "media_keys": ["16_1880044669121314816"] },
    "text": "these people scoffing at llm integration into workflows must be bullied for their own good\nit's very much like \"don't use the internet it's full of fake stuff, go to physical library\" ngmi attitude, but this time there won't be decades of a grace period https://t.co/YeVr7heuLu https://t.co/VrzuQ8Bt6V",
    "id": "1880044682601984170"
  },
  {
    "created_at": "2025-01-17T00:08:07.000Z",
    "edit_history_tweet_ids": ["1880044395141161132"],
    "author_id": "89538466",
    "text": "Legibility is an expensive luxury in the age of AI",
    "id": "1880044395141161132"
  },
  {
    "created_at": "2025-01-17T00:06:42.000Z",
    "edit_history_tweet_ids": ["1880044034984669330"],
    "in_reply_to_user_id": "823506858",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880043573195993507" }
    ],
    "author_id": "823506858",
    "note_tweet": {
      "text": "Ok annoyingly X doesn't allow polls in replies? So I guess respond or dm me with your answers pls üôè\n\nFrom the diagram above:\n1. Do you understand what OpenPipe does?\n2. Would you use OpenPipe?"
    },
    "text": "Ok annoyingly X doesn't allow polls in replies? So I guess respond or dm me with your answers pls üôè\n\nFrom the diagram above:\n1. Do you understand what OpenPipe does?\n2. Would you use OpenPipe? https://t.co/thO9TpwffA",
    "id": "1880044034984669330"
  },
  {
    "created_at": "2025-01-17T00:06:15.000Z",
    "edit_history_tweet_ids": ["1880043923860808011"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880043114796314644" }],
    "author_id": "192201556",
    "text": "RT @SharmakeFarah14: I actually remember such misalignment happening in Sydney, and suffice it to say that @gwern showed that case was enti‚Ä¶",
    "id": "1880043923860808011"
  },
  {
    "created_at": "2025-01-17T00:04:52.000Z",
    "edit_history_tweet_ids": ["1880043573195993507"],
    "author_id": "823506858",
    "note_tweet": {
      "text": "Workshopping a new landing page!\n\nDo you actually understand how OpenPipe works from this diagram? (poll below)"
    },
    "attachments": { "media_keys": ["3_1880043397404397568"] },
    "text": "Workshopping a new landing page!\n\nDo you actually understand how OpenPipe works from this diagram? (poll below) https://t.co/NAZZiptD1u https://t.co/aTdietM55f",
    "id": "1880043573195993507"
  },
  {
    "created_at": "2025-01-17T00:04:09.000Z",
    "edit_history_tweet_ids": ["1880043394069852653"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1880043313056858326" }],
    "author_id": "85225861",
    "text": "RT @RichardMCNgo: @elidourado @binarybits The last two decades have been a constant refrain of extremely smart domain experts saying that s‚Ä¶",
    "id": "1880043394069852653"
  },
  {
    "created_at": "2025-01-16T23:59:39.000Z",
    "edit_history_tweet_ids": ["1880042262056575091"],
    "in_reply_to_user_id": "192201556",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880042153524506716" }
    ],
    "author_id": "192201556",
    "attachments": { "media_keys": ["3_1880042208201478144"] },
    "text": "the only sane solution to search-driven capabilities, if we want the limits, is direct state control over compute and preregistered grant proposals for every. single. workload.\n(\"I aim\" meme needs to die, anthropic really dropped the ball with their system prompt in this respect) https://t.co/WaNMWWRSJa",
    "id": "1880042262056575091"
  },
  {
    "created_at": "2025-01-16T23:59:13.000Z",
    "edit_history_tweet_ids": ["1880042153524506716"],
    "referenced_tweets": [{ "type": "quoted", "id": "1880034689504932203" }],
    "author_id": "192201556",
    "note_tweet": {
      "text": "Smells like dark inference in here! Oy mate! You got a loicense for them attention 'ead matmuls? And don‚Äôt even think about unsupervised learning‚Äî we supervise e'rrything 'round these parts, ya cheeky poofta!\n‚Äì coming to the special AI economic zone near you in 2025"
    },
    "attachments": { "media_keys": ["3_1880041822359056384"] },
    "text": "Smells like dark inference in here! Oy mate! You got a loicense for them attention 'ead matmuls? And don‚Äôt even think about unsupervised learning‚Äî we supervise e'rrything 'round these parts, ya cheeky poofta!\n‚Äì coming to the special AI economic zone near you in 2025 https://t.co/KZawkxluLz https://t.co/Yv0Hx0IzlL https://t.co/pPiZhIB3mC",
    "id": "1880042153524506716"
  },
  {
    "created_at": "2025-01-16T23:58:12.000Z",
    "edit_history_tweet_ids": ["1880041895931543958"],
    "referenced_tweets": [{ "type": "retweeted", "id": "1879930096792015151" }],
    "author_id": "2465283662",
    "attachments": { "media_keys": ["3_1879929409802469389"] },
    "text": "RT @victormustar: FitDiT Virtual Try-on Demo on Hugging Face is wild ü§Ø\n‚¨áÔ∏è Anyone can try it online https://t.co/I69UgVxgvU",
    "id": "1880041895931543958"
  },
  {
    "created_at": "2025-01-16T23:51:34.000Z",
    "edit_history_tweet_ids": ["1880040228808978734"],
    "in_reply_to_user_id": "89538466",
    "referenced_tweets": [
      { "type": "replied_to", "id": "1880039677375443153" }
    ],
    "author_id": "89538466",
    "text": "Consultants optimize for legibility, and this is why they‚Äôre a negativity force in the hyperoptimized world of today",
    "id": "1880040228808978734"
  }
]
