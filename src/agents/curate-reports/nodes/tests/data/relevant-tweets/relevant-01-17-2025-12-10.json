[
  {
    "edit_history_tweet_ids": ["1880331306204373400"],
    "created_at": "2025-01-17T19:08:12.000Z",
    "text": "spent the last month building my own framework to train a diffusion model from scratch.  it was hard\n\nalmost like i just learned to cast an ancient spell that requires lots of mysterious steps and ingredients.  for a long time i was trying, and nothing happened.  but when itâ€¦ https://t.co/emrh8x2QOf",
    "author_id": "783098774130401280",
    "note_tweet": {
      "text": "spent the last month building my own framework to train a diffusion model from scratch.  it was hard\n\nalmost like i just learned to cast an ancient spell that requires lots of mysterious steps and ingredients.  for a long time i was trying, and nothing happened.  but when it worked it felt like magic\n\ni've learned a lot so wanted to share a bit ðŸ§µ\n\n- i'm doing *conditional* diffusion, trying to produce outputs x that depend on some inputs y.  my biggest blocker was that the architectural biases matter here â€“  you can NOT put the conditioning directly into the input, or the model will just learn to map y to x instead of using y to denoise the noisy input x. (the loss will go down but sampling will not work)\n- thus the diffusion world has a zoo of \"conditional\" architectures that can be a little challenging to adapt for your problem. but you have to use one or else things just won't work\n- apparently, architecture still matters in vision (sad).   initialization, residuals, and extra normalization can make all the difference\n- learning a small \"probe\" alongside your diffusion model is hugely valuable.  you can just cut the gradients to the probe so that it doesn't affect training.  this way you will know when you beat the baseline.  (i'm not sure if this is common practice but it was invaluable for me)\n- you need to incorporate sampling into training every-so-often. otherwise you will never figure out why your model doesn't work\n- the normalization is super important.  your input data needs to have ~mean 0 or std 1.  otherwise learning might not work,  or will be super slow\n- in diffusion a lot of things can have the same shape but be different \"types\" in the sense that they're incompatible in some way.  easy to make these bugs and the code will still run.  and you often can find them by checking that the norms, stds, and means are approximately correct\n- complex systems that you write from scratch will inevitably have tons of bugs.  you can start with trying to learn the identity function (in diffusion just set the noise to zeros).  if you can't do this something is broken.  in my case this helped me realize one of my losses had a sign flipped\n- in my opinion the loss after 1000 steps or so is usually a reliable signal for debugging architectural changes\n- diffusion people look down on DDPM as old and outdated but turns out it's still \"good enough for government work\" and worked fine for me eventually\n- wouldn't recommend the diffusers library.  not sure it's really being developed anymore.  heard the openai impl is much better\n- in general building systems from scratch is a slow and frustrating way to do research and i would recommend most people just start with a good codebase and tweaking it to fit your problem.  but if you build everything yourself you will learn a lot and feel a deep sense of satisfaction when it all starts working :)"
    },
    "id": "1880331306204373400"
  },
  {
    "edit_history_tweet_ids": ["1880328329666109446", "1880329810737786926"],
    "attachments": {
      "media_keys": ["3_1880328326608207873"]
    },
    "created_at": "2025-01-17T19:02:16.000Z",
    "text": "On LiveCodeBench, DeepSeek-R1 scores somewhere between o1 low reasoning and o1 medium reasoning \n\nNote that this looks to be full R1 and not the lite version from before https://t.co/2N663zHG9E https://t.co/ZUdSnGdsQR",
    "author_id": "1718879852827484160",
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880317308515897761"
      }
    ],
    "id": "1880329810737786926"
  },
  {
    "edit_history_tweet_ids": ["1880329359887856094"],
    "created_at": "2025-01-17T19:00:28.000Z",
    "text": "The big open question is that if you believe o1 is the same underlying model regardless of the reasoning level, what differentiates the reasoning levels and if these techniques are applied to R1, what would its performance look like? https://t.co/0Ic6i7GmjA",
    "author_id": "1718879852827484160",
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880328329666109446"
      }
    ],
    "id": "1880329359887856094"
  },
  {
    "edit_history_tweet_ids": ["1880326800762708217"],
    "created_at": "2025-01-17T18:50:18.000Z",
    "text": "Devin was only at ~14% 6 months ago and now SoTA is 65% \n\nSo I donâ€™t think we should write off coding agents just because they donâ€™t work well now https://t.co/hiUOi1KiL6",
    "author_id": "825766640",
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880004026957500434"
      }
    ],
    "id": "1880326800762708217"
  },
  {
    "edit_history_tweet_ids": ["1880324652184330603"],
    "created_at": "2025-01-17T18:41:46.000Z",
    "text": "RT @nomic_ai: Nomic Embed Vision is now under an Apache 2.0 License.\n\n- High quality, unified embedding space for image, text, and multimodâ€¦",
    "author_id": "1152315474484613123",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880313093097693212"
      }
    ],
    "id": "1880324652184330603"
  },
  {
    "edit_history_tweet_ids": ["1880323050798973295"],
    "attachments": {
      "media_keys": ["3_1880314443390685184"]
    },
    "created_at": "2025-01-17T18:35:24.000Z",
    "text": "We've updated custom instructions to make it easier to customize how ChatGPT responds to you.\n\nWith the new UI, you can tell ChatGPT the traits you want it to have, how you want it to talk to you, and any rules you want it to follow. https://t.co/BaXaqAw5cE",
    "author_id": "4398626122",
    "id": "1880323050798973295"
  },
  {
    "edit_history_tweet_ids": ["1880320444936708557"],
    "created_at": "2025-01-17T18:25:03.000Z",
    "text": "RT @dylhunn: o3-mini is my favorite model of all time. Itâ€™s unbelievably fast, and brilliant at code, especially debugging over large conteâ€¦",
    "author_id": "1513853205125681162",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880064256626106473"
      }
    ],
    "id": "1880320444936708557"
  },
  {
    "edit_history_tweet_ids": ["1880320405665087659"],
    "created_at": "2025-01-17T18:24:54.000Z",
    "text": "Iâ€™ve spent a LOT of time thinking about this problem.\n\nAt first, I believed that reasoning models like O1 would be limited to solving problems for which we already know the solutions. This assumption was based on the idea that these models are trained on problems with verifiableâ€¦ https://t.co/ikVob3p8Az https://t.co/ub3RPVq8TG",
    "author_id": "1825243643529027584",
    "note_tweet": {
      "text": "Iâ€™ve spent a LOT of time thinking about this problem.\n\nAt first, I believed that reasoning models like O1 would be limited to solving problems for which we already know the solutions. This assumption was based on the idea that these models are trained on problems with verifiable answers, such as those found in math or coding.\n\nHowever, Iâ€™ve come to realize this perspective was incomplete. Reasoning models donâ€™t memorize solutions - they learn methods and algorithms for approaching problems. This capability allows them to address unsolved problems using existing methodologies, even if humans havenâ€™t yet solved those problems. For this to happen, the models need the freedom to explore the problem space creatively. They must generate diverse outputs and avoid being overly constrained by current knowledge or assumptions. I believe this freedom to explore is also why TTC models excel on benchmarks like AidanBench.\n\nAs I thought more deeply about this, I began categorizing unsolved problems into two groups:\n1. Problems where we already possess the necessary mathematical tools but havenâ€™t yet discovered the solution.\n2. Problems that require the invention of entirely new mathematical tools, such as developing calculus or creating a novel branch of mathematics.\n\nIt now seems clear to me that reasoning models should be well-suited to solving problems in the first category.\n\nHowever, Iâ€™m much less confident about their ability to tackle problems in the second category. Making the creative leaps necessary to invent entirely new tools feels like a fundamentally different challenge that requires better architectures.\n\nThat said, large-scale reinforcement learning and search methods could potentially push these models toward developing more general or fundamental approaches for type 1 problems. Such advancements might also lead to insights that bridge the gap to type 2 problems. For example, if a particular method used for a type 2 problem also proves useful for a simpler type 1 problem (where we already know the answer), reasoning models might generalize/grok the solution to the type 1 problem in a way that uncovers insights applicable to the type 2 problem.\n\nThis process mirrors breakthroughs in physics, where unified or more general approaches - such as the Lagrangian, General Relativity, QM or the Path Integral reveal deeper connections and can be applied to simpler problems, to solve them in a shorter and more elegant way.\n\nEven if type 2 problems remain unsolved the space of type 1 problems is HUGE. Making these problems efficiently solvable in the near future would be a monumental achievement.\n\nI see this test-time-compute self-distillation paradigm mainly as an easy way to decrease the cost of solving (already solved problems and) type 1 problems."
    },
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880142612927246460"
      }
    ],
    "id": "1880320405665087659"
  },
  {
    "edit_history_tweet_ids": ["1880317736686874929"],
    "created_at": "2025-01-17T18:14:17.000Z",
    "text": "Helping a co-worker track down an issue running timm in a @huggingface Space, I ended up re-working the JupyterLab Space template. Attach a few @NVIDIAAI  L40S GPUs, some persistent storage, and it works quite nicely for training and evals! It's an improvement for Transformersâ€¦ https://t.co/sjOcgnqYVE",
    "author_id": "557902603",
    "note_tweet": {
      "entities": {
        "mentions": [
          {
            "start": 58,
            "end": 70,
            "username": "huggingface",
            "id": "778764142412984320"
          },
          {
            "start": 144,
            "end": 153,
            "username": "NVIDIAAI",
            "id": "740238495952736256"
          }
        ]
      },
      "text": "Helping a co-worker track down an issue running timm in a @huggingface Space, I ended up re-working the JupyterLab Space template. Attach a few @NVIDIAAI  L40S GPUs, some persistent storage, and it works quite nicely for training and evals! It's an improvement for Transformers use too."
    },
    "id": "1880317736686874929"
  },
  {
    "edit_history_tweet_ids": ["1880314518753956261"],
    "attachments": {
      "media_keys": ["3_1880314515331375104"]
    },
    "created_at": "2025-01-17T18:01:30.000Z",
    "text": "NVIDIA NIM with OpenAI library compatibility and the new cosmos-nemotron-34bÂ are now available in ai-gradio\n\nDevelopers can deploy apps with NVIDIA NIM in just a few lines of code\n\nFor example:\n\npip install \"ai-gradio[nvidia]\"\n\nimport gradio as gr\nimport ai_gradio\n\ndemo =â€¦ https://t.co/euTh3BxyjK https://t.co/Es6aAmk6zG",
    "author_id": "2465283662",
    "note_tweet": {
      "text": "NVIDIA NIM with OpenAI library compatibility and the new cosmos-nemotron-34bÂ are now available in ai-gradio\n\nDevelopers can deploy apps with NVIDIA NIM in just a few lines of code\n\nFor example:\n\npip install \"ai-gradio[nvidia]\"\n\nimport gradio as gr\nimport ai_gradio\n\ndemo = gr.load(\nÂ  Â  name='nvidia:nvidia/cosmos-nemotron-34b',\nÂ  Â  src=ai_gradio.registry,\n)\ndemo.launch()"
    },
    "id": "1880314518753956261"
  },
  {
    "edit_history_tweet_ids": ["1880314144936636629"],
    "attachments": {
      "media_keys": ["3_1880314142369710080"]
    },
    "created_at": "2025-01-17T18:00:01.000Z",
    "text": "ðŸ¤–ðŸ§  Memory-Enabled AI Chatbots\n\nCreate intelligent chatbots that maintain conversation context across sessions using LangChain and Gemini AI. Featuring MongoDB storage for seamless, persistent memory capabilities.\n\nLearn more: https://t.co/JTBgysAKJs https://t.co/z1nVfIQGKu",
    "author_id": "1589007443853340672",
    "id": "1880314144936636629"
  },
  {
    "edit_history_tweet_ids": ["1880309315334205704"],
    "created_at": "2025-01-17T17:40:49.000Z",
    "text": "RT @physical_int: FAST policies also follow language well and allow us to train the first generalist policies that can perform tasks out ofâ€¦",
    "author_id": "2236047510",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879963474287354141"
      }
    ],
    "id": "1880309315334205704"
  },
  {
    "edit_history_tweet_ids": ["1880308970088529951"],
    "created_at": "2025-01-17T17:39:27.000Z",
    "text": "This is true for regular software engineering as well\n\nUse LLMs to do 95% of the work that is time-consuming but doesn't require burning brain cells\n\nFocus your bandwidth on uplifting the quality of your software on the remaining 5% that matters\n\nAnd just like that you'll leaveâ€¦ https://t.co/CshK2XSgKn https://t.co/aDbAO1HPd4",
    "author_id": "1513853205125681162",
    "note_tweet": {
      "text": "This is true for regular software engineering as well\n\nUse LLMs to do 95% of the work that is time-consuming but doesn't require burning brain cells\n\nFocus your bandwidth on uplifting the quality of your software on the remaining 5% that matters\n\nAnd just like that you'll leave your competitors in the dust that ban LLMs, keep on recruiting more to make up for slow development pace and then run into Brook's law"
    },
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880015645347311772"
      }
    ],
    "id": "1880308970088529951"
  },
  {
    "edit_history_tweet_ids": ["1880306079273480520"],
    "created_at": "2025-01-17T17:27:58.000Z",
    "text": "Building with the Realtime API can be complex because of the low-latency, synchronous nature of voice interactions. This repo includes best practices weâ€™ve learned for managing this complexity, like:\n\n- Orchestrating agent handoffs (inspired by Swarm)\n- Background escalation toâ€¦ https://t.co/YikwP108TV",
    "author_id": "1633874951508721686",
    "in_reply_to_user_id": "1633874951508721686",
    "note_tweet": {
      "text": "Building with the Realtime API can be complex because of the low-latency, synchronous nature of voice interactions. This repo includes best practices weâ€™ve learned for managing this complexity, like:\n\n- Orchestrating agent handoffs (inspired by Swarm)\n- Background escalation to o1 for advanced decision making\n- Improving model instruction following by defining a state machine in the prompt\n- Demos of applying these patterns to customer service and front desk use cases"
    },
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880306077738365211"
      }
    ],
    "id": "1880306079273480520"
  },
  {
    "edit_history_tweet_ids": ["1880306077738365211"],
    "created_at": "2025-01-17T17:27:57.000Z",
    "text": "Weâ€™ve put together a reference implementation for building and orchestrating agentic patterns using the Realtime API. You can use this repo to prototype a voice app using multi-agent flows in less than 20 minutes! \n\nhttps://t.co/YdGZGt2Y6q",
    "author_id": "1633874951508721686",
    "id": "1880306077738365211"
  },
  {
    "edit_history_tweet_ids": ["1880305914936455682"],
    "attachments": {
      "media_keys": ["3_1880305742495846400"]
    },
    "created_at": "2025-01-17T17:27:19.000Z",
    "text": "Google recently published one of the best whitepaper on AI Agents. Everyone should read it.\n\nIt covers everything you need to know:\n&gt; Defines agents, components, and cognitive architectures.\n&gt; Explains tools: extensions, functions, and data stores.\n&gt; Covers learning techniques toâ€¦ https://t.co/aXcbkf9JAZ https://t.co/U06aIJzuLw",
    "author_id": "931470139",
    "note_tweet": {
      "text": "Google recently published one of the best whitepaper on AI Agents. Everyone should read it.\n\nIt covers everything you need to know:\n> Defines agents, components, and cognitive architectures.\n> Explains tools: extensions, functions, and data stores.\n> Covers learning techniques to improve agent performance.\n> Demonstrates building agents using LangChain and LangGraph."
    },
    "id": "1880305914936455682"
  },
  {
    "edit_history_tweet_ids": ["1880301149104099699"],
    "attachments": {
      "media_keys": ["3_1879827195130265600"]
    },
    "created_at": "2025-01-17T17:08:22.000Z",
    "text": "RT @pcuenq: By the way, did you notice that you can now comment on Hugging Face blog posts? ðŸš€ https://t.co/8hHemoayt2",
    "author_id": "186420551",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879827197583888810"
      }
    ],
    "id": "1880301149104099699"
  },
  {
    "edit_history_tweet_ids": ["1880301133517975771"],
    "created_at": "2025-01-17T17:08:19.000Z",
    "text": "RT @_fracapuano: How crazy cool is @huggingface - you can make highly customized models standard with a single line. Truly amazing https://â€¦",
    "author_id": "186420551",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880199578122875176"
      }
    ],
    "id": "1880301133517975771"
  },
  {
    "edit_history_tweet_ids": ["1880300742273302672"],
    "attachments": {
      "media_keys": ["3_1880300640242405376"]
    },
    "created_at": "2025-01-17T17:06:45.000Z",
    "text": "HF spaces is so underrated\n\ncheck it out if you dig AI/Agents and want to try out new apps https://t.co/q2E5u81V46",
    "author_id": "2465283662",
    "id": "1880300742273302672"
  },
  {
    "edit_history_tweet_ids": ["1880300661533012194"],
    "attachments": {
      "media_keys": ["3_1880299462226214912"]
    },
    "created_at": "2025-01-17T17:06:26.000Z",
    "text": "Scheduled Tasks with LangGraph\n\nChatGPT's new task scheduling feature is a fantastic UX for many AI applications. In this video, we show how to create the same UX for any LangGraph deployment.\n\nAll LangGraph deployments support scheduling, which can be easily set via the SDK. Inâ€¦ https://t.co/ZV9AJPamgy https://t.co/HdaPE1in7m",
    "author_id": "1589007443853340672",
    "note_tweet": {
      "text": "Scheduled Tasks with LangGraph\n\nChatGPT's new task scheduling feature is a fantastic UX for many AI applications. In this video, we show how to create the same UX for any LangGraph deployment.\n\nAll LangGraph deployments support scheduling, which can be easily set via the SDK. In this video we explain how to easily set it up for your deployment and highlight several of our \"ambient\" (in-the-background\") agent that use scheduling (social media / e-mail assistance).\n\nVideo:\nhttps://t.co/LlPjOTwoaw\n\nBlog post on ambient agents:\nhttps://t.co/0kPBybS7tl",
      "entities": {
        "urls": [
          {
            "start": 476,
            "end": 499,
            "url": "https://t.co/LlPjOTwoaw",
            "expanded_url": "https://youtu.be/9DRn9RpR2vA",
            "display_url": "youtu.be/9DRn9RpR2vA"
          },
          {
            "start": 530,
            "end": 553,
            "url": "https://t.co/0kPBybS7tl",
            "expanded_url": "https://blog.langchain.dev/introducing-ambient-agents/",
            "display_url": "blog.langchain.dev/introducing-amâ€¦"
          }
        ]
      }
    },
    "id": "1880300661533012194"
  },
  {
    "edit_history_tweet_ids": ["1880299047178715244"],
    "attachments": {
      "media_keys": ["3_1880299043902894080"]
    },
    "created_at": "2025-01-17T17:00:01.000Z",
    "text": "ðŸ¤– ðŸ§  Build AI Agents with Persistent Memory\n\nCreate enterprise-ready LangChain React agents that remember conversations across sessions using PostgreSQL and Claude-3-haiku LLM, featuring both Python &amp; Node.js implementations.\n\nLearn more: https://t.co/mUINsGaq58 https://t.co/jM5eSJqQpR",
    "author_id": "1589007443853340672",
    "id": "1880299047178715244"
  },
  {
    "created_at": "2025-01-17T16:41:26.000Z",
    "edit_history_tweet_ids": ["1880294367338094667"],
    "text": "Italians have been dropping alpha since a few thousand years and the world is just not paying attention. \n\nLinear layers, convolutions, transformers, recurrent networks, autograd with PyTorch and JAX code. 300 pages of alpha.\n\nThe PDF draft is free. \n\nLink in ðŸ§µ https://t.co/b1wXESFT0f",
    "author_id": "967757817355653120",
    "attachments": {
      "media_keys": ["3_1880294363399372800"]
    },
    "id": "1880294367338094667"
  },
  {
    "created_at": "2025-01-17T16:41:04.000Z",
    "edit_history_tweet_ids": ["1880294278125219890"],
    "text": "I built an example of how to use @AnthropicAI MCP with @AIatMeta Llama 3.3 70B. It's a simple CLI Agent managing a SQLite database in ~250 lines of code. https://t.co/UyKB5KV2zZ",
    "author_id": "1141052916570214400",
    "attachments": {
      "media_keys": ["3_1880294267664388096"]
    },
    "id": "1880294278125219890"
  },
  {
    "created_at": "2025-01-17T16:30:49.000Z",
    "edit_history_tweet_ids": ["1880291696149426340"],
    "text": "MiniMax-01 Coder is now available in anychat\n\nmade a working chess game in one shot\n\ntry it out https://t.co/BbRvtumbGh",
    "author_id": "2465283662",
    "attachments": {
      "media_keys": ["3_1880291595259363328"]
    },
    "id": "1880291696149426340"
  },
  {
    "created_at": "2025-01-17T16:28:53.000Z",
    "edit_history_tweet_ids": ["1880291212642644301"],
    "text": "Most ai frameworks arent good because the main selling point is that you can import a single line of code and just â€˜run_agent_loop()â€™ \n\nYou have 0 visibility about prompts, token usage, workflow etc. Oh you want some transparency? Hereâ€™s another library.\n\nThis isnt just for agentâ€¦ https://t.co/oIFhElM3uL https://t.co/x36x4o3utp",
    "author_id": "1718879852827484160",
    "note_tweet": {
      "text": "Most ai frameworks arent good because the main selling point is that you can import a single line of code and just â€˜run_agent_loop()â€™ \n\nYou have 0 visibility about prompts, token usage, workflow etc. Oh you want some transparency? Hereâ€™s another library.\n\nThis isnt just for agent stuff. There is a pretty well known RAG eval library whose entire selling point is that you run a single function with the names of the metrics you want. The only way to figure out what each metric is doing is to look at source."
    },
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880275616030945699"
      }
    ],
    "id": "1880291212642644301"
  },
  {
    "created_at": "2025-01-17T16:20:34.000Z",
    "edit_history_tweet_ids": ["1880289118212755846"],
    "text": "2025 is the year AI becomes background technology. People will quietly use LLMs every day to write, research and discuss what they care about. ASI debate is so 2024.",
    "author_id": "560473379",
    "id": "1880289118212755846"
  },
  {
    "created_at": "2025-01-17T16:10:54.000Z",
    "edit_history_tweet_ids": ["1880286685000253623"],
    "text": "It's been a bit! How does a new @huggingface accelerate release sound?\n\nv1.3.0 is now out, with a few small changes:\n\n* @PyTorch 2.0.0 is now the minimum we support, goodbye &lt;2.0!\n\n* We have a new example on how to properly do gradient accumulation with LM's!\n\n* Many bugfixes https://t.co/Nv7ZSD95fR https://t.co/Ih6bailSeT",
    "author_id": "721018777664626688",
    "note_tweet": {
      "text": "It's been a bit! How does a new @huggingface accelerate release sound?\n\nv1.3.0 is now out, with a few small changes:\n\n* @PyTorch 2.0.0 is now the minimum we support, goodbye <2.0!\n\n* We have a new example on how to properly do gradient accumulation with LM's!\n\n* Many bugfixes",
      "entities": {
        "mentions": [
          {
            "start": 32,
            "end": 44,
            "username": "huggingface",
            "id": "778764142412984320"
          },
          {
            "start": 120,
            "end": 128,
            "username": "PyTorch",
            "id": "776585502606721024"
          }
        ]
      }
    },
    "attachments": {
      "media_keys": ["3_1880286317105344513"]
    },
    "id": "1880286685000253623"
  },
  {
    "created_at": "2025-01-17T16:06:31.000Z",
    "edit_history_tweet_ids": ["1880285582464893129"],
    "text": "If you want to take it a step further you can check out my new courses on building with LLMs, RAGs, and AI Agents here: https://t.co/gKtLjAStAu\n\nI believe it compliments the book well.",
    "author_id": "3448284313",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880284480465957130"
      }
    ],
    "id": "1880285582464893129",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T16:06:06.000Z",
    "edit_history_tweet_ids": ["1880285476252446867"],
    "text": "RT @llamafactory_ai: Fine-tune Llama-3 on this Gradio web UI at Colab: https://t.co/io0oDCnN5Y",
    "author_id": "2465283662",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880285127974220068"
      }
    ],
    "id": "1880285476252446867"
  },
  {
    "created_at": "2025-01-17T16:05:47.000Z",
    "edit_history_tweet_ids": ["1880285395935719734"],
    "text": "We're kicking off 2025 with another Compound AI System Meetup with @lancedb in Mountain View on Jan 22! ðŸŽ‰ Join us for a deep dive into AI infrastructure and insights with Lu Qiu, Allison Wang, Holden Karau, and Dr. Sharon Zhou. ðŸ”—Save your spot: https://t.co/Q9sOGaIElJ",
    "author_id": "1335773237683240960",
    "id": "1880285395935719734"
  },
  {
    "created_at": "2025-01-17T16:02:08.000Z",
    "edit_history_tweet_ids": ["1880284477445767586"],
    "text": "Foundations of LLMs\n\nThis amazing new LLM book just dropped on arXiv. \n\n200+ pages!\n\nIt covers areas such as pre-training, prompting, and alignment methods. \n\nIt looks like a great intro to LLMs for devs and researchers. https://t.co/aw2EQT7EsC https://t.co/keIf9Lqcd4",
    "author_id": "3448284313",
    "note_tweet": {
      "text": "Foundations of LLMs\n\nThis amazing new LLM book just dropped on arXiv. \n\n200+ pages!\n\nIt covers areas such as pre-training, prompting, and alignment methods. \n\nIt looks like a great intro to LLMs for devs and researchers."
    },
    "attachments": {
      "media_keys": ["3_1880284392557301760"]
    },
    "id": "1880284477445767586"
  },
  {
    "note_tweet": {
      "entities": {
        "urls": [
          {
            "start": 401,
            "end": 424,
            "url": "https://t.co/9RrY7wm6L8",
            "expanded_url": "https://memgraph.com/blog/integrating-memgraph-llamaindex-genai-apps",
            "display_url": "memgraph.com/blog/integratiâ€¦"
          }
        ],
        "mentions": [
          {
            "start": 10,
            "end": 21,
            "username": "memgraphdb",
            "id": "735566660480970752"
          }
        ]
      },
      "text": "Learn how @memgraphdb and LlamaIndex work together to build agentic graph applications!\n\nKey takeaways from our recent webinar:\nðŸ” Explore GraphRAG for improved context retrieval in generative AI workflows\nðŸ¤– Discover agentic strategies to enhance RAG pipelines\nðŸš€ See how Memgraph complements LlamaIndex in constructing and querying knowledge graphs\n\nRead the full recap or watch the webinar recording:\nhttps://t.co/9RrY7wm6L8"
    },
    "created_at": "2025-01-17T15:58:50.000Z",
    "edit_history_tweet_ids": ["1880283649033269712"],
    "text": "Learn how @memgraphdb and LlamaIndex work together to build agentic graph applications!\n\nKey takeaways from our recent webinar:\nðŸ” Explore GraphRAG for improved context retrieval in generative AI workflows\nðŸ¤– Discover agentic strategies to enhance RAG pipelines\nðŸš€ See howâ€¦ https://t.co/a4SMTY5pC3 https://t.co/PaK8dt1m9y",
    "author_id": "1604278358296055808",
    "attachments": {
      "media_keys": ["3_1880283641470939137"]
    },
    "id": "1880283649033269712"
  },
  {
    "created_at": "2025-01-17T15:56:21.000Z",
    "edit_history_tweet_ids": ["1880283025595867631"],
    "text": "LLM and agents are still brittle but many researchers are already experimenting with them in different areas of medicine including mental health care. \n\nHere is an example of a new paper that proposes a multi-agent framework, AutoCBT, for Cognitive Behavioral Therapy.\n\nThe workâ€¦ https://t.co/9U318LAuLW https://t.co/87dJu3JM2x",
    "author_id": "3448284313",
    "note_tweet": {
      "text": "LLM and agents are still brittle but many researchers are already experimenting with them in different areas of medicine including mental health care. \n\nHere is an example of a new paper that proposes a multi-agent framework, AutoCBT, for Cognitive Behavioral Therapy.\n\nThe work proposes a general multi-agent framework that generates high-quality responses for single-turn psychological consultation scenarios.\n\nIt uses a combination of dynamic routing, memory, and supervisory mechanisms to enhance the autonomous ability of each agent.\n\nExperimental results show that AutoCBT can provide higher-quality automated psychological counseling services. AutoCBT improves dialogue quality compared to other purely prompt-based counseling frameworks."
    },
    "attachments": {
      "media_keys": ["3_1880278467838615552"]
    },
    "id": "1880283025595867631"
  },
  {
    "created_at": "2025-01-17T15:48:01.000Z",
    "edit_history_tweet_ids": ["1880280926724280418"],
    "text": "A few notes on Frames:\n\n- Frames has been engineered from the ground up for professional creative work. If you're in editorial, art direction, pre-vis, brand development, production, etc., this model is for you.\n- The prompting system has been designed for precision and depth. Itâ€¦ https://t.co/JOBCkFzYI8 https://t.co/v5EQOvxmqf",
    "author_id": "788107483306942464",
    "note_tweet": {
      "text": "A few notes on Frames:\n\n- Frames has been engineered from the ground up for professional creative work. If you're in editorial, art direction, pre-vis, brand development, production, etc., this model is for you.\n- The prompting system has been designed for precision and depth. It may take some initial exploration to master it. The more precise your input, the more nuanced your results will be.\n- Frames excels in understanding the subtleties that define good work: advanced texture rendering, natural lighting behavior, and thoughtful/interesting compositions. A big move beyond the rigid, symmetrical outputs you might be used to. Frames creates more naturalistic, cinematically composed results.\n- Frames has been optimized for creative exploration and artistic discovery, producing more nuanced and interesting creative results.\n- The model has been developed in close collaboration with our Studio team, ensuring it meets real-world professional standards.\n- This is our first public release of Frames. This is Frames v1. We have a clear roadmap for future developments, including enhanced controllability features and expanded style tools.\n- If you have any notes or feedback points, we would love to hear them."
    },
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880269616204976219"
      }
    ],
    "id": "1880280926724280418"
  },
  {
    "created_at": "2025-01-17T15:27:53.000Z",
    "edit_history_tweet_ids": ["1880275861401923619"],
    "text": "OmniThink is a new framework that emulates a human-like process of iterative expansion and reflection. \n\nIt's built to simulate the cognitive behavior of learners as they deepen their knowledge. \n\nCompared to RAG and role-playing, OmniThink can expand knowledge boundaries throughâ€¦ https://t.co/52MwdzeYpd https://t.co/KVt3sbsgNn",
    "author_id": "3448284313",
    "note_tweet": {
      "text": "OmniThink is a new framework that emulates a human-like process of iterative expansion and reflection. \n\nIt's built to simulate the cognitive behavior of learners as they deepen their knowledge. \n\nCompared to RAG and role-playing, OmniThink can expand knowledge boundaries through continuous reflection and exploration. This makes it ideal for use cases that require long-form generation."
    },
    "attachments": {
      "media_keys": ["3_1880274457945612288"]
    },
    "id": "1880275861401923619"
  },
  {
    "created_at": "2025-01-17T15:19:24.000Z",
    "edit_history_tweet_ids": ["1880273723661353436"],
    "text": "Everything that happened this week in open AI, a recap ðŸ¤ \n\nðŸ‘€ Multimodal\n- MiniCPM-o 2.6 is a new sota any-to-any model by @OpenBMB  (vision, speech and text!)\n- VideoChat-Flash-Qwen2.5-2B is new video multimodal models by @opengvlab that come in sizes 2B &amp; 7B in resolutions 224â€¦ https://t.co/OjYHYogtVn https://t.co/hkBlJxXYKj",
    "author_id": "1202267633049100291",
    "note_tweet": {
      "text": "Everything that happened this week in open AI, a recap ðŸ¤ \n\nðŸ‘€ Multimodal\n- MiniCPM-o 2.6 is a new sota any-to-any model by @OpenBMB  (vision, speech and text!)\n- VideoChat-Flash-Qwen2.5-2B is new video multimodal models by @opengvlab that come in sizes 2B & 7B in resolutions 224 & 448\n-  @BytedanceTalk released larger SA2VA that comes in 26B parameters\n- Dataset: VRC-Bench is a new diverse benchmark for multimodal LLM reasoning performance\n\nðŸ’¬ LLMs\n- MiniMax-Text-01 is a new huge language model (456B passive 45.9B active params) by MiniMaxAI with context length of 4M tokens ðŸ¤¯\n- Dataset: Sky-T1-data-17k is a diverse dataset used to train Sky-T1-32B\n- @kyutai_labs released Helium-1-Preview-2B is a new small multilingual LM\n- Wayfarer-12B is a new LLM able to write D&D ðŸ§™ðŸ»â€â™‚ï¸\n- ReaderLM-v2 is a new HTML parsing model by @JinaAI_  \n- @driaforall released, Dria-Agent-a-3B, new agentic coding model (Pythonic function calling) based on Qwen2.5 Coder\n- @UnslothAI released Phi-4, faster and memory efficient Llama 3.3\n\nðŸ–¼ï¸ Vision\n- MatchAnything is a new foundation model for matching\n- FitDit is a high-fidelity VTON model based on DiT architecture\n\nðŸ—£ï¸ Audio\n- OuteTTS-0.3-1B is a new multilingual text-to-speech model with voice cloning and emotion control capabilities\n\nðŸ“– Retrieval\n- lightblue released a new reranker based on Qwen2.5 LB-reranker-0.5B-v1.0 that can handle 95+ languages\n- cde-small-v2 is a new sota small retrieval model by @jxmnop",
      "entities": {
        "mentions": [
          {
            "start": 121,
            "end": 129,
            "username": "OpenBMB",
            "id": "1496119294844825600"
          },
          {
            "start": 221,
            "end": 231,
            "username": "opengvlab",
            "id": "1610948392489979904"
          },
          {
            "start": 287,
            "end": 301,
            "username": "BytedanceTalk",
            "id": "749868630221828096"
          },
          {
            "start": 655,
            "end": 667,
            "username": "kyutai_labs",
            "id": "1723735413578219520"
          },
          {
            "start": 825,
            "end": 833,
            "username": "JinaAI_",
            "id": "1245077804426952704"
          },
          {
            "start": 838,
            "end": 849,
            "username": "driaforall",
            "id": "1741850179068678144"
          },
          {
            "start": 955,
            "end": 965,
            "username": "UnslothAI",
            "id": "1730159888402395136"
          },
          {
            "start": 1445,
            "end": 1452,
            "username": "jxmnop",
            "id": "783098774130401280"
          }
        ]
      }
    },
    "attachments": {
      "media_keys": ["3_1880273055651377152"]
    },
    "id": "1880273723661353436"
  },
  {
    "created_at": "2025-01-17T15:10:42.000Z",
    "edit_history_tweet_ids": ["1880271537212657922"],
    "text": "Learn how to leverage @AnthropicAI's Model Context Protocol (MCP) to build modular AI agents using open LLMs, @OpenAI, or @GoogleDeepMind Gemini! ðŸ‘€Â \nExcited to publish an example of how to build a simple CLI Agent that manages an SQLite database using an Anthropic MCP server andâ€¦ https://t.co/A9Hehivnsw https://t.co/MlksbyZhNz",
    "author_id": "1141052916570214400",
    "note_tweet": {
      "text": "Learn how to leverage @AnthropicAI's Model Context Protocol (MCP) to build modular AI agents using open LLMs, @OpenAI, or @GoogleDeepMind Gemini! ðŸ‘€Â \nExcited to publish an example of how to build a simple CLI Agent that manages an SQLite database using an Anthropic MCP server and @AIatMeta Llama 3.3 70B.\n\nTL;DR:\nðŸ”„ How MCP decouples AI agent components for better maintainability\nðŸ› ï¸ Setting up a Docker-based MCP Server with SQLite\nðŸ”Œ Implementing a client that works with any LLM API (OpenAI, Gemini, open LLMs)\nðŸ“¦ Building an interactive CLI agent managing SQLite database operations\nðŸ¤– Converting MCP tools into LLM-compatible function calls\nðŸ“ Single file < 250 lines of code\n\nI am working on a small toolkit that makes building agents with an MCP server even easier! Stay tuned for that. ðŸš€",
      "entities": {
        "mentions": [
          {
            "start": 22,
            "end": 34,
            "username": "AnthropicAI",
            "id": "1353836358901501952"
          },
          {
            "start": 110,
            "end": 117,
            "username": "OpenAI",
            "id": "4398626122"
          },
          {
            "start": 122,
            "end": 137,
            "username": "GoogleDeepMind",
            "id": "4783690002"
          },
          {
            "start": 280,
            "end": 289,
            "username": "AIatMeta",
            "id": "1034844617261248512"
          }
        ]
      }
    },
    "attachments": {
      "media_keys": ["3_1880271189995565056"]
    },
    "id": "1880271537212657922"
  },
  {
    "created_at": "2025-01-17T15:06:44.000Z",
    "edit_history_tweet_ids": ["1880270539299983638"],
    "text": "RT @runwayml: Today we are releasing Frames. Our most advanced base model for image generation, offering unprecedented stylistic control anâ€¦",
    "author_id": "788107483306942464",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880269616204976219"
      }
    ],
    "id": "1880270539299983638"
  },
  {
    "created_at": "2025-01-17T15:06:22.000Z",
    "edit_history_tweet_ids": ["1880270444273811663"],
    "text": "RT @akshay_pachaar: I just created a RAG app to chat with GitHub!\n\nIt runs 100% locally, powered by Llama3.2 and uses GitIngest for parsingâ€¦",
    "author_id": "369777416",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880231619241668666"
      }
    ],
    "id": "1880270444273811663"
  },
  {
    "created_at": "2025-01-17T15:03:18.000Z",
    "edit_history_tweet_ids": ["1880269674442879032"],
    "text": "Folks at Answer AI wrote about their experience and impressions with Devin after trying 20+ tasks. \n\nhttps://t.co/uIhFKcdYyb https://t.co/uZgGr9dUsD",
    "author_id": "3448284313",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880269672156721448"
      }
    ],
    "attachments": {
      "media_keys": ["3_1880266810169139200"]
    },
    "id": "1880269674442879032",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:18.000Z",
    "edit_history_tweet_ids": ["1880269672156721448"],
    "text": "Yifan recently wrote about test-driven development with LLMs. \n\nhttps://t.co/Wxq3dbpdMh https://t.co/o9th4oVz3S",
    "author_id": "3448284313",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880269669552255045"
      }
    ],
    "attachments": {
      "media_keys": ["3_1880266467888816128"]
    },
    "id": "1880269672156721448",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:17.000Z",
    "edit_history_tweet_ids": ["1880269669552255045"],
    "text": "This article showcases some use cases for generalist software development agents with OpenHands. Prompt examples are provided. \n\nhttps://t.co/GnFQ04Pon4 https://t.co/5k2l8TcvJQ",
    "author_id": "3448284313",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880269666649854329"
      }
    ],
    "attachments": {
      "media_keys": ["3_1880264141677498368"]
    },
    "id": "1880269669552255045",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:16.000Z",
    "edit_history_tweet_ids": ["1880269666649854329"],
    "text": "David Crawshaw writes about his experience programming with LLMs and their potential for improving productivity. \n\nabout https://t.co/hAdIuSACq8",
    "author_id": "3448284313",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880269663902527903"
      }
    ],
    "attachments": {
      "media_keys": ["3_1880265530927370240"]
    },
    "id": "1880269666649854329",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:16.000Z",
    "edit_history_tweet_ids": ["1880269663902527903"],
    "text": "David Andersen goes deeper into the potential of LLMs to optimize code. \n\nhttps://t.co/NJk4cUIC6d https://t.co/5N8rGARyU8",
    "author_id": "3448284313",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880269661109121134"
      }
    ],
    "attachments": {
      "media_keys": ["3_1880265960780656640"]
    },
    "id": "1880269663902527903",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T15:03:15.000Z",
    "edit_history_tweet_ids": ["1880269661109121134"],
    "text": "Max Woolf found that prompting LLMs with \"write better code\" leads to interesting code improvements. \n\nhttps://t.co/pS3SCHYIMX https://t.co/dDklm7JFVc",
    "author_id": "3448284313",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880269659070689496"
      }
    ],
    "attachments": {
      "media_keys": ["3_1880264515327053824"]
    },
    "id": "1880269661109121134",
    "in_reply_to_user_id": "3448284313"
  },
  {
    "created_at": "2025-01-17T14:43:33.000Z",
    "edit_history_tweet_ids": ["1880264702498074709"],
    "text": "RT @llamafactory_ai: ðŸš€LLaMA Factory has been migrated to @Gradio 5!\nEnjoy the modern design of both light &amp; dark style.\n\nThank the Gradio tâ€¦",
    "author_id": "2465283662",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880226201341686053"
      }
    ],
    "id": "1880264702498074709"
  },
  {
    "created_at": "2025-01-17T14:12:01.000Z",
    "edit_history_tweet_ids": ["1880256766165856600"],
    "text": "ðŸ¤– From this week's issue: Cohere launched the early access program for North, an all-in-one secure AI workspace platform that empowers employees to significantly improve the quality and speed of their work. https://t.co/ul42TERskv",
    "author_id": "763368160527544320",
    "id": "1880256766165856600"
  },
  {
    "created_at": "2025-01-17T14:07:16.000Z",
    "edit_history_tweet_ids": ["1880255570520993995"],
    "text": "RT @davidberenstei: ðŸŽï¸ If you need speed during AI development, use synthetic data. You can now do so even faster MLX on Apple Silicon usinâ€¦",
    "author_id": "245262377",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880173504034730425"
      }
    ],
    "id": "1880255570520993995"
  },
  {
    "created_at": "2025-01-17T13:44:46.000Z",
    "id": "1880249909791846519",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880131877237100658"
      }
    ],
    "edit_history_tweet_ids": ["1880249909791846519"],
    "author_id": "1202267633049100291",
    "text": "RT @xtl994: We also release a stronger 26B Sa2VA model. @ByteDanceOSS  @Gradio  Please  see the Bytedance Opensource Huggingface: https://tâ€¦"
  },
  {
    "attachments": {
      "media_keys": ["3_1880246518738817024"]
    },
    "created_at": "2025-01-17T13:32:52.000Z",
    "id": "1880246916283515211",
    "edit_history_tweet_ids": ["1880246916283515211"],
    "author_id": "5483052",
    "text": "LSAT question screenshot generator where all of the answers are wrong but LSAT shaped ðŸ˜ˆ\n\nbuilt with Claude 3.5 Sonnet + html block on glif, link below https://t.co/MYU5wtmMue"
  },
  {
    "attachments": {
      "media_keys": ["3_1880236765308391424"]
    },
    "created_at": "2025-01-17T12:52:43.000Z",
    "id": "1880236809671831929",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880236806916260026"
      }
    ],
    "edit_history_tweet_ids": ["1880236809671831929"],
    "author_id": "1338631899422617600",
    "text": "Will static embeddings become the default models for text? Probably not, but they are worth checking anyway!\n\nðŸ“œ Read the full post here: https://t.co/s59l3QGg84 https://t.co/mmYjsfuELm",
    "in_reply_to_user_id": "1338631899422617600"
  },
  {
    "attachments": {
      "media_keys": ["3_1879900624432529408"]
    },
    "created_at": "2025-01-17T11:54:35.000Z",
    "id": "1880222181617193429",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879900990314512605"
      }
    ],
    "edit_history_tweet_ids": ["1880222181617193429"],
    "author_id": "3448284313",
    "text": "RT @omarsar0: What a great resource to learn how others are building with LLMs and AI agents. https://t.co/nnm6aub7Zu"
  },
  {
    "attachments": {
      "media_keys": ["3_1880216023279800320"]
    },
    "note_tweet": {
      "entities": {
        "urls": [
          {
            "start": 258,
            "end": 281,
            "url": "https://t.co/1m1iyHYmNg",
            "expanded_url": "http://therundown.ai/p/nigerias-ai-tutoring-triumph",
            "display_url": "therundown.ai/p/nigerias-ai-â€¦"
          }
        ]
      },
      "text": "Top stories in AI today:\n\n-AI tutoring shows stunning results\n-Apple pulls AI news summaries after false headlines\n-Transform your resume with AI feedback\n-Microsoft unveils AI model for materials discovery\n-4 new AI tools & 4 job opportunities \n\nRead more: https://t.co/1m1iyHYmNg"
    },
    "created_at": "2025-01-17T11:30:07.000Z",
    "id": "1880216025884418535",
    "edit_history_tweet_ids": ["1880216025884418535"],
    "author_id": "731917653506318336",
    "text": "Top stories in AI today:\n\n-AI tutoring shows stunning results\n-Apple pulls AI news summaries after false headlines\n-Transform your resume with AI feedback\n-Microsoft unveils AI model for materials discovery\n-4 new AI tools &amp; 4 job opportunities \n\nRead more:â€¦ https://t.co/OVe5nF2RcT https://t.co/gkiyaY3Qfz"
  },
  {
    "created_at": "2025-01-17T11:17:10.000Z",
    "id": "1880212766944112834",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879932498660225257"
      }
    ],
    "edit_history_tweet_ids": ["1880212766944112834"],
    "author_id": "1188812448767336449",
    "text": "RT @benediktstroebl: HALâ€™s solution: Inspired by efforts like HELM or the Open LLM Leaderboard, HAL combines a standardized evaluation harnâ€¦"
  },
  {
    "created_at": "2025-01-17T11:10:03.000Z",
    "id": "1880210972343947673",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879696157452144836"
      }
    ],
    "edit_history_tweet_ids": ["1880210972343947673"],
    "author_id": "1271482878958940160",
    "text": "RT @TheTuringPost: A new MiniMax-01 series of models from @MiniMax__AI combines high performance and handles extremely long contexts.\n\n- Itâ€¦"
  },
  {
    "created_at": "2025-01-17T09:48:26.000Z",
    "id": "1880190433768403383",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880187575664799977"
      }
    ],
    "edit_history_tweet_ids": ["1880190433768403383"],
    "author_id": "912955216559054848",
    "text": "RT @alexvoica: Today, @synthesiaIO was ranked the UK's fastest growing generative AI company in the inaugural edition ofÂ @thetimes Â 100 Tecâ€¦"
  },
  {
    "created_at": "2025-01-17T09:12:09.000Z",
    "id": "1880181304173756457",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879829357016789113"
      }
    ],
    "edit_history_tweet_ids": ["1880181304173756457"],
    "author_id": "2854214132",
    "text": "RT @_philschmid: How can we build domain-specific reasoning models? By using a two-stage training process (complex reasoning on verifiableâ€¦"
  },
  {
    "created_at": "2025-01-17T09:09:07.000Z",
    "id": "1880180540768415844",
    "edit_history_tweet_ids": ["1880180464616722544", "1880180540768415844"],
    "author_id": "982939260",
    "text": "I'm still blown away by how good the Kokoro-82M TTS model is.\nhttps://t.co/nfBJ0zzFUP"
  },
  {
    "created_at": "2025-01-17T09:07:21.000Z",
    "id": "1880180097631818168",
    "edit_history_tweet_ids": ["1880180097631818168"],
    "author_id": "982939260",
    "text": "Someone made an X bot that uses chutes for image generation, pretty neat! https://t.co/EaR7Bf5W7K\n(keep in mind this is not the chutes team/our agent system)"
  },
  {
    "attachments": {
      "media_keys": ["3_1880028823590207488"]
    },
    "created_at": "2025-01-17T09:04:29.000Z",
    "id": "1880179374881968394",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880029249807216860"
      }
    ],
    "edit_history_tweet_ids": ["1880179374881968394"],
    "author_id": "821092604821536768",
    "text": "RT @damekdavis: taught my first class at penn today. \n\ntopic: optimization in PyTorch https://t.co/HWpGVcOqs1"
  },
  {
    "attachments": {
      "media_keys": ["3_1880175760935092224"]
    },
    "created_at": "2025-01-17T08:53:11.000Z",
    "id": "1880176528916639993",
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1879932823668498576"
      }
    ],
    "edit_history_tweet_ids": ["1880176528916639993"],
    "author_id": "1188812448767336449",
    "text": "I'd love to know how results on GAIA in HAL have been \"reproduced by the HAL team\" given that the test set is private and only 4 people have access to it.\n\nIf you're evaluating only on the validation set (would be fair imo), why are you reporting scores on \"450 questions\"? https://t.co/iYlOdMRIse https://t.co/AByKTRRJH5"
  },
  {
    "attachments": {
      "media_keys": ["3_1880173549505105920"]
    },
    "created_at": "2025-01-17T08:43:09.000Z",
    "id": "1880174003735949661",
    "edit_history_tweet_ids": ["1880174003735949661"],
    "author_id": "192201556",
    "text": "nvidia has published and promptly deleted their LLaMA 3.1 8B finetune with Medusa speculative decoding. Nvidia please bring it back at least for research value https://t.co/LBDhr32bWB"
  },
  {
    "attachments": {
      "media_keys": ["3_1880102565548793856"]
    },
    "created_at": "2025-01-17T08:11:38.000Z",
    "id": "1880166074500673645",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880106360731496661"
      }
    ],
    "edit_history_tweet_ids": ["1880166074500673645"],
    "author_id": "2854214132",
    "text": "RT @bycloudai: someone has finally done it \ntest time compute + diffusion models\na really interesting one for sure ðŸ§µ https://t.co/BxvujCvpU2"
  },
  {
    "created_at": "2025-01-17T08:11:11.000Z",
    "id": "1880165960717656154",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880165958825963732"
      }
    ],
    "edit_history_tweet_ids": ["1880165960717656154"],
    "author_id": "1026989978599940101",
    "text": "blog on Hugging Face Daily Papers that is updated on a daily basis\n: https://t.co/arOTmuTGec",
    "in_reply_to_user_id": "1026989978599940101"
  },
  {
    "attachments": {
      "media_keys": ["3_1880164548650639360", "3_1880164548646432774"]
    },
    "created_at": "2025-01-17T08:11:10.000Z",
    "id": "1880165956133220384",
    "edit_history_tweet_ids": ["1880165956133220384"],
    "author_id": "1026989978599940101",
    "text": "updates on ai-paper-reviewer!\n\ncore\nâœ¦ supporting open source Layout Parsing model from @OpenDataLab_AI \nâœ¦ scrapping papers from @openreviewnet \n \nblog \nâœ¦ display papers by the dates added in @huggingface Daily Papers. Up to 3 latest days are managed, then archived\n\nlink ðŸ‘‡ https://t.co/IuoyZpizTc"
  },
  {
    "attachments": {
      "media_keys": ["3_1880162501838376960"]
    },
    "created_at": "2025-01-17T08:03:31.000Z",
    "id": "1880164031987589413",
    "note_tweet": {
      "text": "Learnings from Scaling Visual Tokenizers for Reconstruction and Generation\n\nNew paper from Meta studies how scaling the autoencoder bottleneck affects reconstruction and generation.\n\n* Scaling the encoder doesn't necessarily improve reconstruction or generation performance. Small encoders are optimal\n\n* Increasing the bottleneck size enhances reconstruction quality but degrades generation performance when too large\n\n* Scaling the decoder improves reconstruction, but has more minimal benefits in generation\n\n* The perceptual and GAN losses trades off image fidelity (SSIM/PSNR) for image quality (FID/IS), effectively transforming the decoder into a generative model\n\n* Videos follow same reconstruction trends as images, but achieve better reconstruction metrics given the same compression rate of pixels per channel"
    },
    "edit_history_tweet_ids": ["1880164031987589413"],
    "author_id": "441465751",
    "text": "Learnings from Scaling Visual Tokenizers for Reconstruction and Generation\n\nNew paper from Meta studies how scaling the autoencoder bottleneck affects reconstruction and generation.\n\n* Scaling the encoder doesn't necessarily improve reconstruction or generation performance. Smallâ€¦ https://t.co/O1CfFlpMT9 https://t.co/c86nXuKk6x"
  },
  {
    "created_at": "2025-01-17T07:56:08.000Z",
    "id": "1880162171323314526",
    "edit_history_tweet_ids": ["1880162171323314526"],
    "author_id": "967757817355653120",
    "text": "If we think of human intelligence as being the result of random mutations and natural selection, I still wonder why many people have a hard time accepting The Bitter Lesson.\n\nIn case you missed it: https://t.co/0K530YQJLN"
  },
  {
    "attachments": {
      "media_keys": ["3_1880160284964216832"]
    },
    "created_at": "2025-01-17T07:50:34.000Z",
    "id": "1880160772380409942",
    "edit_history_tweet_ids": ["1880160772380409942"],
    "author_id": "441465751",
    "text": "Vision-Language Models Do Not Understand Negation\n\nCLIP-based models exhibit a strong affirmation bias, finetuning with synthetic negation data can help address the challenge. https://t.co/cgo8Noa34y"
  },
  {
    "attachments": {
      "media_keys": ["13_1690052888519680001"]
    },
    "created_at": "2025-01-17T07:43:14.000Z",
    "id": "1880158928656560488",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1879331049383334187"
      }
    ],
    "edit_history_tweet_ids": ["1880158928656560488"],
    "author_id": "2895499182",
    "text": "Blog post for TransformerÂ²: Self-Adaptive LLMs\n\nhttps://t.co/AyeFdqEKsd\n\nEventually, neural network weights should be as adaptive as the Octopus ðŸ™\nhttps://t.co/me7urXJ6BS",
    "in_reply_to_user_id": "2895499182"
  },
  {
    "attachments": {
      "media_keys": ["3_1880158172632981505"]
    },
    "created_at": "2025-01-17T07:41:52.000Z",
    "id": "1880158582332907801",
    "edit_history_tweet_ids": ["1880158582332907801"],
    "author_id": "441465751",
    "text": "Aligning Instruction Tuning with Pre-training\n\nDetermines differences between pretraining corpus and SFT corpus and generates instruction data for the difference set. Evaluations on three fully\nopen LLMs across eight benchmarks demonstrate\nconsistent performance improvements. https://t.co/1jJxiv5q2T"
  },
  {
    "created_at": "2025-01-17T07:37:04.000Z",
    "id": "1880157373119201612",
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880129024737104118"
      }
    ],
    "edit_history_tweet_ids": ["1880157373119201612"],
    "author_id": "175282603",
    "text": "We tried really really hard to make Devin (the coding agent) work for us.\n\nBut it didn't.\n\nCheck out Hamel's detailed writeup blog linked below, describing the many tasks of many types we explored, nearly all of which failed.\n\nWe remain less than bullish on agents... https://t.co/MZwj5GaEKL"
  },
  {
    "edit_history_tweet_ids": ["1880147465485316443"],
    "author_id": "2282571910",
    "created_at": "2025-01-17T06:57:41.000Z",
    "text": "RT @SakanaAILabs: Weâ€™re excited to introduce TransformerÂ², a machine learning system that dynamically adjusts its weights for various tasksâ€¦",
    "id": "1880147465485316443",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879325924887613931"
      }
    ]
  },
  {
    "attachments": {
      "media_keys": ["3_1880140588235759616"]
    },
    "edit_history_tweet_ids": ["1880141924310397090"],
    "note_tweet": {
      "text": "# Suchir's Last Essay\n\nSuchir should be remembered as a brilliant researcher and exceptionally kind human. Around the time he left OpenAI, he shared with me his vision for an alternative research approach to AGI. I encouraged him to flesh out his ideas into an essay, which he drafted but tragically did not have the chance to complete. The premise: intelligence *is* data efficiency - and we can do much better than the current paradigm of scaling autoregressive models.\n\nI'm sharing his essay draft below in its original form. As we in the ML community work to improve and benchmark data efficiency, let's keep Suchir's contributions in mind, and honor his legacy as a brave, creative, and fiercely independent researcher.\n\nSuchir was our first summer intern at my previous startup, where he did outstanding work on real-time video understanding. I miss his friendship, insights, and kindness."
    },
    "author_id": "1075605139",
    "created_at": "2025-01-17T06:35:40.000Z",
    "text": "# Suchir's Last Essay\n\nSuchir should be remembered as a brilliant researcher and exceptionally kind human. Around the time he left OpenAI, he shared with me his vision for an alternative research approach to AGI. I encouraged him to flesh out his ideas into an essay, which heâ€¦ https://t.co/TSyqqKkErj https://t.co/AlzjbvmO5T",
    "id": "1880141924310397090"
  },
  {
    "attachments": {
      "media_keys": ["7_1880129304605958144"]
    },
    "edit_history_tweet_ids": ["1880129375368265780"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:45:48.000Z",
    "text": "ðŸª¶ MagicQuill\n\nAn Intelligent Interactive Image Editing System https://t.co/vfUMp0CsK3",
    "id": "1880129375368265780"
  },
  {
    "in_reply_to_user_id": "825766640",
    "attachments": {
      "media_keys": ["3_1880125562850791424"]
    },
    "edit_history_tweet_ids": ["1880129026435756153"],
    "author_id": "825766640",
    "created_at": "2025-01-17T05:44:25.000Z",
    "text": "This describes our final verdict.  We really tried to like it. \n\nI'm hopeful that as models improve, this genre of product will work much better soon.\n\nhttps://t.co/DDqzoAXKkl https://t.co/bJPOhfwRO5",
    "id": "1880129026435756153",
    "referenced_tweets": [
      {
        "type": "replied_to",
        "id": "1880129024737104118"
      }
    ]
  },
  {
    "attachments": {
      "media_keys": ["3_1880122283366514688"]
    },
    "edit_history_tweet_ids": ["1880129024737104118"],
    "author_id": "825766640",
    "created_at": "2025-01-17T05:44:25.000Z",
    "text": "New post re: Devin (the AI SWE).  We couldn't find many reviews of people using it for real tasks, so we went MKBHD mode and put Devin through its paces.\n\nWe documented our findings here.  Would love to know if others have had a different experience.\n\nhttps://t.co/DDqzoAXKkl https://t.co/XNxYbby5VF",
    "id": "1880129024737104118"
  },
  {
    "attachments": {
      "media_keys": ["3_1880127436353941504"]
    },
    "edit_history_tweet_ids": ["1880127521569796326"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:38:26.000Z",
    "text": "text-generation-webui\n\nA Gradio web UI for Large Language Models with support for multiple inference backends. https://t.co/3YIz6qVsir",
    "id": "1880127521569796326"
  },
  {
    "attachments": {
      "media_keys": ["7_1880124345634209792"]
    },
    "edit_history_tweet_ids": ["1880124384603668584"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:25:58.000Z",
    "text": "SynthLight\n\nPortrait Relighting with Diffusion Model by Learning to Re-render Synthetic Faces https://t.co/PnX0j4r8mN",
    "id": "1880124384603668584"
  },
  {
    "attachments": {
      "media_keys": ["3_1880123887335202816"]
    },
    "edit_history_tweet_ids": ["1880123934512947305"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:24:11.000Z",
    "text": "FAST\n\nEfficient Action Tokenization for Vision-Language-Action Models https://t.co/6ZQTSivWER",
    "id": "1880123934512947305"
  },
  {
    "attachments": {
      "media_keys": ["3_1880122687088967680"]
    },
    "edit_history_tweet_ids": ["1880122745037693203"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:19:28.000Z",
    "text": "AnyStory\n\nTowards Unified Single and Multiple Subject Personalization in Text-to-Image Generation https://t.co/qm2LqTb7am",
    "id": "1880122745037693203"
  },
  {
    "edit_history_tweet_ids": ["1880122322713256380"],
    "author_id": "175282603",
    "created_at": "2025-01-17T05:17:47.000Z",
    "text": "RT @UnslothAI: You can finetune Phi-4 for free on @Kaggle now!\n\nYou'll learn how to:\nâ€¢ Prepare your dataset\nâ€¢ Train Phi-4 via Kaggle's freeâ€¦",
    "id": "1880122322713256380",
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879942441538609583"
      }
    ]
  },
  {
    "attachments": {
      "media_keys": ["7_1880121638391361537"]
    },
    "edit_history_tweet_ids": ["1880121732150992940"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T05:15:26.000Z",
    "text": "CaPa\n\nCarve-n-Paint Synthesis for Efficient 4K Textured Mesh Generation https://t.co/QPncctgon9",
    "id": "1880121732150992940"
  },
  {
    "attachments": {
      "media_keys": ["3_1880120431652360192", "3_1880120515337076736"]
    },
    "edit_history_tweet_ids": ["1880120901481689171"],
    "author_id": "192201556",
    "created_at": "2025-01-17T05:12:08.000Z",
    "text": "Still boggles the mind how similar LLMs can be to lazy students/interns\nthey're perfectly capable of doing research, but often would rather blather in generalities as if they get paid by the hour https://t.co/5ytUOPuLek",
    "id": "1880120901481689171"
  },
  {
    "attachments": {
      "media_keys": ["3_1880116604400197632"]
    },
    "edit_history_tweet_ids": ["1880116651368280221"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T04:55:15.000Z",
    "text": "Learnings from Scaling Visual Tokenizers for Reconstruction and Generation https://t.co/1oQSxxdbd7",
    "id": "1880116651368280221"
  },
  {
    "attachments": {
      "media_keys": ["3_1880115980317110272"]
    },
    "edit_history_tweet_ids": ["1880116051792560320"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T04:52:52.000Z",
    "text": "Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps https://t.co/BT46xBuEcM",
    "id": "1880116051792560320"
  },
  {
    "attachments": {
      "media_keys": ["3_1880114358237138944"]
    },
    "edit_history_tweet_ids": ["1880114418325025089"],
    "author_id": "2465283662",
    "created_at": "2025-01-17T04:46:22.000Z",
    "text": "Towards Large Reasoning Models\n\nA Survey of Reinforced Reasoning with Large Language Models https://t.co/j2qQHJWNxn",
    "id": "1880114418325025089"
  },
  {
    "attachments": {
      "media_keys": ["3_1880108843432108032"]
    },
    "edit_history_tweet_ids": ["1880109051142631491"],
    "author_id": "1718879852827484160",
    "created_at": "2025-01-17T04:25:03.000Z",
    "text": "This feels pretty big. Inference time scaling with search for diffusion models https://t.co/Mpn0E5Q8z5 https://t.co/m2LN0i5IGB",
    "id": "1880109051142631491",
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880107882412405167"
      }
    ]
  },
  {
    "attachments": {
      "media_keys": ["3_1880107851235946496"]
    },
    "edit_history_tweet_ids": ["1880107882412405167"],
    "author_id": "1718879852827484160",
    "created_at": "2025-01-17T04:20:24.000Z",
    "text": "We've got inference scaling curves for diffusion models https://t.co/skHmjeoBwj",
    "id": "1880107882412405167"
  },
  {
    "edit_history_tweet_ids": ["1880106419573387528"],
    "note_tweet": {
      "text": "When I first saw diffusion models, I was blown away by how naturally they scale during inference: you train them with fixed flops, but during test time, you can ramp it up by like 1,000x. This was way before it became a big deal withÂ o1. But honestly, the scaling isnâ€™t that impressive since adding more denoising steps stops making much of a difference pretty quickly â€“ sry but it's a disappointing scaling law :(\n\nPeople have played with the randomness in diffusion models at testÂ time and found that using good noises can improve the quality for various tasks. In this new work, we focus on a systematicÂ exploration of inference-time scaling of diffusion models with a general search framework.\n\nWe take the idea of verifiers from large language models and demonstrate that different search algorithms can help find better noise candidates, preventing the scaling from hitting a ceiling during testing. By looking at inference-time scaling, we also highlight the trade-offs between different verifiers and discover new insights about evaluating diffusion models.\n\nDefinitely check out Wills @ma_nanye's thread below!",
      "entities": {
        "mentions": [
          {
            "start": 1094,
            "end": 1103,
            "username": "ma_nanye",
            "id": "1513237725960445960"
          }
        ]
      }
    },
    "author_id": "1283081795890626560",
    "created_at": "2025-01-17T04:14:35.000Z",
    "text": "When I first saw diffusion models, I was blown away by how naturally they scale during inference: you train them with fixed flops, but during test time, you can ramp it up by like 1,000x. This was way before it became a big deal withÂ o1. But honestly, the scaling isnâ€™t thatâ€¦ https://t.co/HxMiAWDoTV https://t.co/Hs5AuqXRQt",
    "id": "1880106419573387528",
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880105038132990054"
      }
    ]
  },
  {
    "attachments": {
      "media_keys": ["3_1880098065044135936", "3_1880098305012813824"]
    },
    "edit_history_tweet_ids": ["1880098533350732203"],
    "note_tweet": {
      "text": "Crazy new feature in Triton \n\nBasically, Warp specialization in Triton takes advantage of the GPUâ€™s hardware-level concurrency by splitting your kernel into multiple asynchronous tasks (â€œwarp groupsâ€). \n\nEach warp group runs in parallelâ€”communicating efficiently via H100â€™s fast shared memory. \n\nYou enable this magic by setting a couple of autotune flags, such as num_consumer_groups and num_buffers_warp_spec. Under the hood, Triton now **automatically** schedules these warp groups to run concurrently, squeezing more performance out of the GPU.\n\nIn the example above (a warp-specialized matrix multiplication), you see how they do standard Triton stepsâ€”loop over chunks of K, load A/B blocks, compute partial results, and then write them back. \n\nThe key difference is the triton.Config specifying warp specialization parameters (like num_consumer_groups=2 and num_buffers_warp_spec=3). \n\nThatâ€™s it: Triton handles splitting and overlapping work so that each warp group can make better use of GPU resources."
    },
    "author_id": "3378986176",
    "created_at": "2025-01-17T03:43:15.000Z",
    "text": "Crazy new feature in Triton \n\nBasically, Warp specialization in Triton takes advantage of the GPUâ€™s hardware-level concurrency by splitting your kernel into multiple asynchronous tasks (â€œwarp groupsâ€). \n\nEach warp group runs in parallelâ€”communicating efficiently via H100â€™s fastâ€¦ https://t.co/mAyrJ4eOjQ https://t.co/GDORoUuKpP",
    "id": "1880098533350732203"
  },
  {
    "attachments": {
      "media_keys": ["3_1880094840358350848"]
    },
    "edit_history_tweet_ids": ["1880095232706113726"],
    "author_id": "593407733",
    "created_at": "2025-01-17T03:30:08.000Z",
    "text": "Nice work from GDM on going beyond steps to scale test-time compute for diffusion models. \n\nI know this is not the first work, but it does a pretty good job of formalizing the problem, discussing:\n\n* Biases of verifiers \n* Mixing &amp; matching different verifiers\n* AND more https://t.co/T8Dg6wNSH5",
    "id": "1880095232706113726"
  },
  {
    "created_at": "2025-01-17T02:59:59.000Z",
    "edit_history_tweet_ids": ["1880087643964199260"],
    "note_tweet": {
      "entities": {
        "urls": [
          {
            "start": 379,
            "end": 402,
            "url": "https://t.co/jQxRXaaZov",
            "expanded_url": "https://hubs.la/Q032Wts00",
            "display_url": "hubs.la/Q032Wts00"
          }
        ]
      },
      "text": "DeepSeek-V3, the company's latest open LLM, surpasses Llama 3.1 405B and GPT-4o on key benchmarks, especially in coding and math tasks. \n\nUsing a mixture-of-experts architecture with 671 billion parameters, only 37 billion are active at once, DeepSeek V3 was trained at a low cost of $5.6 million â€” less than a tenth of Llama 3.1 405Bâ€™s training cost. \n\nLearn more in The Batch: https://t.co/jQxRXaaZov"
    },
    "author_id": "992153930095251456",
    "text": "DeepSeek-V3, the company's latest open LLM, surpasses Llama 3.1 405B and GPT-4o on key benchmarks, especially in coding and math tasks. \n\nUsing a mixture-of-experts architecture with 671 billion parameters, only 37 billion are active at once, DeepSeek V3 was trained at a low costâ€¦ https://t.co/a9PxiLOVKX",
    "id": "1880087643964199260"
  },
  {
    "created_at": "2025-01-17T02:54:05.000Z",
    "edit_history_tweet_ids": ["1880086159419928831"],
    "author_id": "441465751",
    "attachments": {
      "media_keys": ["3_1880084190261137408"]
    },
    "text": "Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps\n\nNew paper by Google DeepMind demonstrates how scaling up inference-time compute spent on search algorithms and verifiers for diffusion model sampling can improve sample quality. https://t.co/DbsBtNsCFw",
    "id": "1880086159419928831"
  },
  {
    "created_at": "2025-01-17T02:44:26.000Z",
    "edit_history_tweet_ids": ["1880083730032968134"],
    "author_id": "794433401591693312",
    "attachments": {
      "media_keys": ["3_1880083011859017729"]
    },
    "text": "Google presents: Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps\n\n- Scales up the inference-time compute for verifiers and the search algorithms\n\n- This leads to substantial improvements in the quality of samples generated by diffusion models https://t.co/FAq3ccDuzB",
    "id": "1880083730032968134"
  },
  {
    "created_at": "2025-01-17T02:41:06.000Z",
    "edit_history_tweet_ids": ["1880082893789360544"],
    "author_id": "985281530070265862",
    "text": "Nvidia will be a robotics company at the end of the day, not just semiconductor.\nFew understand the moves they are doing at the lowest level from manufacturing up to software.\nClassic extend embrace extinguish.\nThey are going to sell robots and this is from Jensen straight up",
    "id": "1880082893789360544"
  },
  {
    "created_at": "2025-01-17T02:41:02.000Z",
    "edit_history_tweet_ids": ["1880082877230248165"],
    "author_id": "794433401591693312",
    "attachments": {
      "media_keys": ["3_1880082583125651459"]
    },
    "text": "Meta presents: Learnings from Scaling Visual Tokenizers for Reconstruction and Generation\n\n- Explores scaling of visual tokenizers\n- Outperforms existing auto-encoders on video reconstruction, all with 2-5Ã— fewer FLOPs https://t.co/lWpL75RN8x",
    "id": "1880082877230248165"
  },
  {
    "created_at": "2025-01-17T02:28:02.000Z",
    "edit_history_tweet_ids": ["1880079480015958207", "1880079605266280498"],
    "note_tweet": {
      "entities": {
        "urls": [
          {
            "start": 329,
            "end": 352,
            "url": "https://t.co/4jKSTaomCH",
            "expanded_url": "https://arxiv.org/abs/2411.13055",
            "display_url": "arxiv.org/abs/2411.13055"
          }
        ]
      },
      "text": "If you plan to do LLM training as the accelerators get faster and faster, you will be getting smaller and smaller returns on investment unless you demand a very faster interconnect.\n\nWith each generation compute speeds up much faster than network, so network becomes the bottleneck.\n\nSee this relatively recent paper for support https://t.co/4jKSTaomCH\n\nAnd once you get your fast network, benchmark and tune it up so that that fast on paper network is actually as fast as it can be."
    },
    "author_id": "1068360975898660864",
    "text": "If you plan to do LLM training as the accelerators get faster and faster, you will be getting smaller and smaller returns on investment unless you demand a very faster interconnect.\n\nWith each generation compute speeds up much faster than network, so network becomes theâ€¦ https://t.co/83STS5Dtf9",
    "id": "1880079605266280498"
  },
  {
    "created_at": "2025-01-17T01:50:38.000Z",
    "edit_history_tweet_ids": ["1880070193596232081"],
    "in_reply_to_user_id": "192201556",
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880069643022528955"
      },
      {
        "type": "replied_to",
        "id": "1880066066191405213"
      }
    ],
    "author_id": "192201556",
    "text": "full reasoning trace, it gets confused but recovers.\nThis is a new thing that has not been systematically happening in previous generation LLMs.\nhttps://t.co/voIIWG89vH",
    "id": "1880070193596232081"
  },
  {
    "created_at": "2025-01-17T01:34:14.000Z",
    "edit_history_tweet_ids": ["1880066066191405213"],
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880043625830404540"
      }
    ],
    "author_id": "192201556",
    "attachments": {
      "media_keys": ["3_1880064702362869760"]
    },
    "text": "reminder your job is not \"safe\" just because some specific crappy LLM still can't score 170 on LSAT or whatever. This is the worst this tech will ever be, but you aren't even seeing the best of it that is available right now.\nThis one is a tiny research prototype served for free. https://t.co/Ks639vIVMz https://t.co/DVRfWkIhIl",
    "id": "1880066066191405213"
  },
  {
    "created_at": "2025-01-17T01:26:24.000Z",
    "edit_history_tweet_ids": ["1880064093786370215"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1877743475086766236"
      }
    ],
    "author_id": "731538535795163136",
    "text": "RT @CohereForAI: Be sure to check out @yuntiandeng on January 18th as he will deliver a talk titled \"Implicit Chain-of-Thought: Internaliziâ€¦",
    "id": "1880064093786370215"
  },
  {
    "created_at": "2025-01-17T01:17:26.000Z",
    "edit_history_tweet_ids": ["1880061839016620099"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879958389968843106"
      }
    ],
    "author_id": "1068360975898660864",
    "text": "RT @jeffra45: ðŸš€ Super proud to share ArcticTraining, an open-source post-training framework to simplify and power new research directions!â€¦",
    "id": "1880061839016620099"
  },
  {
    "created_at": "2025-01-17T01:16:14.000Z",
    "edit_history_tweet_ids": ["1880061534359200133"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880060785646530972"
      }
    ],
    "author_id": "245262377",
    "text": "RT @_dougsan: hacked @fullmoonapp to integrate with the MLX server, enabling you to run a larger model on your Mac and access it remotely wâ€¦",
    "id": "1880061534359200133"
  },
  {
    "created_at": "2025-01-17T01:07:26.000Z",
    "edit_history_tweet_ids": ["1880059318785176043"],
    "author_id": "2465283662",
    "attachments": {
      "media_keys": ["3_1880059210404110336"]
    },
    "text": "MiniMax-01 coder mode is now available in ai-gradio\n\npip install --upgrade \"ai-gradio[minimax]\"\n\nimport gradio as gr\nimport ai_gradio\n\ndemo = gr.load(\nname='minimax:MiniMax-Text-01',\nsrc=ai_gradio.registry,\ncoder=True\n)\ndemo.launch() https://t.co/dulIdUZ853",
    "id": "1880059318785176043"
  },
  {
    "created_at": "2025-01-17T00:58:31.000Z",
    "edit_history_tweet_ids": ["1880057077718290512"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879959251793375311"
      }
    ],
    "author_id": "186420551",
    "text": "RT @itsPaulAi: Hugging Face released a free course on agents\n\nYou can learn how to create:\n\n- Code agents that solve problem with code\n- Reâ€¦",
    "id": "1880057077718290512"
  },
  {
    "created_at": "2025-01-17T00:51:19.000Z",
    "edit_history_tweet_ids": ["1880055263543324720"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879202132106371497"
      }
    ],
    "author_id": "48008938",
    "text": "RT @ziv_ravid: A new paper  ðŸ¥³ðŸ¥³ðŸ¥³\nWe present \"Rate-In\" - a technique that helps neural networks better express their uncertainty during inferâ€¦",
    "id": "1880055263543324720"
  },
  {
    "created_at": "2025-01-17T00:51:02.000Z",
    "edit_history_tweet_ids": ["1880055194869964992"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879202143913324832"
      }
    ],
    "author_id": "48008938",
    "text": "RT @ziv_ravid: Check out our paper for detailed experiments and explanations on how we're making AI systems more reliable by helping them bâ€¦",
    "id": "1880055194869964992"
  },
  {
    "created_at": "2025-01-17T00:47:58.000Z",
    "edit_history_tweet_ids": ["1880054423004803294"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879930741758341334"
      }
    ],
    "author_id": "2728439146",
    "text": "RT @mdancho84: The price of the Python AI/ML Stack I've been using for 12 months:\n\nLangchain $0\nLanggraph $0\nScikit Learn $0\nH2O $0\nTorch $â€¦",
    "id": "1880054423004803294"
  },
  {
    "created_at": "2025-01-17T00:44:40.000Z",
    "edit_history_tweet_ids": ["1880053591089750098"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880048546382221313"
      }
    ],
    "author_id": "1605274291569799168",
    "text": "RT @ThorondorLLC: New project! Optimize your stable diffusion prompts via a \"chain-of-thought\" style iteration - built with DSPy https://t.â€¦",
    "id": "1880053591089750098"
  },
  {
    "created_at": "2025-01-17T00:26:55.000Z",
    "edit_history_tweet_ids": ["1880049125087146062"],
    "author_id": "1529761561170124800",
    "note_tweet": {
      "text": "We've got a podcast!\n\nIn our first episode, Ege, Tamay and Jaime dig into:\nâ€¢ What they expect AI to look like by 2030\nâ€¢ Why economists are underestimating the likelihood of explosive growth\nâ€¢ The startling regularity in technological trends like Moore's Law\nâ€¢ Moravecâ€™s paradox, and how we might overcome it\n\nAnd more more!\n\nTimestamps:\n00:00:00 Preview\n00:00:37 What is Epoch AI?\n00:02:32 Scaling Laws\n00:08:43 Key Drivers\n00:19:20 End of the Decade Predictions\n00:21:18 Bottlenecks: Power\n00:27:59 Bottlenecks: GPUs\n00:32:07 Bottlenecks: Data\n00:45:37 Bottlenecks: Latency\n00:56:18 Bottlenecks: Failure Rates\n01:03:55 AI Investment\n01:07:11 Automation\n01:12:10 Benchmarks & Moravecâ€™s Paradox\n01:19:45 Economic Impact\n01:45:48 Open Questions & Takeaways"
    },
    "attachments": {
      "media_keys": ["13_1880028265378902017"]
    },
    "text": "We've got a podcast!\n\nIn our first episode, Ege, Tamay and Jaime dig into:\nâ€¢ What they expect AI to look like by 2030\nâ€¢ Why economists are underestimating the likelihood of explosive growth\nâ€¢ The startling regularity in technological trends like Moore's Law\nâ€¢ Moravecâ€™sâ€¦ https://t.co/VenD6I6ysD https://t.co/zBAYtSy7jj",
    "id": "1880049125087146062"
  },
  {
    "created_at": "2025-01-17T00:25:23.000Z",
    "edit_history_tweet_ids": ["1880048736807842013"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1880015645347311772"
      }
    ],
    "author_id": "89538466",
    "text": "RT @bearlyai: Goldman Sachs CEO David Solomon says that AI can draft 95% of an S1 IPO prospectus â€œin minutesâ€ (a job that used to require aâ€¦",
    "id": "1880048736807842013"
  },
  {
    "created_at": "2025-01-17T00:09:16.000Z",
    "edit_history_tweet_ids": ["1880044682601984170"],
    "referenced_tweets": [
      {
        "type": "quoted",
        "id": "1880034144622899560"
      }
    ],
    "author_id": "192201556",
    "attachments": {
      "media_keys": ["16_1880044669121314816"]
    },
    "text": "these people scoffing at llm integration into workflows must be bullied for their own good\nit's very much like \"don't use the internet it's full of fake stuff, go to physical library\" ngmi attitude, but this time there won't be decades of a grace period https://t.co/YeVr7heuLu https://t.co/VrzuQ8Bt6V",
    "id": "1880044682601984170"
  },
  {
    "created_at": "2025-01-16T23:58:12.000Z",
    "edit_history_tweet_ids": ["1880041895931543958"],
    "referenced_tweets": [
      {
        "type": "retweeted",
        "id": "1879930096792015151"
      }
    ],
    "author_id": "2465283662",
    "attachments": {
      "media_keys": ["3_1879929409802469389"]
    },
    "text": "RT @victormustar: FitDiT Virtual Try-on Demo on Hugging Face is wild ðŸ¤¯\nâ¬‡ï¸ Anyone can try it online https://t.co/I69UgVxgvU",
    "id": "1880041895931543958"
  }
]
